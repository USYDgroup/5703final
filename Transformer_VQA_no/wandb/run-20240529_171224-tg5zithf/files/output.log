Not using distributed mode
Creating vqa datasets
Creating model
reshape position embedding from 256 to 576
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/ALBEF.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['temp', 'image_queue', 'text_queue', 'queue_ptr', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'visual_encoder_m.cls_token', 'visual_encoder_m.pos_embed', 'visual_encoder_m.patch_embed.proj.weight', 'visual_encoder_m.patch_embed.proj.bias', 'visual_encoder_m.blocks.0.norm1.weight', 'visual_encoder_m.blocks.0.norm1.bias', 'visual_encoder_m.blocks.0.attn.qkv.weight', 'visual_encoder_m.blocks.0.attn.qkv.bias', 'visual_encoder_m.blocks.0.attn.proj.weight', 'visual_encoder_m.blocks.0.attn.proj.bias', 'visual_encoder_m.blocks.0.norm2.weight', 'visual_encoder_m.blocks.0.norm2.bias', 'visual_encoder_m.blocks.0.mlp.fc1.weight', 'visual_encoder_m.blocks.0.mlp.fc1.bias', 'visual_encoder_m.blocks.0.mlp.fc2.weight', 'visual_encoder_m.blocks.0.mlp.fc2.bias', 'visual_encoder_m.blocks.1.norm1.weight', 'visual_encoder_m.blocks.1.norm1.bias', 'visual_encoder_m.blocks.1.attn.qkv.weight', 'visual_encoder_m.blocks.1.attn.qkv.bias', 'visual_encoder_m.blocks.1.attn.proj.weight', 'visual_encoder_m.blocks.1.attn.proj.bias', 'visual_encoder_m.blocks.1.norm2.weight', 'visual_encoder_m.blocks.1.norm2.bias', 'visual_encoder_m.blocks.1.mlp.fc1.weight', 'visual_encoder_m.blocks.1.mlp.fc1.bias', 'visual_encoder_m.blocks.1.mlp.fc2.weight', 'visual_encoder_m.blocks.1.mlp.fc2.bias', 'visual_encoder_m.blocks.2.norm1.weight', 'visual_encoder_m.blocks.2.norm1.bias', 'visual_encoder_m.blocks.2.attn.qkv.weight', 'visual_encoder_m.blocks.2.attn.qkv.bias', 'visual_encoder_m.blocks.2.attn.proj.weight', 'visual_encoder_m.blocks.2.attn.proj.bias', 'visual_encoder_m.blocks.2.norm2.weight', 'visual_encoder_m.blocks.2.norm2.bias', 'visual_encoder_m.blocks.2.mlp.fc1.weight', 'visual_encoder_m.blocks.2.mlp.fc1.bias', 'visual_encoder_m.blocks.2.mlp.fc2.weight', 'visual_encoder_m.blocks.2.mlp.fc2.bias', 'visual_encoder_m.blocks.3.norm1.weight', 'visual_encoder_m.blocks.3.norm1.bias', 'visual_encoder_m.blocks.3.attn.qkv.weight', 'visual_encoder_m.blocks.3.attn.qkv.bias', 'visual_encoder_m.blocks.3.attn.proj.weight', 'visual_encoder_m.blocks.3.attn.proj.bias', 'visual_encoder_m.blocks.3.norm2.weight', 'visual_encoder_m.blocks.3.norm2.bias', 'visual_encoder_m.blocks.3.mlp.fc1.weight', 'visual_encoder_m.blocks.3.mlp.fc1.bias', 'visual_encoder_m.blocks.3.mlp.fc2.weight', 'visual_encoder_m.blocks.3.mlp.fc2.bias', 'visual_encoder_m.blocks.4.norm1.weight', 'visual_encoder_m.blocks.4.norm1.bias', 'visual_encoder_m.blocks.4.attn.qkv.weight', 'visual_encoder_m.blocks.4.attn.qkv.bias', 'visual_encoder_m.blocks.4.attn.proj.weight', 'visual_encoder_m.blocks.4.attn.proj.bias', 'visual_encoder_m.blocks.4.norm2.weight', 'visual_encoder_m.blocks.4.norm2.bias', 'visual_encoder_m.blocks.4.mlp.fc1.weight', 'visual_encoder_m.blocks.4.mlp.fc1.bias', 'visual_encoder_m.blocks.4.mlp.fc2.weight', 'visual_encoder_m.blocks.4.mlp.fc2.bias', 'visual_encoder_m.blocks.5.norm1.weight', 'visual_encoder_m.blocks.5.norm1.bias', 'visual_encoder_m.blocks.5.attn.qkv.weight', 'visual_encoder_m.blocks.5.attn.qkv.bias', 'visual_encoder_m.blocks.5.attn.proj.weight', 'visual_encoder_m.blocks.5.attn.proj.bias', 'visual_encoder_m.blocks.5.norm2.weight', 'visual_encoder_m.blocks.5.norm2.bias', 'visual_encoder_m.blocks.5.mlp.fc1.weight', 'visual_encoder_m.blocks.5.mlp.fc1.bias', 'visual_encoder_m.blocks.5.mlp.fc2.weight', 'visual_encoder_m.blocks.5.mlp.fc2.bias', 'visual_encoder_m.blocks.6.norm1.weight', 'visual_encoder_m.blocks.6.norm1.bias', 'visual_encoder_m.blocks.6.attn.qkv.weight', 'visual_encoder_m.blocks.6.attn.qkv.bias', 'visual_encoder_m.blocks.6.attn.proj.weight', 'visual_encoder_m.blocks.6.attn.proj.bias', 'visual_encoder_m.blocks.6.norm2.weight', 'visual_encoder_m.blocks.6.norm2.bias', 'visual_encoder_m.blocks.6.mlp.fc1.weight', 'visual_encoder_m.blocks.6.mlp.fc1.bias', 'visual_encoder_m.blocks.6.mlp.fc2.weight', 'visual_encoder_m.blocks.6.mlp.fc2.bias', 'visual_encoder_m.blocks.7.norm1.weight', 'visual_encoder_m.blocks.7.norm1.bias', 'visual_encoder_m.blocks.7.attn.qkv.weight', 'visual_encoder_m.blocks.7.attn.qkv.bias', 'visual_encoder_m.blocks.7.attn.proj.weight', 'visual_encoder_m.blocks.7.attn.proj.bias', 'visual_encoder_m.blocks.7.norm2.weight', 'visual_encoder_m.blocks.7.norm2.bias', 'visual_encoder_m.blocks.7.mlp.fc1.weight', 'visual_encoder_m.blocks.7.mlp.fc1.bias', 'visual_encoder_m.blocks.7.mlp.fc2.weight', 'visual_encoder_m.blocks.7.mlp.fc2.bias', 'visual_encoder_m.blocks.8.norm1.weight', 'visual_encoder_m.blocks.8.norm1.bias', 'visual_encoder_m.blocks.8.attn.qkv.weight', 'visual_encoder_m.blocks.8.attn.qkv.bias', 'visual_encoder_m.blocks.8.attn.proj.weight', 'visual_encoder_m.blocks.8.attn.proj.bias', 'visual_encoder_m.blocks.8.norm2.weight', 'visual_encoder_m.blocks.8.norm2.bias', 'visual_encoder_m.blocks.8.mlp.fc1.weight', 'visual_encoder_m.blocks.8.mlp.fc1.bias', 'visual_encoder_m.blocks.8.mlp.fc2.weight', 'visual_encoder_m.blocks.8.mlp.fc2.bias', 'visual_encoder_m.blocks.9.norm1.weight', 'visual_encoder_m.blocks.9.norm1.bias', 'visual_encoder_m.blocks.9.attn.qkv.weight', 'visual_encoder_m.blocks.9.attn.qkv.bias', 'visual_encoder_m.blocks.9.attn.proj.weight', 'visual_encoder_m.blocks.9.attn.proj.bias', 'visual_encoder_m.blocks.9.norm2.weight', 'visual_encoder_m.blocks.9.norm2.bias', 'visual_encoder_m.blocks.9.mlp.fc1.weight', 'visual_encoder_m.blocks.9.mlp.fc1.bias', 'visual_encoder_m.blocks.9.mlp.fc2.weight', 'visual_encoder_m.blocks.9.mlp.fc2.bias', 'visual_encoder_m.blocks.10.norm1.weight', 'visual_encoder_m.blocks.10.norm1.bias', 'visual_encoder_m.blocks.10.attn.qkv.weight', 'visual_encoder_m.blocks.10.attn.qkv.bias', 'visual_encoder_m.blocks.10.attn.proj.weight', 'visual_encoder_m.blocks.10.attn.proj.bias', 'visual_encoder_m.blocks.10.norm2.weight', 'visual_encoder_m.blocks.10.norm2.bias', 'visual_encoder_m.blocks.10.mlp.fc1.weight', 'visual_encoder_m.blocks.10.mlp.fc1.bias', 'visual_encoder_m.blocks.10.mlp.fc2.weight', 'visual_encoder_m.blocks.10.mlp.fc2.bias', 'visual_encoder_m.blocks.11.norm1.weight', 'visual_encoder_m.blocks.11.norm1.bias', 'visual_encoder_m.blocks.11.attn.qkv.weight', 'visual_encoder_m.blocks.11.attn.qkv.bias', 'visual_encoder_m.blocks.11.attn.proj.weight', 'visual_encoder_m.blocks.11.attn.proj.bias', 'visual_encoder_m.blocks.11.norm2.weight', 'visual_encoder_m.blocks.11.norm2.bias', 'visual_encoder_m.blocks.11.mlp.fc1.weight', 'visual_encoder_m.blocks.11.mlp.fc1.bias', 'visual_encoder_m.blocks.11.mlp.fc2.weight', 'visual_encoder_m.blocks.11.mlp.fc2.bias', 'visual_encoder_m.norm.weight', 'visual_encoder_m.norm.bias', 'vision_proj_m.weight', 'vision_proj_m.bias', 'text_proj_m.weight', 'text_proj_m.bias', 'text_encoder_m.embeddings.position_ids', 'text_decoder_m.bert.embeddings.position_ids', 'text_encoder_m.embeddings.word_embeddings.weight', 'text_decoder_m.bert.embeddings.word_embeddings.weight', 'text_encoder_m.embeddings.position_embeddings.weight', 'text_decoder_m.bert.embeddings.position_embeddings.weight', 'text_encoder_m.embeddings.token_type_embeddings.weight', 'text_decoder_m.bert.embeddings.token_type_embeddings.weight', 'text_encoder_m.embeddings.LayerNorm.weight', 'text_decoder_m.bert.embeddings.LayerNorm.weight', 'text_encoder_m.embeddings.LayerNorm.bias', 'text_decoder_m.bert.embeddings.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.attention.self.query.weight', 'text_encoder_m.encoder.layer.0.attention.self.query.bias', 'text_encoder_m.encoder.layer.0.attention.self.key.weight', 'text_encoder_m.encoder.layer.0.attention.self.key.bias', 'text_encoder_m.encoder.layer.0.attention.self.value.weight', 'text_encoder_m.encoder.layer.0.attention.self.value.bias', 'text_encoder_m.encoder.layer.0.attention.output.dense.weight', 'text_encoder_m.encoder.layer.0.attention.output.dense.bias', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.intermediate.dense.weight', 'text_encoder_m.encoder.layer.0.intermediate.dense.bias', 'text_encoder_m.encoder.layer.0.output.dense.weight', 'text_encoder_m.encoder.layer.0.output.dense.bias', 'text_encoder_m.encoder.layer.0.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.attention.self.query.weight', 'text_encoder_m.encoder.layer.1.attention.self.query.bias', 'text_encoder_m.encoder.layer.1.attention.self.key.weight', 'text_encoder_m.encoder.layer.1.attention.self.key.bias', 'text_encoder_m.encoder.layer.1.attention.self.value.weight', 'text_encoder_m.encoder.layer.1.attention.self.value.bias', 'text_encoder_m.encoder.layer.1.attention.output.dense.weight', 'text_encoder_m.encoder.layer.1.attention.output.dense.bias', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.intermediate.dense.weight', 'text_encoder_m.encoder.layer.1.intermediate.dense.bias', 'text_encoder_m.encoder.layer.1.output.dense.weight', 'text_encoder_m.encoder.layer.1.output.dense.bias', 'text_encoder_m.encoder.layer.1.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.attention.self.query.weight', 'text_encoder_m.encoder.layer.2.attention.self.query.bias', 'text_encoder_m.encoder.layer.2.attention.self.key.weight', 'text_encoder_m.encoder.layer.2.attention.self.key.bias', 'text_encoder_m.encoder.layer.2.attention.self.value.weight', 'text_encoder_m.encoder.layer.2.attention.self.value.bias', 'text_encoder_m.encoder.layer.2.attention.output.dense.weight', 'text_encoder_m.encoder.layer.2.attention.output.dense.bias', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.intermediate.dense.weight', 'text_encoder_m.encoder.layer.2.intermediate.dense.bias', 'text_encoder_m.encoder.layer.2.output.dense.weight', 'text_encoder_m.encoder.layer.2.output.dense.bias', 'text_encoder_m.encoder.layer.2.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.query.weight', 'text_encoder_m.encoder.layer.6.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.query.bias', 'text_encoder_m.encoder.layer.6.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.key.weight', 'text_encoder_m.encoder.layer.6.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.key.bias', 'text_encoder_m.encoder.layer.6.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.value.weight', 'text_encoder_m.encoder.layer.6.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.value.bias', 'text_encoder_m.encoder.layer.6.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.attention.output.dense.weight', 'text_encoder_m.encoder.layer.6.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.attention.output.dense.bias', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.0.intermediate.dense.weight', 'text_encoder_m.encoder.layer.6.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.0.intermediate.dense.bias', 'text_encoder_m.encoder.layer.6.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.output.dense.weight', 'text_encoder_m.encoder.layer.6.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.output.dense.bias', 'text_encoder_m.encoder.layer.6.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.query.weight', 'text_encoder_m.encoder.layer.7.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.query.bias', 'text_encoder_m.encoder.layer.7.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.key.weight', 'text_encoder_m.encoder.layer.7.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.key.bias', 'text_encoder_m.encoder.layer.7.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.value.weight', 'text_encoder_m.encoder.layer.7.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.value.bias', 'text_encoder_m.encoder.layer.7.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.attention.output.dense.weight', 'text_encoder_m.encoder.layer.7.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.attention.output.dense.bias', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.1.intermediate.dense.weight', 'text_encoder_m.encoder.layer.7.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.1.intermediate.dense.bias', 'text_encoder_m.encoder.layer.7.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.output.dense.weight', 'text_encoder_m.encoder.layer.7.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.output.dense.bias', 'text_encoder_m.encoder.layer.7.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.query.weight', 'text_encoder_m.encoder.layer.8.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.query.bias', 'text_encoder_m.encoder.layer.8.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.key.weight', 'text_encoder_m.encoder.layer.8.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.key.bias', 'text_encoder_m.encoder.layer.8.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.value.weight', 'text_encoder_m.encoder.layer.8.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.value.bias', 'text_encoder_m.encoder.layer.8.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.attention.output.dense.weight', 'text_encoder_m.encoder.layer.8.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.attention.output.dense.bias', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.2.intermediate.dense.weight', 'text_encoder_m.encoder.layer.8.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.2.intermediate.dense.bias', 'text_encoder_m.encoder.layer.8.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.output.dense.weight', 'text_encoder_m.encoder.layer.8.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.output.dense.bias', 'text_encoder_m.encoder.layer.8.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.9.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.9.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.9.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.9.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.9.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.9.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.9.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.9.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.9.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.9.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.9.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.10.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.10.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.10.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.10.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.10.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.10.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.10.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.10.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.10.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.10.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.10.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.11.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.11.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.11.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.11.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.11.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.11.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.11.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.11.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.11.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.11.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.11.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.output.LayerNorm.bias', 'text_decoder_m.cls.predictions.bias', 'text_decoder_m.cls.predictions.transform.dense.weight', 'text_decoder_m.cls.predictions.transform.dense.bias', 'text_decoder_m.cls.predictions.transform.LayerNorm.weight', 'text_decoder_m.cls.predictions.transform.LayerNorm.bias', 'text_decoder_m.cls.predictions.decoder.weight', 'text_decoder_m.cls.predictions.decoder.bias', 'fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [    0/27734]  eta: 1 day, 0:52:37  lr: 0.000010  loss: 43.4484  time: 3.2292  data: 1.3091  max mem: 11191
Train Epoch: [0]  [   50/27734]  eta: 4:43:44  lr: 0.000010  loss: 7.7889  time: 0.5692  data: 0.0002  max mem: 15280
Train Epoch: [0]  [  100/27734]  eta: 4:32:58  lr: 0.000010  loss: 6.3743  time: 0.5686  data: 0.0002  max mem: 15289
Train Epoch: [0]  [  150/27734]  eta: 4:27:58  lr: 0.000013  loss: 7.7909  time: 0.5600  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  200/27734]  eta: 4:25:36  lr: 0.000013  loss: 5.8733  time: 0.5658  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  250/27734]  eta: 4:24:13  lr: 0.000015  loss: 4.2686  time: 0.5697  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  300/27734]  eta: 4:23:10  lr: 0.000015  loss: 3.8041  time: 0.5645  data: 0.0001  max mem: 15328
Train Epoch: [0]  [  350/27734]  eta: 4:22:35  lr: 0.000018  loss: 6.6678  time: 0.5733  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  400/27734]  eta: 4:22:21  lr: 0.000018  loss: 10.1648  time: 0.5683  data: 0.0001  max mem: 15328
Train Epoch: [0]  [  450/27734]  eta: 4:21:12  lr: 0.000020  loss: 8.3763  time: 0.5671  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  500/27734]  eta: 4:20:10  lr: 0.000020  loss: 9.0297  time: 0.5667  data: 0.0002  max mem: 15340
Train Epoch: [0]  [  550/27734]  eta: 4:19:24  lr: 0.000020  loss: 6.3026  time: 0.5722  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  600/27734]  eta: 4:18:38  lr: 0.000020  loss: 9.0818  time: 0.5614  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  650/27734]  eta: 4:17:53  lr: 0.000020  loss: 6.6252  time: 0.5620  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  700/27734]  eta: 4:17:14  lr: 0.000020  loss: 5.3787  time: 0.5704  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  750/27734]  eta: 4:16:27  lr: 0.000020  loss: 5.9044  time: 0.5568  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  800/27734]  eta: 4:15:49  lr: 0.000020  loss: 4.5536  time: 0.5609  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  850/27734]  eta: 4:15:08  lr: 0.000020  loss: 4.3025  time: 0.5640  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  900/27734]  eta: 4:14:28  lr: 0.000020  loss: 5.1047  time: 0.5630  data: 0.0003  max mem: 15373
Train Epoch: [0]  [  950/27734]  eta: 4:13:55  lr: 0.000020  loss: 8.3180  time: 0.5683  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1000/27734]  eta: 4:13:20  lr: 0.000020  loss: 2.8438  time: 0.5626  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1050/27734]  eta: 4:12:41  lr: 0.000020  loss: 7.4500  time: 0.5569  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1100/27734]  eta: 4:12:08  lr: 0.000020  loss: 8.3205  time: 0.5685  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1150/27734]  eta: 4:11:31  lr: 0.000020  loss: 5.2281  time: 0.5562  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1200/27734]  eta: 4:10:56  lr: 0.000020  loss: 5.6087  time: 0.5621  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1250/27734]  eta: 4:10:24  lr: 0.000020  loss: 8.5955  time: 0.5613  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1300/27734]  eta: 4:09:48  lr: 0.000020  loss: 9.1206  time: 0.5623  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1350/27734]  eta: 4:09:12  lr: 0.000020  loss: 6.3503  time: 0.5595  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1400/27734]  eta: 4:08:37  lr: 0.000020  loss: 6.6648  time: 0.5594  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1450/27734]  eta: 4:08:06  lr: 0.000020  loss: 5.8239  time: 0.5631  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1500/27734]  eta: 4:07:35  lr: 0.000020  loss: 7.1456  time: 0.5574  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1550/27734]  eta: 4:07:05  lr: 0.000020  loss: 6.3092  time: 0.5677  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1600/27734]  eta: 4:06:36  lr: 0.000020  loss: 7.1129  time: 0.5655  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1650/27734]  eta: 4:06:10  lr: 0.000020  loss: 4.2710  time: 0.5621  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1700/27734]  eta: 4:05:40  lr: 0.000020  loss: 10.0815  time: 0.5619  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1750/27734]  eta: 4:05:10  lr: 0.000020  loss: 8.9726  time: 0.5651  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1800/27734]  eta: 4:04:43  lr: 0.000020  loss: 7.8391  time: 0.5722  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 1850/27734]  eta: 4:04:10  lr: 0.000020  loss: 6.4854  time: 0.5578  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1900/27734]  eta: 4:03:32  lr: 0.000020  loss: 4.8933  time: 0.5603  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 1950/27734]  eta: 4:03:00  lr: 0.000020  loss: 11.2736  time: 0.5599  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2000/27734]  eta: 4:02:31  lr: 0.000020  loss: 3.0238  time: 0.5596  data: 0.0002  max mem: 15548
Traceback (most recent call last):
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 368, in <module>
    main(args, config)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 298, in main
    train_stats = train(model, train_loader, optimizer, tokenizer, epoch, warmup_steps, device, lr_scheduler, config)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 90, in train
    loss.backward()
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt