Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['text_encoder.encoder.layer.12.attention.self.query.weight', 'text_encoder.encoder.layer.12.attention.self.query.bias', 'text_encoder.encoder.layer.12.attention.self.key.weight', 'text_encoder.encoder.layer.12.attention.self.key.bias', 'text_encoder.encoder.layer.12.attention.self.value.weight', 'text_encoder.encoder.layer.12.attention.self.value.bias', 'text_encoder.encoder.layer.12.attention.output.dense.weight', 'text_encoder.encoder.layer.12.attention.output.dense.bias', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.crossattention.self.query.weight', 'text_encoder.encoder.layer.12.crossattention.self.query.bias', 'text_encoder.encoder.layer.12.crossattention.self.key.weight', 'text_encoder.encoder.layer.12.crossattention.self.key.bias', 'text_encoder.encoder.layer.12.crossattention.self.value.weight', 'text_encoder.encoder.layer.12.crossattention.self.value.bias', 'text_encoder.encoder.layer.12.crossattention.output.dense.weight', 'text_encoder.encoder.layer.12.crossattention.output.dense.bias', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.intermediate.dense.weight', 'text_encoder.encoder.layer.12.intermediate.dense.bias', 'text_encoder.encoder.layer.12.output.dense.weight', 'text_encoder.encoder.layer.12.output.dense.bias', 'text_encoder.encoder.layer.12.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.attention.self.query.weight', 'text_encoder.encoder.layer.13.attention.self.query.bias', 'text_encoder.encoder.layer.13.attention.self.key.weight', 'text_encoder.encoder.layer.13.attention.self.key.bias', 'text_encoder.encoder.layer.13.attention.self.value.weight', 'text_encoder.encoder.layer.13.attention.self.value.bias', 'text_encoder.encoder.layer.13.attention.output.dense.weight', 'text_encoder.encoder.layer.13.attention.output.dense.bias', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.crossattention.self.query.weight', 'text_encoder.encoder.layer.13.crossattention.self.query.bias', 'text_encoder.encoder.layer.13.crossattention.self.key.weight', 'text_encoder.encoder.layer.13.crossattention.self.key.bias', 'text_encoder.encoder.layer.13.crossattention.self.value.weight', 'text_encoder.encoder.layer.13.crossattention.self.value.bias', 'text_encoder.encoder.layer.13.crossattention.output.dense.weight', 'text_encoder.encoder.layer.13.crossattention.output.dense.bias', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.intermediate.dense.weight', 'text_encoder.encoder.layer.13.intermediate.dense.bias', 'text_encoder.encoder.layer.13.output.dense.weight', 'text_encoder.encoder.layer.13.output.dense.bias', 'text_encoder.encoder.layer.13.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.attention.self.query.weight', 'text_encoder.encoder.layer.14.attention.self.query.bias', 'text_encoder.encoder.layer.14.attention.self.key.weight', 'text_encoder.encoder.layer.14.attention.self.key.bias', 'text_encoder.encoder.layer.14.attention.self.value.weight', 'text_encoder.encoder.layer.14.attention.self.value.bias', 'text_encoder.encoder.layer.14.attention.output.dense.weight', 'text_encoder.encoder.layer.14.attention.output.dense.bias', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.crossattention.self.query.weight', 'text_encoder.encoder.layer.14.crossattention.self.query.bias', 'text_encoder.encoder.layer.14.crossattention.self.key.weight', 'text_encoder.encoder.layer.14.crossattention.self.key.bias', 'text_encoder.encoder.layer.14.crossattention.self.value.weight', 'text_encoder.encoder.layer.14.crossattention.self.value.bias', 'text_encoder.encoder.layer.14.crossattention.output.dense.weight', 'text_encoder.encoder.layer.14.crossattention.output.dense.bias', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.intermediate.dense.weight', 'text_encoder.encoder.layer.14.intermediate.dense.bias', 'text_encoder.encoder.layer.14.output.dense.weight', 'text_encoder.encoder.layer.14.output.dense.bias', 'text_encoder.encoder.layer.14.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.attention.self.query.weight', 'text_encoder.encoder.layer.15.attention.self.query.bias', 'text_encoder.encoder.layer.15.attention.self.key.weight', 'text_encoder.encoder.layer.15.attention.self.key.bias', 'text_encoder.encoder.layer.15.attention.self.value.weight', 'text_encoder.encoder.layer.15.attention.self.value.bias', 'text_encoder.encoder.layer.15.attention.output.dense.weight', 'text_encoder.encoder.layer.15.attention.output.dense.bias', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.crossattention.self.query.weight', 'text_encoder.encoder.layer.15.crossattention.self.query.bias', 'text_encoder.encoder.layer.15.crossattention.self.key.weight', 'text_encoder.encoder.layer.15.crossattention.self.key.bias', 'text_encoder.encoder.layer.15.crossattention.self.value.weight', 'text_encoder.encoder.layer.15.crossattention.self.value.bias', 'text_encoder.encoder.layer.15.crossattention.output.dense.weight', 'text_encoder.encoder.layer.15.crossattention.output.dense.bias', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.intermediate.dense.weight', 'text_encoder.encoder.layer.15.intermediate.dense.bias', 'text_encoder.encoder.layer.15.output.dense.weight', 'text_encoder.encoder.layer.15.output.dense.bias', 'text_encoder.encoder.layer.15.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.output.LayerNorm.bias', 'inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [   0/1125]  eta: 0:49:27  lr: 0.000010  loss: 1.6340  time: 2.6376  data: 0.8942  max mem: 11560
Train Epoch: [0]  [  50/1125]  eta: 0:11:16  lr: 0.000010  loss: 0.4749  time: 0.5906  data: 0.0001  max mem: 15654
Train Epoch: [0]  [ 100/1125]  eta: 0:10:27  lr: 0.000010  loss: 0.5352  time: 0.5923  data: 0.0001  max mem: 15654
Train Epoch: [0]  [ 150/1125]  eta: 0:09:49  lr: 0.000013  loss: 0.2766  time: 0.5876  data: 0.0001  max mem: 15654
Train Epoch: [0]  [ 200/1125]  eta: 0:09:14  lr: 0.000013  loss: 0.3050  time: 0.5809  data: 0.0001  max mem: 15654
Train Epoch: [0]  [ 250/1125]  eta: 0:08:42  lr: 0.000015  loss: 0.2615  time: 0.5907  data: 0.0001  max mem: 15654
Train Epoch: [0]  [ 300/1125]  eta: 0:08:12  lr: 0.000015  loss: 0.3813  time: 0.5950  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 350/1125]  eta: 0:07:41  lr: 0.000018  loss: 0.2566  time: 0.5846  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 400/1125]  eta: 0:07:11  lr: 0.000018  loss: 0.3576  time: 0.5851  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 450/1125]  eta: 0:06:40  lr: 0.000020  loss: 0.4674  time: 0.5842  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 500/1125]  eta: 0:06:10  lr: 0.000020  loss: 0.3085  time: 0.5787  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 550/1125]  eta: 0:05:40  lr: 0.000020  loss: 0.1072  time: 0.5915  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 600/1125]  eta: 0:05:10  lr: 0.000020  loss: 0.2237  time: 0.5995  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 650/1125]  eta: 0:04:41  lr: 0.000020  loss: 0.1113  time: 0.5900  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 700/1125]  eta: 0:04:11  lr: 0.000020  loss: 0.1994  time: 0.5900  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 750/1125]  eta: 0:03:41  lr: 0.000020  loss: 0.1149  time: 0.5923  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 800/1125]  eta: 0:03:12  lr: 0.000020  loss: 0.0638  time: 0.5873  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 850/1125]  eta: 0:02:42  lr: 0.000020  loss: 0.2150  time: 0.5858  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.1766  time: 0.5785  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 950/1125]  eta: 0:01:43  lr: 0.000020  loss: 0.0825  time: 0.5771  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.1037  time: 0.5973  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.2308  time: 0.5961  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.2640  time: 0.5897  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.2659  time: 0.5672  data: 0.0002  max mem: 15656
Train Epoch: [0] Total time: 0:11:03 (0.5898 s / it)
Averaged stats: lr: 0.0000  loss: 0.2619
Generate VQA test result:  [  0/563]  eta: 0:07:54    time: 0.8421  data: 0.2980  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:52    time: 0.2076  data: 0.0001  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:39    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2076  data: 0.0001  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2088  data: 0.0001  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2074  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2078  data: 0.0001  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2078  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2079  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2073  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2078  data: 0.0001  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2063  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2090 s / it)
0.933392539964476
Train Epoch: [1]  [   0/1125]  eta: 0:35:19  lr: 0.000019  loss: 0.1496  time: 1.8844  data: 0.9231  max mem: 15656
Train Epoch: [1]  [  50/1125]  eta: 0:11:02  lr: 0.000019  loss: 0.1191  time: 0.5849  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 100/1125]  eta: 0:10:17  lr: 0.000019  loss: 0.0385  time: 0.5859  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 150/1125]  eta: 0:09:41  lr: 0.000019  loss: 0.1777  time: 0.5846  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 200/1125]  eta: 0:09:09  lr: 0.000019  loss: 0.0236  time: 0.5899  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 250/1125]  eta: 0:08:38  lr: 0.000019  loss: 0.0976  time: 0.5830  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 300/1125]  eta: 0:08:08  lr: 0.000019  loss: 0.0940  time: 0.5891  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 350/1125]  eta: 0:07:38  lr: 0.000019  loss: 0.0435  time: 0.5863  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 400/1125]  eta: 0:07:07  lr: 0.000019  loss: 0.0591  time: 0.5862  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 450/1125]  eta: 0:06:38  lr: 0.000019  loss: 0.0535  time: 0.5918  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 500/1125]  eta: 0:06:08  lr: 0.000019  loss: 0.0285  time: 0.5902  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 550/1125]  eta: 0:05:39  lr: 0.000019  loss: 0.0167  time: 0.5978  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 600/1125]  eta: 0:05:09  lr: 0.000019  loss: 0.0533  time: 0.5848  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 650/1125]  eta: 0:04:39  lr: 0.000019  loss: 0.1183  time: 0.5799  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 700/1125]  eta: 0:04:10  lr: 0.000019  loss: 0.0907  time: 0.5897  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 750/1125]  eta: 0:03:40  lr: 0.000019  loss: 0.0139  time: 0.5959  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 800/1125]  eta: 0:03:11  lr: 0.000019  loss: 0.0319  time: 0.5916  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 850/1125]  eta: 0:02:41  lr: 0.000019  loss: 0.0703  time: 0.5886  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 900/1125]  eta: 0:02:12  lr: 0.000019  loss: 0.0604  time: 0.5868  data: 0.0001  max mem: 15656
Train Epoch: [1]  [ 950/1125]  eta: 0:01:42  lr: 0.000019  loss: 0.1342  time: 0.5815  data: 0.0001  max mem: 15656
Train Epoch: [1]  [1000/1125]  eta: 0:01:13  lr: 0.000019  loss: 0.1712  time: 0.5874  data: 0.0001  max mem: 15656
Train Epoch: [1]  [1050/1125]  eta: 0:00:44  lr: 0.000019  loss: 0.0733  time: 0.5831  data: 0.0001  max mem: 15656
Train Epoch: [1]  [1100/1125]  eta: 0:00:14  lr: 0.000019  loss: 0.0730  time: 0.5877  data: 0.0001  max mem: 15656
Train Epoch: [1]  [1124/1125]  eta: 0:00:00  lr: 0.000019  loss: 0.2664  time: 0.5736  data: 0.0002  max mem: 15656
Train Epoch: [1] Total time: 0:11:01 (0.5881 s / it)
Averaged stats: lr: 0.0000  loss: 0.0959
Generate VQA test result:  [  0/563]  eta: 0:05:12    time: 0.5542  data: 0.3221  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2083  data: 0.0001  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2080  data: 0.0001  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2078  data: 0.0001  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2081  data: 0.0001  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2094  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2082  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2080  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2081  data: 0.0001  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2076  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2064  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2088 s / it)
0.9760213143872114
Train Epoch: [2]  [   0/1125]  eta: 0:35:27  lr: 0.000017  loss: 0.0866  time: 1.8915  data: 1.0363  max mem: 15656
Train Epoch: [2]  [  50/1125]  eta: 0:10:58  lr: 0.000017  loss: 0.0367  time: 0.5819  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 100/1125]  eta: 0:10:18  lr: 0.000017  loss: 0.0967  time: 0.5940  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 150/1125]  eta: 0:09:42  lr: 0.000017  loss: 0.0055  time: 0.5902  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 200/1125]  eta: 0:09:10  lr: 0.000017  loss: 0.0309  time: 0.5901  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 250/1125]  eta: 0:08:37  lr: 0.000017  loss: 0.1171  time: 0.5851  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 300/1125]  eta: 0:08:07  lr: 0.000017  loss: 0.0340  time: 0.5841  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 350/1125]  eta: 0:07:38  lr: 0.000017  loss: 0.0016  time: 0.5947  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 400/1125]  eta: 0:07:08  lr: 0.000017  loss: 0.0230  time: 0.5882  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 450/1125]  eta: 0:06:38  lr: 0.000017  loss: 0.0677  time: 0.5873  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 500/1125]  eta: 0:06:08  lr: 0.000017  loss: 0.0112  time: 0.5812  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 550/1125]  eta: 0:05:39  lr: 0.000017  loss: 0.0026  time: 0.5868  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 600/1125]  eta: 0:05:10  lr: 0.000017  loss: 0.0092  time: 0.6070  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 650/1125]  eta: 0:04:40  lr: 0.000017  loss: 0.0282  time: 0.5925  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 700/1125]  eta: 0:04:10  lr: 0.000017  loss: 0.0218  time: 0.5821  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 750/1125]  eta: 0:03:41  lr: 0.000017  loss: 0.0046  time: 0.5799  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 800/1125]  eta: 0:03:11  lr: 0.000017  loss: 0.0159  time: 0.5972  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 850/1125]  eta: 0:02:42  lr: 0.000017  loss: 0.0951  time: 0.5867  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 900/1125]  eta: 0:02:12  lr: 0.000017  loss: 0.0091  time: 0.5789  data: 0.0001  max mem: 15656
Train Epoch: [2]  [ 950/1125]  eta: 0:01:43  lr: 0.000017  loss: 0.0132  time: 0.5888  data: 0.0001  max mem: 15656
Train Epoch: [2]  [1000/1125]  eta: 0:01:13  lr: 0.000017  loss: 0.0183  time: 0.5959  data: 0.0001  max mem: 15656
Train Epoch: [2]  [1050/1125]  eta: 0:00:44  lr: 0.000017  loss: 0.1457  time: 0.5851  data: 0.0001  max mem: 15656
Train Epoch: [2]  [1100/1125]  eta: 0:00:14  lr: 0.000017  loss: 0.2045  time: 0.5826  data: 0.0001  max mem: 15656
Train Epoch: [2]  [1124/1125]  eta: 0:00:00  lr: 0.000017  loss: 0.0035  time: 0.5811  data: 0.0002  max mem: 15656
Train Epoch: [2] Total time: 0:11:02 (0.5888 s / it)
Averaged stats: lr: 0.0000  loss: 0.0529
Generate VQA test result:  [  0/563]  eta: 0:05:09    time: 0.5506  data: 0.3190  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2092  data: 0.0002  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2075  data: 0.0002  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2082  data: 0.0001  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2087  data: 0.0001  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2076  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2077  data: 0.0001  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2086  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2080  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2079  data: 0.0001  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2077  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2064  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2086 s / it)
0.9840142095914742
Train Epoch: [3]  [   0/1125]  eta: 0:38:15  lr: 0.000014  loss: 0.0027  time: 2.0405  data: 1.2020  max mem: 15656
Train Epoch: [3]  [  50/1125]  eta: 0:11:06  lr: 0.000014  loss: 0.3423  time: 0.5915  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 100/1125]  eta: 0:10:19  lr: 0.000014  loss: 0.0031  time: 0.5820  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 150/1125]  eta: 0:09:45  lr: 0.000014  loss: 0.0033  time: 0.5978  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 200/1125]  eta: 0:09:13  lr: 0.000014  loss: 0.0600  time: 0.5914  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 250/1125]  eta: 0:08:41  lr: 0.000014  loss: 0.0060  time: 0.5814  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 300/1125]  eta: 0:08:10  lr: 0.000014  loss: 0.0027  time: 0.5812  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 350/1125]  eta: 0:07:39  lr: 0.000014  loss: 0.0263  time: 0.5839  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 400/1125]  eta: 0:07:09  lr: 0.000014  loss: 0.0816  time: 0.5965  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 450/1125]  eta: 0:06:39  lr: 0.000014  loss: 0.0038  time: 0.5924  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 500/1125]  eta: 0:06:09  lr: 0.000014  loss: 0.0573  time: 0.5878  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 550/1125]  eta: 0:05:40  lr: 0.000014  loss: 0.0041  time: 0.5850  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 600/1125]  eta: 0:05:10  lr: 0.000014  loss: 0.0010  time: 0.5890  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 650/1125]  eta: 0:04:40  lr: 0.000014  loss: 0.0139  time: 0.5852  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 700/1125]  eta: 0:04:10  lr: 0.000014  loss: 0.0066  time: 0.5882  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 750/1125]  eta: 0:03:41  lr: 0.000014  loss: 0.0056  time: 0.5898  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 800/1125]  eta: 0:03:11  lr: 0.000014  loss: 0.0047  time: 0.5943  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 850/1125]  eta: 0:02:42  lr: 0.000014  loss: 0.0090  time: 0.5928  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 900/1125]  eta: 0:02:12  lr: 0.000014  loss: 0.2305  time: 0.5880  data: 0.0001  max mem: 15656
Train Epoch: [3]  [ 950/1125]  eta: 0:01:43  lr: 0.000014  loss: 0.1033  time: 0.5945  data: 0.0001  max mem: 15656
Train Epoch: [3]  [1000/1125]  eta: 0:01:13  lr: 0.000014  loss: 0.0075  time: 0.5896  data: 0.0001  max mem: 15656
Train Epoch: [3]  [1050/1125]  eta: 0:00:44  lr: 0.000014  loss: 0.0096  time: 0.5862  data: 0.0001  max mem: 15656
Train Epoch: [3]  [1100/1125]  eta: 0:00:14  lr: 0.000014  loss: 0.0101  time: 0.5787  data: 0.0001  max mem: 15656
Train Epoch: [3]  [1124/1125]  eta: 0:00:00  lr: 0.000014  loss: 0.0233  time: 0.5717  data: 0.0001  max mem: 15656
Train Epoch: [3] Total time: 0:11:04 (0.5904 s / it)
Averaged stats: lr: 0.0000  loss: 0.0360
Generate VQA test result:  [  0/563]  eta: 0:05:24    time: 0.5764  data: 0.3516  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2073  data: 0.0001  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2079  data: 0.0001  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2082  data: 0.0002  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2089  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2080  data: 0.0001  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2082  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2084  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2080  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2081  data: 0.0001  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2074  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2063  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2088 s / it)
0.9849023090586145
Train Epoch: [4]  [   0/1125]  eta: 0:33:12  lr: 0.000011  loss: 0.0107  time: 1.7712  data: 0.9355  max mem: 15656
Train Epoch: [4]  [  50/1125]  eta: 0:10:46  lr: 0.000011  loss: 0.0535  time: 0.5774  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 100/1125]  eta: 0:10:04  lr: 0.000011  loss: 0.0009  time: 0.5788  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 150/1125]  eta: 0:09:37  lr: 0.000011  loss: 0.0004  time: 0.5999  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 200/1125]  eta: 0:09:07  lr: 0.000011  loss: 0.0079  time: 0.5952  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 250/1125]  eta: 0:08:38  lr: 0.000011  loss: 0.0026  time: 0.5924  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 300/1125]  eta: 0:08:08  lr: 0.000011  loss: 0.0008  time: 0.5891  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 350/1125]  eta: 0:07:38  lr: 0.000011  loss: 0.0005  time: 0.5845  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 400/1125]  eta: 0:07:07  lr: 0.000011  loss: 0.0103  time: 0.5820  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 450/1125]  eta: 0:06:38  lr: 0.000011  loss: 0.0009  time: 0.5960  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 500/1125]  eta: 0:06:08  lr: 0.000011  loss: 0.0088  time: 0.5853  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 550/1125]  eta: 0:05:39  lr: 0.000011  loss: 0.0035  time: 0.5849  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 600/1125]  eta: 0:05:09  lr: 0.000011  loss: 0.1345  time: 0.5852  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 650/1125]  eta: 0:04:39  lr: 0.000011  loss: 0.0015  time: 0.5867  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 700/1125]  eta: 0:04:10  lr: 0.000011  loss: 0.0005  time: 0.5926  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 750/1125]  eta: 0:03:41  lr: 0.000011  loss: 0.0015  time: 0.5937  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 800/1125]  eta: 0:03:11  lr: 0.000011  loss: 0.0004  time: 0.5844  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 850/1125]  eta: 0:02:42  lr: 0.000011  loss: 0.0005  time: 0.5898  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 900/1125]  eta: 0:02:12  lr: 0.000011  loss: 0.0026  time: 0.5902  data: 0.0001  max mem: 15656
Train Epoch: [4]  [ 950/1125]  eta: 0:01:43  lr: 0.000011  loss: 0.0004  time: 0.5893  data: 0.0001  max mem: 15656
Train Epoch: [4]  [1000/1125]  eta: 0:01:13  lr: 0.000011  loss: 0.0089  time: 0.5859  data: 0.0001  max mem: 15656
Train Epoch: [4]  [1050/1125]  eta: 0:00:44  lr: 0.000011  loss: 0.0006  time: 0.5876  data: 0.0001  max mem: 15656
Train Epoch: [4]  [1100/1125]  eta: 0:00:14  lr: 0.000011  loss: 0.0010  time: 0.5934  data: 0.0001  max mem: 15656
Train Epoch: [4]  [1124/1125]  eta: 0:00:00  lr: 0.000011  loss: 0.0348  time: 0.5742  data: 0.0001  max mem: 15656
Train Epoch: [4] Total time: 0:11:02 (0.5889 s / it)
Averaged stats: lr: 0.0000  loss: 0.0179
Generate VQA test result:  [  0/563]  eta: 0:05:20    time: 0.5691  data: 0.3445  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2090  data: 0.0001  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2096  data: 0.0001  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2083  data: 0.0001  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2084  data: 0.0001  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2081  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2085  data: 0.0001  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2092  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2085  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2081  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2081  data: 0.0001  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2080  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2067  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2094 s / it)
0.991785079928952
Train Epoch: [5]  [   0/1125]  eta: 0:33:24  lr: 0.000007  loss: 0.0028  time: 1.7817  data: 0.9086  max mem: 15656
Train Epoch: [5]  [  50/1125]  eta: 0:10:49  lr: 0.000007  loss: 0.0012  time: 0.5852  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 100/1125]  eta: 0:10:13  lr: 0.000007  loss: 0.0361  time: 0.5866  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 150/1125]  eta: 0:09:42  lr: 0.000007  loss: 0.0198  time: 0.6031  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 200/1125]  eta: 0:09:12  lr: 0.000007  loss: 0.0005  time: 0.5912  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 250/1125]  eta: 0:08:40  lr: 0.000007  loss: 0.1303  time: 0.5910  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 300/1125]  eta: 0:08:11  lr: 0.000007  loss: 0.0007  time: 0.5969  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 350/1125]  eta: 0:07:40  lr: 0.000007  loss: 0.0003  time: 0.5879  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 400/1125]  eta: 0:07:09  lr: 0.000007  loss: 0.1161  time: 0.5823  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 450/1125]  eta: 0:06:39  lr: 0.000007  loss: 0.0003  time: 0.5864  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 500/1125]  eta: 0:06:09  lr: 0.000007  loss: 0.0681  time: 0.5909  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 550/1125]  eta: 0:05:40  lr: 0.000007  loss: 0.0008  time: 0.5895  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 600/1125]  eta: 0:05:10  lr: 0.000007  loss: 0.0309  time: 0.5880  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 650/1125]  eta: 0:04:40  lr: 0.000007  loss: 0.0002  time: 0.5936  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 700/1125]  eta: 0:04:11  lr: 0.000007  loss: 0.0023  time: 0.5818  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 750/1125]  eta: 0:03:41  lr: 0.000007  loss: 0.0006  time: 0.5827  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 800/1125]  eta: 0:03:11  lr: 0.000007  loss: 0.0029  time: 0.5944  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 850/1125]  eta: 0:02:42  lr: 0.000007  loss: 0.0021  time: 0.5865  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 900/1125]  eta: 0:02:12  lr: 0.000007  loss: 0.0006  time: 0.5891  data: 0.0001  max mem: 15656
Train Epoch: [5]  [ 950/1125]  eta: 0:01:43  lr: 0.000007  loss: 0.0007  time: 0.5843  data: 0.0001  max mem: 15656
Train Epoch: [5]  [1000/1125]  eta: 0:01:13  lr: 0.000007  loss: 0.0006  time: 0.5876  data: 0.0001  max mem: 15656
Train Epoch: [5]  [1050/1125]  eta: 0:00:44  lr: 0.000007  loss: 0.0004  time: 0.5909  data: 0.0001  max mem: 15656
Train Epoch: [5]  [1100/1125]  eta: 0:00:14  lr: 0.000007  loss: 0.0084  time: 0.5886  data: 0.0001  max mem: 15656
Train Epoch: [5]  [1124/1125]  eta: 0:00:00  lr: 0.000007  loss: 0.0075  time: 0.5725  data: 0.0002  max mem: 15656
Train Epoch: [5] Total time: 0:11:04 (0.5904 s / it)
Averaged stats: lr: 0.0000  loss: 0.0127
Generate VQA test result:  [  0/563]  eta: 0:05:21    time: 0.5714  data: 0.3434  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2072  data: 0.0001  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2070  data: 0.0001  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2074  data: 0.0001  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2069  data: 0.0001  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2067  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2073  data: 0.0001  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2068  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2069  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2074  data: 0.0001  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2070  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2056  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2079 s / it)
0.9966696269982238
Train Epoch: [6]  [   0/1125]  eta: 0:34:24  lr: 0.000004  loss: 0.0007  time: 1.8353  data: 1.0759  max mem: 15656
Train Epoch: [6]  [  50/1125]  eta: 0:10:59  lr: 0.000004  loss: 0.0004  time: 0.5966  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 100/1125]  eta: 0:10:11  lr: 0.000004  loss: 0.0007  time: 0.5766  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 150/1125]  eta: 0:09:38  lr: 0.000004  loss: 0.0011  time: 0.5908  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 200/1125]  eta: 0:09:08  lr: 0.000004  loss: 0.0009  time: 0.5958  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 250/1125]  eta: 0:08:38  lr: 0.000004  loss: 0.0004  time: 0.5899  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 300/1125]  eta: 0:08:07  lr: 0.000004  loss: 0.0005  time: 0.5818  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 350/1125]  eta: 0:07:37  lr: 0.000004  loss: 0.0005  time: 0.5944  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 400/1125]  eta: 0:07:07  lr: 0.000004  loss: 0.0007  time: 0.5793  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 450/1125]  eta: 0:06:37  lr: 0.000004  loss: 0.0022  time: 0.5903  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 500/1125]  eta: 0:06:07  lr: 0.000004  loss: 0.0087  time: 0.5841  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 550/1125]  eta: 0:05:38  lr: 0.000004  loss: 0.0007  time: 0.5955  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 600/1125]  eta: 0:05:08  lr: 0.000004  loss: 0.0004  time: 0.5912  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 650/1125]  eta: 0:04:39  lr: 0.000004  loss: 0.0005  time: 0.5905  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 700/1125]  eta: 0:04:09  lr: 0.000004  loss: 0.0038  time: 0.5902  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 750/1125]  eta: 0:03:40  lr: 0.000004  loss: 0.0011  time: 0.5863  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 800/1125]  eta: 0:03:10  lr: 0.000004  loss: 0.0005  time: 0.5825  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 850/1125]  eta: 0:02:41  lr: 0.000004  loss: 0.0014  time: 0.5792  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 900/1125]  eta: 0:02:12  lr: 0.000004  loss: 0.0002  time: 0.5841  data: 0.0001  max mem: 15656
Train Epoch: [6]  [ 950/1125]  eta: 0:01:42  lr: 0.000004  loss: 0.0009  time: 0.5886  data: 0.0001  max mem: 15656
Train Epoch: [6]  [1000/1125]  eta: 0:01:13  lr: 0.000004  loss: 0.0009  time: 0.5881  data: 0.0001  max mem: 15656
Train Epoch: [6]  [1050/1125]  eta: 0:00:44  lr: 0.000004  loss: 0.0012  time: 0.6004  data: 0.0001  max mem: 15656
Train Epoch: [6]  [1100/1125]  eta: 0:00:14  lr: 0.000004  loss: 0.1373  time: 0.5822  data: 0.0001  max mem: 15656
Train Epoch: [6]  [1124/1125]  eta: 0:00:00  lr: 0.000004  loss: 0.0005  time: 0.5780  data: 0.0002  max mem: 15656
Train Epoch: [6] Total time: 0:11:00 (0.5874 s / it)
Averaged stats: lr: 0.0000  loss: 0.0093
Generate VQA test result:  [  0/563]  eta: 0:05:33    time: 0.5931  data: 0.3618  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2077  data: 0.0001  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2078  data: 0.0002  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2083  data: 0.0001  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2077  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2081  data: 0.0001  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2083  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2079  data: 0.0001  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2071  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2057  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2085 s / it)
0.9975577264653641
Train Epoch: [7]  [   0/1125]  eta: 0:33:01  lr: 0.000002  loss: 0.0007  time: 1.7616  data: 1.0199  max mem: 15656
Train Epoch: [7]  [  50/1125]  eta: 0:10:55  lr: 0.000002  loss: 0.0006  time: 0.5874  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 100/1125]  eta: 0:10:13  lr: 0.000002  loss: 0.0005  time: 0.5841  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 150/1125]  eta: 0:09:38  lr: 0.000002  loss: 0.0010  time: 0.5841  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 200/1125]  eta: 0:09:08  lr: 0.000002  loss: 0.0015  time: 0.5900  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 250/1125]  eta: 0:08:37  lr: 0.000002  loss: 0.0008  time: 0.5867  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 300/1125]  eta: 0:08:07  lr: 0.000002  loss: 0.0006  time: 0.5839  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 350/1125]  eta: 0:07:37  lr: 0.000002  loss: 0.0033  time: 0.5878  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 400/1125]  eta: 0:07:08  lr: 0.000002  loss: 0.0004  time: 0.5941  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 450/1125]  eta: 0:06:38  lr: 0.000002  loss: 0.0030  time: 0.5852  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 500/1125]  eta: 0:06:08  lr: 0.000002  loss: 0.0005  time: 0.5821  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 550/1125]  eta: 0:05:39  lr: 0.000002  loss: 0.0004  time: 0.5855  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 600/1125]  eta: 0:05:09  lr: 0.000002  loss: 0.0026  time: 0.5854  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 650/1125]  eta: 0:04:39  lr: 0.000002  loss: 0.0003  time: 0.5846  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 700/1125]  eta: 0:04:10  lr: 0.000002  loss: 0.0004  time: 0.5850  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 750/1125]  eta: 0:03:40  lr: 0.000002  loss: 0.0003  time: 0.5881  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 800/1125]  eta: 0:03:11  lr: 0.000002  loss: 0.0003  time: 0.5920  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 850/1125]  eta: 0:02:41  lr: 0.000002  loss: 0.0004  time: 0.5821  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 900/1125]  eta: 0:02:12  lr: 0.000002  loss: 0.0006  time: 0.5842  data: 0.0001  max mem: 15656
Train Epoch: [7]  [ 950/1125]  eta: 0:01:42  lr: 0.000002  loss: 0.0004  time: 0.5840  data: 0.0001  max mem: 15656
Train Epoch: [7]  [1000/1125]  eta: 0:01:13  lr: 0.000002  loss: 0.0001  time: 0.5876  data: 0.0001  max mem: 15656
Train Epoch: [7]  [1050/1125]  eta: 0:00:44  lr: 0.000002  loss: 0.0005  time: 0.5973  data: 0.0001  max mem: 15656
Train Epoch: [7]  [1100/1125]  eta: 0:00:14  lr: 0.000002  loss: 0.0005  time: 0.5899  data: 0.0001  max mem: 15656
Train Epoch: [7]  [1124/1125]  eta: 0:00:00  lr: 0.000002  loss: 0.0112  time: 0.5708  data: 0.0002  max mem: 15656
Train Epoch: [7] Total time: 0:11:01 (0.5882 s / it)
Averaged stats: lr: 0.0000  loss: 0.0056
Generate VQA test result:  [  0/563]  eta: 0:05:11    time: 0.5535  data: 0.3137  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2086  data: 0.0001  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2090  data: 0.0002  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2087  data: 0.0001  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2083  data: 0.0001  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2084  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2084  data: 0.0001  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2085  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2085  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2083  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2086  data: 0.0002  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2091  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2072  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2093 s / it)
0.9975577264653641
Generate VQA test result:  [  0/563]  eta: 0:05:06    time: 0.5447  data: 0.3219  max mem: 15656
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2078  data: 0.0001  max mem: 15656
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2079  data: 0.0001  max mem: 15656
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2080  data: 0.0001  max mem: 15656
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2086  data: 0.0001  max mem: 15656
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2078  data: 0.0001  max mem: 15656
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2083  data: 0.0002  max mem: 15656
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2084  data: 0.0001  max mem: 15656
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2074  data: 0.0001  max mem: 15656
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2071  data: 0.0001  max mem: 15656
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2075  data: 0.0001  max mem: 15656
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2081  data: 0.0001  max mem: 15656
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2067  data: 0.0001  max mem: 15656
Generate VQA test result: Total time: 0:01:57 (0.2088 s / it)
result file saved to output_optimal/vqa/result/vqa_result_epoch7.json
Training time 1:46:56