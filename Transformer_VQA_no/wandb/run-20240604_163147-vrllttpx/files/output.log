Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['text_encoder.encoder.layer.12.attention.self.query.weight', 'text_encoder.encoder.layer.12.attention.self.query.bias', 'text_encoder.encoder.layer.12.attention.self.key.weight', 'text_encoder.encoder.layer.12.attention.self.key.bias', 'text_encoder.encoder.layer.12.attention.self.value.weight', 'text_encoder.encoder.layer.12.attention.self.value.bias', 'text_encoder.encoder.layer.12.attention.output.dense.weight', 'text_encoder.encoder.layer.12.attention.output.dense.bias', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.crossattention.self.query.weight', 'text_encoder.encoder.layer.12.crossattention.self.query.bias', 'text_encoder.encoder.layer.12.crossattention.self.key.weight', 'text_encoder.encoder.layer.12.crossattention.self.key.bias', 'text_encoder.encoder.layer.12.crossattention.self.value.weight', 'text_encoder.encoder.layer.12.crossattention.self.value.bias', 'text_encoder.encoder.layer.12.crossattention.output.dense.weight', 'text_encoder.encoder.layer.12.crossattention.output.dense.bias', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.intermediate.dense.weight', 'text_encoder.encoder.layer.12.intermediate.dense.bias', 'text_encoder.encoder.layer.12.output.dense.weight', 'text_encoder.encoder.layer.12.output.dense.bias', 'text_encoder.encoder.layer.12.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.attention.self.query.weight', 'text_encoder.encoder.layer.13.attention.self.query.bias', 'text_encoder.encoder.layer.13.attention.self.key.weight', 'text_encoder.encoder.layer.13.attention.self.key.bias', 'text_encoder.encoder.layer.13.attention.self.value.weight', 'text_encoder.encoder.layer.13.attention.self.value.bias', 'text_encoder.encoder.layer.13.attention.output.dense.weight', 'text_encoder.encoder.layer.13.attention.output.dense.bias', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.crossattention.self.query.weight', 'text_encoder.encoder.layer.13.crossattention.self.query.bias', 'text_encoder.encoder.layer.13.crossattention.self.key.weight', 'text_encoder.encoder.layer.13.crossattention.self.key.bias', 'text_encoder.encoder.layer.13.crossattention.self.value.weight', 'text_encoder.encoder.layer.13.crossattention.self.value.bias', 'text_encoder.encoder.layer.13.crossattention.output.dense.weight', 'text_encoder.encoder.layer.13.crossattention.output.dense.bias', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.intermediate.dense.weight', 'text_encoder.encoder.layer.13.intermediate.dense.bias', 'text_encoder.encoder.layer.13.output.dense.weight', 'text_encoder.encoder.layer.13.output.dense.bias', 'text_encoder.encoder.layer.13.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.attention.self.query.weight', 'text_encoder.encoder.layer.14.attention.self.query.bias', 'text_encoder.encoder.layer.14.attention.self.key.weight', 'text_encoder.encoder.layer.14.attention.self.key.bias', 'text_encoder.encoder.layer.14.attention.self.value.weight', 'text_encoder.encoder.layer.14.attention.self.value.bias', 'text_encoder.encoder.layer.14.attention.output.dense.weight', 'text_encoder.encoder.layer.14.attention.output.dense.bias', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.crossattention.self.query.weight', 'text_encoder.encoder.layer.14.crossattention.self.query.bias', 'text_encoder.encoder.layer.14.crossattention.self.key.weight', 'text_encoder.encoder.layer.14.crossattention.self.key.bias', 'text_encoder.encoder.layer.14.crossattention.self.value.weight', 'text_encoder.encoder.layer.14.crossattention.self.value.bias', 'text_encoder.encoder.layer.14.crossattention.output.dense.weight', 'text_encoder.encoder.layer.14.crossattention.output.dense.bias', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.intermediate.dense.weight', 'text_encoder.encoder.layer.14.intermediate.dense.bias', 'text_encoder.encoder.layer.14.output.dense.weight', 'text_encoder.encoder.layer.14.output.dense.bias', 'text_encoder.encoder.layer.14.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.attention.self.query.weight', 'text_encoder.encoder.layer.15.attention.self.query.bias', 'text_encoder.encoder.layer.15.attention.self.key.weight', 'text_encoder.encoder.layer.15.attention.self.key.bias', 'text_encoder.encoder.layer.15.attention.self.value.weight', 'text_encoder.encoder.layer.15.attention.self.value.bias', 'text_encoder.encoder.layer.15.attention.output.dense.weight', 'text_encoder.encoder.layer.15.attention.output.dense.bias', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.crossattention.self.query.weight', 'text_encoder.encoder.layer.15.crossattention.self.query.bias', 'text_encoder.encoder.layer.15.crossattention.self.key.weight', 'text_encoder.encoder.layer.15.crossattention.self.key.bias', 'text_encoder.encoder.layer.15.crossattention.self.value.weight', 'text_encoder.encoder.layer.15.crossattention.self.value.bias', 'text_encoder.encoder.layer.15.crossattention.output.dense.weight', 'text_encoder.encoder.layer.15.crossattention.output.dense.bias', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.intermediate.dense.weight', 'text_encoder.encoder.layer.15.intermediate.dense.bias', 'text_encoder.encoder.layer.15.output.dense.weight', 'text_encoder.encoder.layer.15.output.dense.bias', 'text_encoder.encoder.layer.15.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.output.LayerNorm.bias', 'inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [   0/1125]  eta: 0:54:21  lr: 0.000010  loss: 1.6340  time: 2.8991  data: 1.2536  max mem: 11560
Train Epoch: [0]  [  50/1125]  eta: 0:11:18  lr: 0.000010  loss: 0.4727  time: 0.5868  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 100/1125]  eta: 0:10:26  lr: 0.000010  loss: 0.5317  time: 0.5911  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 150/1125]  eta: 0:09:47  lr: 0.000012  loss: 0.2808  time: 0.5767  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 200/1125]  eta: 0:09:12  lr: 0.000012  loss: 0.3142  time: 0.5818  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 250/1125]  eta: 0:08:40  lr: 0.000014  loss: 0.2858  time: 0.5806  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 300/1125]  eta: 0:08:09  lr: 0.000014  loss: 0.4000  time: 0.5917  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 350/1125]  eta: 0:07:40  lr: 0.000016  loss: 0.3063  time: 0.5937  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 400/1125]  eta: 0:07:10  lr: 0.000016  loss: 0.4183  time: 0.5982  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 450/1125]  eta: 0:06:40  lr: 0.000018  loss: 0.2622  time: 0.5957  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 500/1125]  eta: 0:06:10  lr: 0.000018  loss: 0.3028  time: 0.5854  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 550/1125]  eta: 0:05:40  lr: 0.000018  loss: 0.1089  time: 0.5929  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 600/1125]  eta: 0:05:10  lr: 0.000018  loss: 0.1907  time: 0.5917  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 650/1125]  eta: 0:04:40  lr: 0.000018  loss: 0.1425  time: 0.5819  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 700/1125]  eta: 0:04:11  lr: 0.000018  loss: 0.1559  time: 0.5838  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 750/1125]  eta: 0:03:41  lr: 0.000018  loss: 0.3099  time: 0.5944  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 800/1125]  eta: 0:03:12  lr: 0.000018  loss: 0.2168  time: 0.5916  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 850/1125]  eta: 0:02:42  lr: 0.000018  loss: 0.2127  time: 0.5844  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 900/1125]  eta: 0:02:12  lr: 0.000018  loss: 0.1068  time: 0.5864  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 950/1125]  eta: 0:01:43  lr: 0.000018  loss: 0.1427  time: 0.5889  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1000/1125]  eta: 0:01:13  lr: 0.000018  loss: 0.1135  time: 0.5954  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1050/1125]  eta: 0:00:44  lr: 0.000018  loss: 0.1486  time: 0.5883  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1100/1125]  eta: 0:00:14  lr: 0.000018  loss: 0.0928  time: 0.5785  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1124/1125]  eta: 0:00:00  lr: 0.000018  loss: 0.1973  time: 0.5778  data: 0.0002  max mem: 15660
Train Epoch: [0] Total time: 0:11:03 (0.5896 s / it)
Averaged stats: lr: 0.0000  loss: 0.2585
Generate VQA test result:  [  0/563]  eta: 0:08:16    time: 0.8816  data: 0.3528  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:54    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:40    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:28    time: 0.2125  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:17    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2106  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2112  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:45    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2104  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2093  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2112 s / it)
0.9245115452930728
Train Epoch: [1]  [   0/1125]  eta: 0:37:32  lr: 0.000008  loss: 0.2471  time: 2.0025  data: 0.9786  max mem: 15660
Train Epoch: [1]  [  50/1125]  eta: 0:10:59  lr: 0.000008  loss: 0.0532  time: 0.5910  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 100/1125]  eta: 0:10:19  lr: 0.000008  loss: 0.0310  time: 0.5933  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 150/1125]  eta: 0:09:44  lr: 0.000008  loss: 0.0299  time: 0.5980  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 200/1125]  eta: 0:09:12  lr: 0.000008  loss: 0.0385  time: 0.5919  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 250/1125]  eta: 0:08:41  lr: 0.000008  loss: 0.0276  time: 0.5927  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 300/1125]  eta: 0:08:11  lr: 0.000008  loss: 0.0227  time: 0.5950  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 350/1125]  eta: 0:07:41  lr: 0.000008  loss: 0.0651  time: 0.5850  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 400/1125]  eta: 0:07:10  lr: 0.000008  loss: 0.0092  time: 0.5921  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 450/1125]  eta: 0:06:41  lr: 0.000008  loss: 0.0208  time: 0.5923  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 500/1125]  eta: 0:06:11  lr: 0.000008  loss: 0.0386  time: 0.5970  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 550/1125]  eta: 0:05:41  lr: 0.000008  loss: 0.0211  time: 0.5901  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 600/1125]  eta: 0:05:12  lr: 0.000008  loss: 0.0701  time: 0.5964  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 650/1125]  eta: 0:04:42  lr: 0.000008  loss: 0.0369  time: 0.5930  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 700/1125]  eta: 0:04:12  lr: 0.000008  loss: 0.0527  time: 0.5942  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 750/1125]  eta: 0:03:42  lr: 0.000008  loss: 0.0059  time: 0.5958  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 800/1125]  eta: 0:03:13  lr: 0.000008  loss: 0.0100  time: 0.5916  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 850/1125]  eta: 0:02:43  lr: 0.000008  loss: 0.0116  time: 0.5939  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 900/1125]  eta: 0:02:13  lr: 0.000008  loss: 0.0443  time: 0.5934  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 950/1125]  eta: 0:01:43  lr: 0.000008  loss: 0.0722  time: 0.5840  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1000/1125]  eta: 0:01:14  lr: 0.000008  loss: 0.1572  time: 0.6010  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1050/1125]  eta: 0:00:44  lr: 0.000008  loss: 0.0045  time: 0.5896  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1100/1125]  eta: 0:00:14  lr: 0.000008  loss: 0.0946  time: 0.5816  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1124/1125]  eta: 0:00:00  lr: 0.000008  loss: 0.0379  time: 0.5737  data: 0.0002  max mem: 15660
Train Epoch: [1] Total time: 0:11:06 (0.5927 s / it)
Averaged stats: lr: 0.0000  loss: 0.0641
Generate VQA test result:  [  0/563]  eta: 0:05:21    time: 0.5705  data: 0.3366  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:51    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2093  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2101  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2101  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2105  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2099  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2105 s / it)
0.9840142095914742
Train Epoch: [2]  [   0/1125]  eta: 0:32:24  lr: 0.000002  loss: 0.0402  time: 1.7286  data: 0.8912  max mem: 15660
Train Epoch: [2]  [  50/1125]  eta: 0:10:59  lr: 0.000002  loss: 0.0149  time: 0.5932  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 100/1125]  eta: 0:10:18  lr: 0.000002  loss: 0.0279  time: 0.5932  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 150/1125]  eta: 0:09:45  lr: 0.000002  loss: 0.0051  time: 0.5938  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 200/1125]  eta: 0:09:12  lr: 0.000002  loss: 0.0223  time: 0.5880  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 250/1125]  eta: 0:08:41  lr: 0.000002  loss: 0.0041  time: 0.5880  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 300/1125]  eta: 0:08:11  lr: 0.000002  loss: 0.0026  time: 0.5902  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 350/1125]  eta: 0:07:40  lr: 0.000002  loss: 0.0027  time: 0.5825  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 400/1125]  eta: 0:07:10  lr: 0.000002  loss: 0.0059  time: 0.5825  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 450/1125]  eta: 0:06:39  lr: 0.000002  loss: 0.0019  time: 0.5768  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 500/1125]  eta: 0:06:09  lr: 0.000002  loss: 0.0015  time: 0.5906  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 550/1125]  eta: 0:05:39  lr: 0.000002  loss: 0.0551  time: 0.5828  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 600/1125]  eta: 0:05:10  lr: 0.000002  loss: 0.0072  time: 0.5860  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 650/1125]  eta: 0:04:40  lr: 0.000002  loss: 0.0031  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 700/1125]  eta: 0:04:11  lr: 0.000002  loss: 0.0608  time: 0.5906  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 750/1125]  eta: 0:03:41  lr: 0.000002  loss: 0.0035  time: 0.5914  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 800/1125]  eta: 0:03:11  lr: 0.000002  loss: 0.0023  time: 0.5803  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 850/1125]  eta: 0:02:42  lr: 0.000002  loss: 0.0825  time: 0.5895  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 900/1125]  eta: 0:02:12  lr: 0.000002  loss: 0.0013  time: 0.5784  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 950/1125]  eta: 0:01:43  lr: 0.000002  loss: 0.0307  time: 0.5836  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1000/1125]  eta: 0:01:13  lr: 0.000002  loss: 0.0026  time: 0.5961  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1050/1125]  eta: 0:00:44  lr: 0.000002  loss: 0.1927  time: 0.5894  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1100/1125]  eta: 0:00:14  lr: 0.000002  loss: 0.1085  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1124/1125]  eta: 0:00:00  lr: 0.000002  loss: 0.0180  time: 0.5804  data: 0.0002  max mem: 15660
Train Epoch: [2] Total time: 0:11:03 (0.5895 s / it)
Averaged stats: lr: 0.0000  loss: 0.0227
Generate VQA test result:  [  0/563]  eta: 0:05:13    time: 0.5567  data: 0.3228  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:51    time: 0.2096  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2088  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2088  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2100  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2100 s / it)
0.9880106571936057
Train Epoch: [3]  [   0/1125]  eta: 0:28:46  lr: 0.000001  loss: 0.0020  time: 1.5346  data: 0.7320  max mem: 15660
Train Epoch: [3]  [  50/1125]  eta: 0:10:47  lr: 0.000001  loss: 0.1180  time: 0.5846  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 100/1125]  eta: 0:10:14  lr: 0.000001  loss: 0.0162  time: 0.6005  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 150/1125]  eta: 0:09:38  lr: 0.000001  loss: 0.0007  time: 0.5790  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 200/1125]  eta: 0:09:08  lr: 0.000001  loss: 0.0786  time: 0.5883  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 250/1125]  eta: 0:08:38  lr: 0.000001  loss: 0.0016  time: 0.5851  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 300/1125]  eta: 0:08:07  lr: 0.000001  loss: 0.0016  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 350/1125]  eta: 0:07:37  lr: 0.000001  loss: 0.0031  time: 0.5811  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 400/1125]  eta: 0:07:08  lr: 0.000001  loss: 0.0084  time: 0.5930  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 450/1125]  eta: 0:06:38  lr: 0.000001  loss: 0.0168  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 500/1125]  eta: 0:06:08  lr: 0.000001  loss: 0.0334  time: 0.5881  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 550/1125]  eta: 0:05:39  lr: 0.000001  loss: 0.0067  time: 0.5890  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 600/1125]  eta: 0:05:09  lr: 0.000001  loss: 0.0019  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 650/1125]  eta: 0:04:40  lr: 0.000001  loss: 0.0012  time: 0.5926  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 700/1125]  eta: 0:04:10  lr: 0.000001  loss: 0.0889  time: 0.5836  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 750/1125]  eta: 0:03:41  lr: 0.000001  loss: 0.0018  time: 0.5915  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 800/1125]  eta: 0:03:11  lr: 0.000001  loss: 0.0008  time: 0.5935  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 850/1125]  eta: 0:02:42  lr: 0.000001  loss: 0.0048  time: 0.5966  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 900/1125]  eta: 0:02:12  lr: 0.000001  loss: 0.0391  time: 0.5909  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 950/1125]  eta: 0:01:43  lr: 0.000001  loss: 0.0161  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1000/1125]  eta: 0:01:13  lr: 0.000001  loss: 0.0085  time: 0.5860  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1050/1125]  eta: 0:00:44  lr: 0.000001  loss: 0.0268  time: 0.5859  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1100/1125]  eta: 0:00:14  lr: 0.000001  loss: 0.0011  time: 0.5942  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1124/1125]  eta: 0:00:00  lr: 0.000001  loss: 0.0099  time: 0.5802  data: 0.0002  max mem: 15660
Train Epoch: [3] Total time: 0:11:03 (0.5899 s / it)
Averaged stats: lr: 0.0000  loss: 0.0201
Generate VQA test result:  [  0/563]  eta: 0:05:02    time: 0.5366  data: 0.3118  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:51    time: 0.2100  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2101  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2106  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2097  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2103  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2104  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2102  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2105  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2100  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2102  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2110 s / it)
0.9960035523978685
Train Epoch: [4]  [   0/1125]  eta: 0:34:25  lr: 0.000001  loss: 0.0022  time: 1.8362  data: 0.9548  max mem: 15660
Train Epoch: [4]  [  50/1125]  eta: 0:11:02  lr: 0.000001  loss: 0.0077  time: 0.5957  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 100/1125]  eta: 0:10:19  lr: 0.000001  loss: 0.0010  time: 0.5907  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 150/1125]  eta: 0:09:42  lr: 0.000001  loss: 0.0008  time: 0.5784  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 200/1125]  eta: 0:09:11  lr: 0.000001  loss: 0.0098  time: 0.5926  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 250/1125]  eta: 0:08:41  lr: 0.000001  loss: 0.0023  time: 0.5996  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 300/1125]  eta: 0:08:11  lr: 0.000001  loss: 0.0017  time: 0.5985  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 350/1125]  eta: 0:07:42  lr: 0.000001  loss: 0.0021  time: 0.5962  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 400/1125]  eta: 0:07:12  lr: 0.000001  loss: 0.0009  time: 0.5968  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 450/1125]  eta: 0:06:41  lr: 0.000001  loss: 0.0016  time: 0.5836  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 500/1125]  eta: 0:06:11  lr: 0.000001  loss: 0.0074  time: 0.5900  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 550/1125]  eta: 0:05:41  lr: 0.000001  loss: 0.0036  time: 0.5989  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 600/1125]  eta: 0:05:11  lr: 0.000001  loss: 0.0009  time: 0.5979  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 650/1125]  eta: 0:04:42  lr: 0.000001  loss: 0.0022  time: 0.5962  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 700/1125]  eta: 0:04:12  lr: 0.000001  loss: 0.0007  time: 0.5864  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 750/1125]  eta: 0:03:42  lr: 0.000001  loss: 0.0010  time: 0.5909  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 800/1125]  eta: 0:03:12  lr: 0.000001  loss: 0.0010  time: 0.5958  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 850/1125]  eta: 0:02:43  lr: 0.000001  loss: 0.0098  time: 0.5909  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 900/1125]  eta: 0:02:13  lr: 0.000001  loss: 0.0008  time: 0.5905  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 950/1125]  eta: 0:01:43  lr: 0.000001  loss: 0.0031  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1000/1125]  eta: 0:01:14  lr: 0.000001  loss: 0.0007  time: 0.5920  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1050/1125]  eta: 0:00:44  lr: 0.000001  loss: 0.0035  time: 0.5962  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1100/1125]  eta: 0:00:14  lr: 0.000001  loss: 0.0009  time: 0.6041  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1124/1125]  eta: 0:00:00  lr: 0.000001  loss: 0.1344  time: 0.5833  data: 0.0002  max mem: 15660
Train Epoch: [4] Total time: 0:11:07 (0.5930 s / it)
Averaged stats: lr: 0.0000  loss: 0.0150
Generate VQA test result:  [  0/563]  eta: 0:05:08    time: 0.5479  data: 0.3187  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2088  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2101  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2104  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2103  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2093  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2073  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2100 s / it)
0.9944493783303731
Train Epoch: [5]  [   0/1125]  eta: 0:35:25  lr: 0.000001  loss: 0.0117  time: 1.8897  data: 1.1353  max mem: 15660
Train Epoch: [5]  [  50/1125]  eta: 0:11:06  lr: 0.000001  loss: 0.0254  time: 0.5992  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 100/1125]  eta: 0:10:18  lr: 0.000001  loss: 0.0150  time: 0.5768  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 150/1125]  eta: 0:09:42  lr: 0.000001  loss: 0.0029  time: 0.5878  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 200/1125]  eta: 0:09:12  lr: 0.000001  loss: 0.0008  time: 0.5964  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 250/1125]  eta: 0:08:41  lr: 0.000001  loss: 0.0528  time: 0.5953  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 300/1125]  eta: 0:08:10  lr: 0.000001  loss: 0.0007  time: 0.5852  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 350/1125]  eta: 0:07:40  lr: 0.000001  loss: 0.0007  time: 0.5865  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 400/1125]  eta: 0:07:10  lr: 0.000001  loss: 0.0010  time: 0.5846  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 450/1125]  eta: 0:06:40  lr: 0.000001  loss: 0.0011  time: 0.5875  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 500/1125]  eta: 0:06:10  lr: 0.000001  loss: 0.0080  time: 0.5891  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 550/1125]  eta: 0:05:40  lr: 0.000001  loss: 0.0016  time: 0.5889  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 600/1125]  eta: 0:05:10  lr: 0.000001  loss: 0.0103  time: 0.5830  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 650/1125]  eta: 0:04:40  lr: 0.000001  loss: 0.0029  time: 0.5765  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 700/1125]  eta: 0:04:11  lr: 0.000001  loss: 0.0039  time: 0.5897  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 750/1125]  eta: 0:03:41  lr: 0.000001  loss: 0.0015  time: 0.5904  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 800/1125]  eta: 0:03:12  lr: 0.000001  loss: 0.0007  time: 0.5913  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 850/1125]  eta: 0:02:42  lr: 0.000001  loss: 0.0022  time: 0.5895  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 900/1125]  eta: 0:02:12  lr: 0.000001  loss: 0.0006  time: 0.5860  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 950/1125]  eta: 0:01:43  lr: 0.000001  loss: 0.0018  time: 0.5867  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1000/1125]  eta: 0:01:13  lr: 0.000001  loss: 0.0013  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1050/1125]  eta: 0:00:44  lr: 0.000001  loss: 0.0011  time: 0.5855  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1100/1125]  eta: 0:00:14  lr: 0.000001  loss: 0.0047  time: 0.5882  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1124/1125]  eta: 0:00:00  lr: 0.000001  loss: 0.0042  time: 0.5821  data: 0.0002  max mem: 15660
Train Epoch: [5] Total time: 0:11:03 (0.5896 s / it)
Averaged stats: lr: 0.0000  loss: 0.0143
Generate VQA test result:  [  0/563]  eta: 0:05:15    time: 0.5603  data: 0.3293  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:51    time: 0.2097  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:39    time: 0.2096  data: 0.0002  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2097  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2106  data: 0.0002  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2101  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2104  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2102  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2102  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2109 s / it)
0.9942273534635879
Train Epoch: [6]  [   0/1125]  eta: 0:34:55  lr: 0.000001  loss: 0.0012  time: 1.8629  data: 0.9324  max mem: 15660
Train Epoch: [6]  [  50/1125]  eta: 0:10:52  lr: 0.000001  loss: 0.0015  time: 0.5896  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 100/1125]  eta: 0:10:12  lr: 0.000001  loss: 0.0012  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 150/1125]  eta: 0:09:41  lr: 0.000001  loss: 0.0029  time: 0.5993  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 200/1125]  eta: 0:09:10  lr: 0.000001  loss: 0.0006  time: 0.5939  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 250/1125]  eta: 0:08:40  lr: 0.000001  loss: 0.0007  time: 0.5983  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 300/1125]  eta: 0:08:09  lr: 0.000001  loss: 0.0008  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 350/1125]  eta: 0:07:40  lr: 0.000001  loss: 0.0011  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 400/1125]  eta: 0:07:09  lr: 0.000001  loss: 0.0006  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 450/1125]  eta: 0:06:39  lr: 0.000001  loss: 0.0018  time: 0.5848  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 500/1125]  eta: 0:06:10  lr: 0.000001  loss: 0.0208  time: 0.5920  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 550/1125]  eta: 0:05:39  lr: 0.000001  loss: 0.0011  time: 0.5854  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 600/1125]  eta: 0:05:10  lr: 0.000001  loss: 0.0011  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 650/1125]  eta: 0:04:40  lr: 0.000001  loss: 0.0022  time: 0.5948  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 700/1125]  eta: 0:04:11  lr: 0.000001  loss: 0.0028  time: 0.5903  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 750/1125]  eta: 0:03:41  lr: 0.000001  loss: 0.0276  time: 0.5942  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 800/1125]  eta: 0:03:12  lr: 0.000001  loss: 0.0006  time: 0.5889  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 850/1125]  eta: 0:02:42  lr: 0.000001  loss: 0.0009  time: 0.5809  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 900/1125]  eta: 0:02:12  lr: 0.000001  loss: 0.0002  time: 0.5770  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 950/1125]  eta: 0:01:43  lr: 0.000001  loss: 0.0012  time: 0.5841  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1000/1125]  eta: 0:01:13  lr: 0.000001  loss: 0.0008  time: 0.6031  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1050/1125]  eta: 0:00:44  lr: 0.000001  loss: 0.0006  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1100/1125]  eta: 0:00:14  lr: 0.000001  loss: 0.1881  time: 0.5999  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1124/1125]  eta: 0:00:00  lr: 0.000001  loss: 0.0024  time: 0.5732  data: 0.0002  max mem: 15660
Train Epoch: [6] Total time: 0:11:04 (0.5903 s / it)
Averaged stats: lr: 0.0000  loss: 0.0144
Generate VQA test result:  [  0/563]  eta: 0:04:58    time: 0.5306  data: 0.3022  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2093  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2098  data: 0.0002  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2100  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2099 s / it)
0.9960035523978685
Train Epoch: [7]  [   0/1125]  eta: 0:34:39  lr: 0.000001  loss: 0.0007  time: 1.8488  data: 0.9569  max mem: 15660
Train Epoch: [7]  [  50/1125]  eta: 0:10:54  lr: 0.000001  loss: 0.0017  time: 0.5807  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 100/1125]  eta: 0:10:13  lr: 0.000001  loss: 0.0004  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 150/1125]  eta: 0:09:42  lr: 0.000001  loss: 0.0261  time: 0.5942  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 200/1125]  eta: 0:09:09  lr: 0.000001  loss: 0.0023  time: 0.5858  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 250/1125]  eta: 0:08:38  lr: 0.000001  loss: 0.0106  time: 0.5891  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 300/1125]  eta: 0:08:07  lr: 0.000001  loss: 0.0308  time: 0.5838  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 350/1125]  eta: 0:07:38  lr: 0.000001  loss: 0.0218  time: 0.5941  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 400/1125]  eta: 0:07:09  lr: 0.000001  loss: 0.0007  time: 0.5952  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 450/1125]  eta: 0:06:39  lr: 0.000001  loss: 0.0095  time: 0.5805  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 500/1125]  eta: 0:06:09  lr: 0.000001  loss: 0.0010  time: 0.5879  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 550/1125]  eta: 0:05:39  lr: 0.000001  loss: 0.0009  time: 0.5994  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 600/1125]  eta: 0:05:10  lr: 0.000001  loss: 0.0007  time: 0.5943  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 650/1125]  eta: 0:04:40  lr: 0.000001  loss: 0.0020  time: 0.5862  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 700/1125]  eta: 0:04:11  lr: 0.000001  loss: 0.0010  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 750/1125]  eta: 0:03:41  lr: 0.000001  loss: 0.0016  time: 0.5757  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 800/1125]  eta: 0:03:11  lr: 0.000001  loss: 0.0003  time: 0.5829  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 850/1125]  eta: 0:02:42  lr: 0.000001  loss: 0.0004  time: 0.5963  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 900/1125]  eta: 0:02:12  lr: 0.000001  loss: 0.0006  time: 0.5951  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 950/1125]  eta: 0:01:43  lr: 0.000001  loss: 0.0028  time: 0.5867  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1000/1125]  eta: 0:01:13  lr: 0.000001  loss: 0.0010  time: 0.5888  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1050/1125]  eta: 0:00:44  lr: 0.000001  loss: 0.0027  time: 0.5880  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1100/1125]  eta: 0:00:14  lr: 0.000001  loss: 0.0008  time: 0.5884  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1124/1125]  eta: 0:00:00  lr: 0.000001  loss: 0.2202  time: 0.5777  data: 0.0002  max mem: 15660
Train Epoch: [7] Total time: 0:11:03 (0.5895 s / it)
Averaged stats: lr: 0.0000  loss: 0.0119
Generate VQA test result:  [  0/563]  eta: 0:05:16    time: 0.5623  data: 0.3306  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:51    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2100  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2099  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2099  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2106  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2102  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2099  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2100  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2097  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2108 s / it)
0.9962255772646537
Generate VQA test result:  [  0/563]  eta: 0:05:19    time: 0.5675  data: 0.3355  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2090  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2088  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2099  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2098 s / it)
result file saved to output_optimal/vqa/result/vqa_result_epoch7.json
Training time 1:47:17