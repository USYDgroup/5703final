Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/output_vqa2/vqa/checkpoint_07.pth ,evaluate.
<All keys matched successfully>
Start training
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
Generate VQA test result:  [    0/26794]  eta: 6:57:50    time: 0.9357  data: 0.3224  max mem: 4164
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
tensor(123)
Traceback (most recent call last):
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 398, in <module>
    main(args, config)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 357, in main
    vqa_result = evaluation(model, test_loader, tokenizer, device, config)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 140, in evaluation
    topk_ids, topk_probs = model(image, question_input, answer_input, train=False, k=config['k_test'])
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/pre_vqa.py", line 71, in forward
    new_image_atts = torch.ones(new_image_embeds.size()[:-1],dtype=torch.long).to(image.device)
KeyboardInterrupt