Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/output_vqa2/vqa/checkpoint_07.pth ,evaluate.
<All keys matched successfully>
Start training
Generate VQA test result:  [    0/26794]  eta: 9:46:30    time: 1.3134  data: 0.3680  max mem: 4164
Generate VQA test result:  [   50/26794]  eta: 1:39:44    time: 0.2001  data: 0.0002  max mem: 4194
Generate VQA test result:  [  100/26794]  eta: 1:34:51    time: 0.2025  data: 0.0002  max mem: 4194
Generate VQA test result:  [  150/26794]  eta: 1:33:02    time: 0.2024  data: 0.0001  max mem: 4194
Generate VQA test result:  [  200/26794]  eta: 1:32:01    time: 0.2011  data: 0.0001  max mem: 4194
Generate VQA test result:  [  250/26794]  eta: 1:31:29    time: 0.2042  data: 0.0002  max mem: 4194
Generate VQA test result:  [  300/26794]  eta: 1:31:04    time: 0.2038  data: 0.0002  max mem: 4194
Generate VQA test result:  [  350/26794]  eta: 1:30:43    time: 0.2037  data: 0.0001  max mem: 4194
Generate VQA test result:  [  400/26794]  eta: 1:30:26    time: 0.2037  data: 0.0002  max mem: 4194
Generate VQA test result:  [  450/26794]  eta: 1:30:10    time: 0.2043  data: 0.0002  max mem: 4194
Generate VQA test result:  [  500/26794]  eta: 1:29:54    time: 0.2040  data: 0.0002  max mem: 4197
Generate VQA test result:  [  550/26794]  eta: 1:29:40    time: 0.2039  data: 0.0002  max mem: 4197
Generate VQA test result:  [  600/26794]  eta: 1:29:26    time: 0.2025  data: 0.0002  max mem: 4197
Generate VQA test result:  [  650/26794]  eta: 1:29:14    time: 0.2044  data: 0.0002  max mem: 4197
Generate VQA test result:  [  700/26794]  eta: 1:29:02    time: 0.2037  data: 0.0002  max mem: 4197
Generate VQA test result:  [  750/26794]  eta: 1:28:50    time: 0.2034  data: 0.0002  max mem: 4197
Generate VQA test result:  [  800/26794]  eta: 1:28:38    time: 0.2042  data: 0.0002  max mem: 4197
Generate VQA test result:  [  850/26794]  eta: 1:28:27    time: 0.2040  data: 0.0002  max mem: 4197
Generate VQA test result:  [  900/26794]  eta: 1:28:14    time: 0.2038  data: 0.0002  max mem: 4197
Generate VQA test result:  [  950/26794]  eta: 1:28:04    time: 0.2041  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1000/26794]  eta: 1:27:53    time: 0.2036  data: 0.0001  max mem: 4197
Generate VQA test result:  [ 1050/26794]  eta: 1:27:41    time: 0.2034  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1100/26794]  eta: 1:27:31    time: 0.2046  data: 0.0001  max mem: 4197
Generate VQA test result:  [ 1150/26794]  eta: 1:27:21    time: 0.2046  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1200/26794]  eta: 1:27:09    time: 0.2036  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1250/26794]  eta: 1:26:58    time: 0.2032  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1300/26794]  eta: 1:26:47    time: 0.2053  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1350/26794]  eta: 1:26:37    time: 0.2048  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1400/26794]  eta: 1:26:28    time: 0.2040  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1450/26794]  eta: 1:26:16    time: 0.2028  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1500/26794]  eta: 1:26:05    time: 0.2032  data: 0.0001  max mem: 4197
Generate VQA test result:  [ 1550/26794]  eta: 1:25:54    time: 0.2036  data: 0.0001  max mem: 4197
Generate VQA test result:  [ 1600/26794]  eta: 1:25:43    time: 0.2039  data: 0.0001  max mem: 4197
Generate VQA test result:  [ 1650/26794]  eta: 1:25:33    time: 0.2039  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1700/26794]  eta: 1:25:22    time: 0.2029  data: 0.0002  max mem: 4197
Generate VQA test result:  [ 1750/26794]  eta: 1:25:10    time: 0.2028  data: 0.0001  max mem: 4197
Traceback (most recent call last):
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 392, in <module>
    main(args, config)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 351, in main
    vqa_result = evaluation(model, test_loader, tokenizer, device, config)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 138, in evaluation
    topk_ids, topk_probs = model(image, question_input, answer_input, train=False, k=config['k_test'])
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/pre_vqa.py", line 161, in forward
    question_output = self.text_encoder(quesiton.input_ids,
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/xbert.py", line 1059, in forward
    encoder_outputs = self.encoder(
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/xbert.py", line 597, in forward
    layer_outputs = layer_module(
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/xbert.py", line 501, in forward
    cross_attention_outputs = self.crossattention(
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/xbert.py", line 402, in forward
    self_outputs = self.self(
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/xbert.py", line 345, in forward
    context_layer = context_layer.view(*new_context_layer_shape)
KeyboardInterrupt