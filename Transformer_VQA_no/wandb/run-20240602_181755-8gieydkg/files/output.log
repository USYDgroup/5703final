Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['text_encoder.encoder.layer.12.attention.self.query.weight', 'text_encoder.encoder.layer.12.attention.self.query.bias', 'text_encoder.encoder.layer.12.attention.self.key.weight', 'text_encoder.encoder.layer.12.attention.self.key.bias', 'text_encoder.encoder.layer.12.attention.self.value.weight', 'text_encoder.encoder.layer.12.attention.self.value.bias', 'text_encoder.encoder.layer.12.attention.output.dense.weight', 'text_encoder.encoder.layer.12.attention.output.dense.bias', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.crossattention.self.query.weight', 'text_encoder.encoder.layer.12.crossattention.self.query.bias', 'text_encoder.encoder.layer.12.crossattention.self.key.weight', 'text_encoder.encoder.layer.12.crossattention.self.key.bias', 'text_encoder.encoder.layer.12.crossattention.self.value.weight', 'text_encoder.encoder.layer.12.crossattention.self.value.bias', 'text_encoder.encoder.layer.12.crossattention.output.dense.weight', 'text_encoder.encoder.layer.12.crossattention.output.dense.bias', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.intermediate.dense.weight', 'text_encoder.encoder.layer.12.intermediate.dense.bias', 'text_encoder.encoder.layer.12.output.dense.weight', 'text_encoder.encoder.layer.12.output.dense.bias', 'text_encoder.encoder.layer.12.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.attention.self.query.weight', 'text_encoder.encoder.layer.13.attention.self.query.bias', 'text_encoder.encoder.layer.13.attention.self.key.weight', 'text_encoder.encoder.layer.13.attention.self.key.bias', 'text_encoder.encoder.layer.13.attention.self.value.weight', 'text_encoder.encoder.layer.13.attention.self.value.bias', 'text_encoder.encoder.layer.13.attention.output.dense.weight', 'text_encoder.encoder.layer.13.attention.output.dense.bias', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.crossattention.self.query.weight', 'text_encoder.encoder.layer.13.crossattention.self.query.bias', 'text_encoder.encoder.layer.13.crossattention.self.key.weight', 'text_encoder.encoder.layer.13.crossattention.self.key.bias', 'text_encoder.encoder.layer.13.crossattention.self.value.weight', 'text_encoder.encoder.layer.13.crossattention.self.value.bias', 'text_encoder.encoder.layer.13.crossattention.output.dense.weight', 'text_encoder.encoder.layer.13.crossattention.output.dense.bias', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.intermediate.dense.weight', 'text_encoder.encoder.layer.13.intermediate.dense.bias', 'text_encoder.encoder.layer.13.output.dense.weight', 'text_encoder.encoder.layer.13.output.dense.bias', 'text_encoder.encoder.layer.13.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.attention.self.query.weight', 'text_encoder.encoder.layer.14.attention.self.query.bias', 'text_encoder.encoder.layer.14.attention.self.key.weight', 'text_encoder.encoder.layer.14.attention.self.key.bias', 'text_encoder.encoder.layer.14.attention.self.value.weight', 'text_encoder.encoder.layer.14.attention.self.value.bias', 'text_encoder.encoder.layer.14.attention.output.dense.weight', 'text_encoder.encoder.layer.14.attention.output.dense.bias', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.crossattention.self.query.weight', 'text_encoder.encoder.layer.14.crossattention.self.query.bias', 'text_encoder.encoder.layer.14.crossattention.self.key.weight', 'text_encoder.encoder.layer.14.crossattention.self.key.bias', 'text_encoder.encoder.layer.14.crossattention.self.value.weight', 'text_encoder.encoder.layer.14.crossattention.self.value.bias', 'text_encoder.encoder.layer.14.crossattention.output.dense.weight', 'text_encoder.encoder.layer.14.crossattention.output.dense.bias', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.intermediate.dense.weight', 'text_encoder.encoder.layer.14.intermediate.dense.bias', 'text_encoder.encoder.layer.14.output.dense.weight', 'text_encoder.encoder.layer.14.output.dense.bias', 'text_encoder.encoder.layer.14.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.attention.self.query.weight', 'text_encoder.encoder.layer.15.attention.self.query.bias', 'text_encoder.encoder.layer.15.attention.self.key.weight', 'text_encoder.encoder.layer.15.attention.self.key.bias', 'text_encoder.encoder.layer.15.attention.self.value.weight', 'text_encoder.encoder.layer.15.attention.self.value.bias', 'text_encoder.encoder.layer.15.attention.output.dense.weight', 'text_encoder.encoder.layer.15.attention.output.dense.bias', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.crossattention.self.query.weight', 'text_encoder.encoder.layer.15.crossattention.self.query.bias', 'text_encoder.encoder.layer.15.crossattention.self.key.weight', 'text_encoder.encoder.layer.15.crossattention.self.key.bias', 'text_encoder.encoder.layer.15.crossattention.self.value.weight', 'text_encoder.encoder.layer.15.crossattention.self.value.bias', 'text_encoder.encoder.layer.15.crossattention.output.dense.weight', 'text_encoder.encoder.layer.15.crossattention.output.dense.bias', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.intermediate.dense.weight', 'text_encoder.encoder.layer.15.intermediate.dense.bias', 'text_encoder.encoder.layer.15.output.dense.weight', 'text_encoder.encoder.layer.15.output.dense.bias', 'text_encoder.encoder.layer.15.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.output.LayerNorm.bias', 'inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [   0/1125]  eta: 0:53:28  lr: 0.000010  loss: 1.6340  time: 2.8521  data: 1.3214  max mem: 11560
/home/admin1/5703-upload/5703/Transformer_VQA_no/optim/nadam.py:80: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1. - beta1, grad)
Train Epoch: [0]  [  50/1125]  eta: 0:12:11  lr: 0.000010  loss: 0.4797  time: 0.6355  data: 0.0001  max mem: 15648
Train Epoch: [0]  [ 100/1125]  eta: 0:11:15  lr: 0.000010  loss: 0.5564  time: 0.6407  data: 0.0001  max mem: 15652
Train Epoch: [0]  [ 150/1125]  eta: 0:10:34  lr: 0.000013  loss: 0.3529  time: 0.6320  data: 0.0001  max mem: 15652
Train Epoch: [0]  [ 200/1125]  eta: 0:09:59  lr: 0.000013  loss: 0.3353  time: 0.6396  data: 0.0001  max mem: 15652
Train Epoch: [0]  [ 250/1125]  eta: 0:09:26  lr: 0.000015  loss: 0.3430  time: 0.6443  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 300/1125]  eta: 0:08:53  lr: 0.000015  loss: 0.3328  time: 0.6417  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 350/1125]  eta: 0:08:19  lr: 0.000018  loss: 0.3211  time: 0.6375  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 400/1125]  eta: 0:07:47  lr: 0.000018  loss: 0.3267  time: 0.6368  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 450/1125]  eta: 0:07:14  lr: 0.000020  loss: 0.5582  time: 0.6358  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 500/1125]  eta: 0:06:42  lr: 0.000020  loss: 0.2405  time: 0.6485  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 550/1125]  eta: 0:06:10  lr: 0.000020  loss: 0.4532  time: 0.6421  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 600/1125]  eta: 0:05:38  lr: 0.000020  loss: 0.1606  time: 0.6404  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 650/1125]  eta: 0:05:05  lr: 0.000020  loss: 0.2551  time: 0.6399  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 700/1125]  eta: 0:04:33  lr: 0.000020  loss: 0.2218  time: 0.6429  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 750/1125]  eta: 0:04:01  lr: 0.000020  loss: 0.1717  time: 0.6356  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 800/1125]  eta: 0:03:28  lr: 0.000020  loss: 0.1912  time: 0.6392  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 850/1125]  eta: 0:02:56  lr: 0.000020  loss: 0.6067  time: 0.6310  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 900/1125]  eta: 0:02:24  lr: 0.000020  loss: 0.1794  time: 0.6493  data: 0.0001  max mem: 15653
Train Epoch: [0]  [ 950/1125]  eta: 0:01:52  lr: 0.000020  loss: 0.2575  time: 0.6351  data: 0.0001  max mem: 15653
Train Epoch: [0]  [1000/1125]  eta: 0:01:20  lr: 0.000020  loss: 0.1622  time: 0.6328  data: 0.0001  max mem: 15653
Train Epoch: [0]  [1050/1125]  eta: 0:00:48  lr: 0.000020  loss: 0.1407  time: 0.6473  data: 0.0001  max mem: 15653
Train Epoch: [0]  [1100/1125]  eta: 0:00:16  lr: 0.000020  loss: 0.1823  time: 0.6527  data: 0.0001  max mem: 15655
Train Epoch: [0]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.2046  time: 0.6286  data: 0.0002  max mem: 15655
Train Epoch: [0] Total time: 0:12:02 (0.6425 s / it)
Averaged stats: lr: 0.0000  loss: 0.3272
Generate VQA test result:  [  0/563]  eta: 0:07:19    time: 0.7799  data: 0.3244  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:53    time: 0.2095  data: 0.0001  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:39    time: 0.2090  data: 0.0001  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:28    time: 0.2092  data: 0.0001  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:17    time: 0.2095  data: 0.0001  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2093  data: 0.0001  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2098  data: 0.0001  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2104  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2096  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2093  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2096  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2094  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2084  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:58 (0.2107 s / it)
0.8716696269982238
Train Epoch: [1]  [   0/1125]  eta: 0:35:37  lr: 0.000019  loss: 0.4102  time: 1.8996  data: 0.9641  max mem: 15655
Train Epoch: [1]  [  50/1125]  eta: 0:12:04  lr: 0.000019  loss: 0.2273  time: 0.6449  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 100/1125]  eta: 0:11:15  lr: 0.000019  loss: 0.2118  time: 0.6415  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 150/1125]  eta: 0:10:36  lr: 0.000019  loss: 0.3457  time: 0.6372  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 200/1125]  eta: 0:10:01  lr: 0.000019  loss: 0.1980  time: 0.6450  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 250/1125]  eta: 0:09:27  lr: 0.000019  loss: 0.2678  time: 0.6339  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 300/1125]  eta: 0:08:54  lr: 0.000019  loss: 0.2086  time: 0.6601  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 350/1125]  eta: 0:08:22  lr: 0.000019  loss: 0.2264  time: 0.6467  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 400/1125]  eta: 0:07:49  lr: 0.000019  loss: 0.2486  time: 0.6448  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 450/1125]  eta: 0:07:17  lr: 0.000019  loss: 0.1593  time: 0.6513  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 500/1125]  eta: 0:06:45  lr: 0.000019  loss: 0.2162  time: 0.6496  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 550/1125]  eta: 0:06:12  lr: 0.000019  loss: 0.4245  time: 0.6429  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 600/1125]  eta: 0:05:40  lr: 0.000019  loss: 0.3939  time: 0.6402  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 650/1125]  eta: 0:05:07  lr: 0.000019  loss: 0.1845  time: 0.6349  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 700/1125]  eta: 0:04:34  lr: 0.000019  loss: 0.3890  time: 0.6519  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 750/1125]  eta: 0:04:02  lr: 0.000019  loss: 0.2268  time: 0.6429  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 800/1125]  eta: 0:03:30  lr: 0.000019  loss: 0.3085  time: 0.6582  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 850/1125]  eta: 0:02:57  lr: 0.000019  loss: 0.2142  time: 0.6375  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 900/1125]  eta: 0:02:25  lr: 0.000019  loss: 0.3286  time: 0.6507  data: 0.0001  max mem: 15655
Train Epoch: [1]  [ 950/1125]  eta: 0:01:53  lr: 0.000019  loss: 0.2129  time: 0.6360  data: 0.0001  max mem: 15655
Train Epoch: [1]  [1000/1125]  eta: 0:01:20  lr: 0.000019  loss: 0.7685  time: 0.6440  data: 0.0001  max mem: 15655
Train Epoch: [1]  [1050/1125]  eta: 0:00:48  lr: 0.000019  loss: 0.2752  time: 0.6439  data: 0.0001  max mem: 15655
Train Epoch: [1]  [1100/1125]  eta: 0:00:16  lr: 0.000019  loss: 0.4762  time: 0.6439  data: 0.0001  max mem: 15655
Train Epoch: [1]  [1124/1125]  eta: 0:00:00  lr: 0.000019  loss: 0.4123  time: 0.6301  data: 0.0001  max mem: 15655
Train Epoch: [1] Total time: 0:12:06 (0.6457 s / it)
Averaged stats: lr: 0.0000  loss: 0.2973
Generate VQA test result:  [  0/563]  eta: 0:05:11    time: 0.5532  data: 0.3211  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2085  data: 0.0002  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2085  data: 0.0001  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2088  data: 0.0002  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2089  data: 0.0001  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2083  data: 0.0001  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2087  data: 0.0002  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2090  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2085  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2085  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2088  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2084  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2074  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:57 (0.2095 s / it)
0.7291296625222025
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Train Epoch: [2]  [   0/1125]  eta: 0:35:13  lr: 0.000017  loss: 0.1812  time: 1.8790  data: 1.1601  max mem: 15655
Train Epoch: [2]  [  50/1125]  eta: 0:11:59  lr: 0.000017  loss: 0.3113  time: 0.6538  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 100/1125]  eta: 0:11:11  lr: 0.000017  loss: 0.2387  time: 0.6440  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 150/1125]  eta: 0:10:32  lr: 0.000017  loss: 0.4347  time: 0.6387  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 200/1125]  eta: 0:09:57  lr: 0.000017  loss: 0.2357  time: 0.6362  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 250/1125]  eta: 0:09:24  lr: 0.000017  loss: 0.1889  time: 0.6465  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 300/1125]  eta: 0:08:52  lr: 0.000017  loss: 0.2529  time: 0.6417  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 350/1125]  eta: 0:08:19  lr: 0.000017  loss: 0.3594  time: 0.6463  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 400/1125]  eta: 0:07:47  lr: 0.000017  loss: 0.3441  time: 0.6449  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 450/1125]  eta: 0:07:15  lr: 0.000017  loss: 0.3462  time: 0.6422  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 500/1125]  eta: 0:06:43  lr: 0.000017  loss: 0.2054  time: 0.6542  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 550/1125]  eta: 0:06:10  lr: 0.000017  loss: 0.4192  time: 0.6409  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 600/1125]  eta: 0:05:38  lr: 0.000017  loss: 0.9312  time: 0.6338  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 650/1125]  eta: 0:05:05  lr: 0.000017  loss: 0.4305  time: 0.6392  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 700/1125]  eta: 0:04:33  lr: 0.000017  loss: 0.5474  time: 0.6404  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 750/1125]  eta: 0:04:01  lr: 0.000017  loss: 0.4837  time: 0.6426  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 800/1125]  eta: 0:03:29  lr: 0.000017  loss: 0.6341  time: 0.6409  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 850/1125]  eta: 0:02:56  lr: 0.000017  loss: 0.3726  time: 0.6430  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 900/1125]  eta: 0:02:24  lr: 0.000017  loss: 0.1934  time: 0.6407  data: 0.0001  max mem: 15655
Train Epoch: [2]  [ 950/1125]  eta: 0:01:52  lr: 0.000017  loss: 0.5614  time: 0.6321  data: 0.0001  max mem: 15655
Train Epoch: [2]  [1000/1125]  eta: 0:01:20  lr: 0.000017  loss: 0.3098  time: 0.6399  data: 0.0001  max mem: 15655
Train Epoch: [2]  [1050/1125]  eta: 0:00:48  lr: 0.000017  loss: 0.4920  time: 0.6365  data: 0.0001  max mem: 15655
Train Epoch: [2]  [1100/1125]  eta: 0:00:16  lr: 0.000017  loss: 0.3386  time: 0.6361  data: 0.0001  max mem: 15655
Train Epoch: [2]  [1124/1125]  eta: 0:00:00  lr: 0.000017  loss: 0.2901  time: 0.6412  data: 0.0002  max mem: 15655
Train Epoch: [2] Total time: 0:12:03 (0.6429 s / it)
Averaged stats: lr: 0.0000  loss: 0.3709
Generate VQA test result:  [  0/563]  eta: 0:05:09    time: 0.5492  data: 0.3108  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2094  data: 0.0001  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2096  data: 0.0002  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2093  data: 0.0001  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2097  data: 0.0001  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2093  data: 0.0002  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2094  data: 0.0001  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2097  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2096  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2094  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2095  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2098  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2088  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:58 (0.2104 s / it)
0.7493339253996447
Train Epoch: [3]  [   0/1125]  eta: 0:36:51  lr: 0.000014  loss: 0.2557  time: 1.9662  data: 1.3060  max mem: 15655
Train Epoch: [3]  [  50/1125]  eta: 0:11:58  lr: 0.000014  loss: 0.5918  time: 0.6485  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 100/1125]  eta: 0:11:11  lr: 0.000014  loss: 0.5501  time: 0.6512  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 150/1125]  eta: 0:10:36  lr: 0.000014  loss: 0.3321  time: 0.6501  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 200/1125]  eta: 0:10:01  lr: 0.000014  loss: 0.6116  time: 0.6460  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 250/1125]  eta: 0:09:26  lr: 0.000014  loss: 0.5246  time: 0.6396  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 300/1125]  eta: 0:08:53  lr: 0.000014  loss: 0.4328  time: 0.6385  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 350/1125]  eta: 0:08:21  lr: 0.000014  loss: 0.2740  time: 0.6467  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 400/1125]  eta: 0:07:48  lr: 0.000014  loss: 0.5935  time: 0.6430  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 450/1125]  eta: 0:07:16  lr: 0.000014  loss: 0.4557  time: 0.6435  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 500/1125]  eta: 0:06:43  lr: 0.000014  loss: 0.4092  time: 0.6349  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 550/1125]  eta: 0:06:11  lr: 0.000014  loss: 0.4387  time: 0.6512  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 600/1125]  eta: 0:05:38  lr: 0.000014  loss: 0.6295  time: 0.6308  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 650/1125]  eta: 0:05:06  lr: 0.000014  loss: 0.3724  time: 0.6403  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 700/1125]  eta: 0:04:33  lr: 0.000014  loss: 0.3846  time: 0.6289  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 750/1125]  eta: 0:04:01  lr: 0.000014  loss: 0.3375  time: 0.6429  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 800/1125]  eta: 0:03:28  lr: 0.000014  loss: 0.2858  time: 0.6357  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 850/1125]  eta: 0:02:56  lr: 0.000014  loss: 0.8939  time: 0.6424  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 900/1125]  eta: 0:02:24  lr: 0.000014  loss: 0.2352  time: 0.6420  data: 0.0001  max mem: 15655
Train Epoch: [3]  [ 950/1125]  eta: 0:01:52  lr: 0.000014  loss: 0.6759  time: 0.6372  data: 0.0001  max mem: 15655
Train Epoch: [3]  [1000/1125]  eta: 0:01:20  lr: 0.000014  loss: 0.3468  time: 0.6396  data: 0.0001  max mem: 15655
Train Epoch: [3]  [1050/1125]  eta: 0:00:48  lr: 0.000014  loss: 0.5691  time: 0.6370  data: 0.0001  max mem: 15655
Train Epoch: [3]  [1100/1125]  eta: 0:00:16  lr: 0.000014  loss: 0.5064  time: 0.6396  data: 0.0001  max mem: 15655
Train Epoch: [3]  [1124/1125]  eta: 0:00:00  lr: 0.000014  loss: 0.4961  time: 0.6346  data: 0.0002  max mem: 15655
Train Epoch: [3] Total time: 0:12:02 (0.6420 s / it)
Averaged stats: lr: 0.0000  loss: 0.3982
Generate VQA test result:  [  0/563]  eta: 0:05:12    time: 0.5551  data: 0.3216  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2089  data: 0.0001  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2094  data: 0.0001  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2091  data: 0.0002  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2097  data: 0.0001  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2097  data: 0.0001  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2097  data: 0.0002  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2096  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2100  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2096  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2097  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2093  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2088  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:58 (0.2103 s / it)
0.7415630550621669
Train Epoch: [4]  [   0/1125]  eta: 0:32:23  lr: 0.000011  loss: 0.4037  time: 1.7276  data: 0.8580  max mem: 15655
Train Epoch: [4]  [  50/1125]  eta: 0:11:59  lr: 0.000011  loss: 0.5171  time: 0.6509  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 100/1125]  eta: 0:11:12  lr: 0.000011  loss: 0.1674  time: 0.6459  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 150/1125]  eta: 0:10:34  lr: 0.000011  loss: 0.3565  time: 0.6316  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 200/1125]  eta: 0:09:59  lr: 0.000011  loss: 0.4474  time: 0.6455  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 250/1125]  eta: 0:09:25  lr: 0.000011  loss: 0.3080  time: 0.6433  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 300/1125]  eta: 0:08:52  lr: 0.000011  loss: 0.3610  time: 0.6435  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 350/1125]  eta: 0:08:19  lr: 0.000011  loss: 0.3643  time: 0.6367  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 400/1125]  eta: 0:07:46  lr: 0.000011  loss: 0.4672  time: 0.6466  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 450/1125]  eta: 0:07:14  lr: 0.000011  loss: 0.3019  time: 0.6364  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 500/1125]  eta: 0:06:42  lr: 0.000011  loss: 0.3147  time: 0.6428  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 550/1125]  eta: 0:06:09  lr: 0.000011  loss: 0.2804  time: 0.6465  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 600/1125]  eta: 0:05:37  lr: 0.000011  loss: 0.3271  time: 0.6460  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 650/1125]  eta: 0:05:05  lr: 0.000011  loss: 0.3095  time: 0.6303  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 700/1125]  eta: 0:04:33  lr: 0.000011  loss: 0.2234  time: 0.6405  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 750/1125]  eta: 0:04:00  lr: 0.000011  loss: 0.3694  time: 0.6380  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 800/1125]  eta: 0:03:28  lr: 0.000011  loss: 0.3835  time: 0.6529  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 850/1125]  eta: 0:02:56  lr: 0.000011  loss: 0.5258  time: 0.6347  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 900/1125]  eta: 0:02:24  lr: 0.000011  loss: 0.2453  time: 0.6394  data: 0.0001  max mem: 15655
Train Epoch: [4]  [ 950/1125]  eta: 0:01:52  lr: 0.000011  loss: 0.3760  time: 0.6392  data: 0.0001  max mem: 15655
Train Epoch: [4]  [1000/1125]  eta: 0:01:20  lr: 0.000011  loss: 0.6884  time: 0.6361  data: 0.0001  max mem: 15655
Train Epoch: [4]  [1050/1125]  eta: 0:00:48  lr: 0.000011  loss: 0.4409  time: 0.6421  data: 0.0001  max mem: 15655
Train Epoch: [4]  [1100/1125]  eta: 0:00:16  lr: 0.000011  loss: 0.5254  time: 0.6419  data: 0.0001  max mem: 15655
Train Epoch: [4]  [1124/1125]  eta: 0:00:00  lr: 0.000011  loss: 0.5940  time: 0.6280  data: 0.0002  max mem: 15655
Train Epoch: [4] Total time: 0:12:01 (0.6417 s / it)
Averaged stats: lr: 0.0000  loss: 0.3962
Generate VQA test result:  [  0/563]  eta: 0:05:37    time: 0.5998  data: 0.3786  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2084  data: 0.0002  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2080  data: 0.0001  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2086  data: 0.0001  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2084  data: 0.0001  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2082  data: 0.0001  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2085  data: 0.0001  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2085  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2084  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2086  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2090  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2086  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2077  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:57 (0.2092 s / it)
0.7206927175843695
Train Epoch: [5]  [   0/1125]  eta: 0:35:58  lr: 0.000007  loss: 0.5769  time: 1.9188  data: 1.0410  max mem: 15655
Train Epoch: [5]  [  50/1125]  eta: 0:11:51  lr: 0.000007  loss: 0.3968  time: 0.6425  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 100/1125]  eta: 0:11:07  lr: 0.000007  loss: 0.4222  time: 0.6390  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 150/1125]  eta: 0:10:34  lr: 0.000007  loss: 0.1819  time: 0.6549  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 200/1125]  eta: 0:09:59  lr: 0.000007  loss: 0.1666  time: 0.6375  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 250/1125]  eta: 0:09:25  lr: 0.000007  loss: 0.5079  time: 0.6374  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 300/1125]  eta: 0:08:53  lr: 0.000007  loss: 0.2516  time: 0.6438  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 350/1125]  eta: 0:08:20  lr: 0.000007  loss: 0.3506  time: 0.6456  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 400/1125]  eta: 0:07:48  lr: 0.000007  loss: 0.2722  time: 0.6384  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 450/1125]  eta: 0:07:15  lr: 0.000007  loss: 0.4100  time: 0.6386  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 500/1125]  eta: 0:06:43  lr: 0.000007  loss: 0.4456  time: 0.6475  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 550/1125]  eta: 0:06:10  lr: 0.000007  loss: 0.3682  time: 0.6339  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 600/1125]  eta: 0:05:38  lr: 0.000007  loss: 0.3789  time: 0.6351  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 650/1125]  eta: 0:05:05  lr: 0.000007  loss: 0.8340  time: 0.6434  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 700/1125]  eta: 0:04:33  lr: 0.000007  loss: 0.2074  time: 0.6434  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 750/1125]  eta: 0:04:01  lr: 0.000007  loss: 0.3776  time: 0.6366  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 800/1125]  eta: 0:03:29  lr: 0.000007  loss: 0.5595  time: 0.6351  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 850/1125]  eta: 0:02:56  lr: 0.000007  loss: 0.2696  time: 0.6454  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 900/1125]  eta: 0:02:24  lr: 0.000007  loss: 0.4412  time: 0.6426  data: 0.0001  max mem: 15655
Train Epoch: [5]  [ 950/1125]  eta: 0:01:52  lr: 0.000007  loss: 0.3514  time: 0.6478  data: 0.0001  max mem: 15655
Train Epoch: [5]  [1000/1125]  eta: 0:01:20  lr: 0.000007  loss: 0.3336  time: 0.6466  data: 0.0001  max mem: 15655
Train Epoch: [5]  [1050/1125]  eta: 0:00:48  lr: 0.000007  loss: 0.3830  time: 0.6459  data: 0.0001  max mem: 15655
Train Epoch: [5]  [1100/1125]  eta: 0:00:16  lr: 0.000007  loss: 0.2675  time: 0.6432  data: 0.0001  max mem: 15655
Train Epoch: [5]  [1124/1125]  eta: 0:00:00  lr: 0.000007  loss: 0.3340  time: 0.6309  data: 0.0002  max mem: 15655
Train Epoch: [5] Total time: 0:12:03 (0.6429 s / it)
Averaged stats: lr: 0.0000  loss: 0.3738
Generate VQA test result:  [  0/563]  eta: 0:05:09    time: 0.5494  data: 0.3237  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2088  data: 0.0001  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2090  data: 0.0001  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2099  data: 0.0002  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2096  data: 0.0001  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2098  data: 0.0001  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2097  data: 0.0001  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2098  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2095  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2091  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2099  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2092  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2083  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:58 (0.2102 s / it)
0.8190497335701599
Train Epoch: [6]  [   0/1125]  eta: 0:35:17  lr: 0.000004  loss: 0.3358  time: 1.8824  data: 0.9320  max mem: 15655
Train Epoch: [6]  [  50/1125]  eta: 0:12:00  lr: 0.000004  loss: 0.1368  time: 0.6395  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 100/1125]  eta: 0:11:15  lr: 0.000004  loss: 0.3712  time: 0.6510  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 150/1125]  eta: 0:10:38  lr: 0.000004  loss: 0.3110  time: 0.6477  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 200/1125]  eta: 0:10:03  lr: 0.000004  loss: 0.5274  time: 0.6510  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 250/1125]  eta: 0:09:31  lr: 0.000004  loss: 0.3060  time: 0.6471  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 300/1125]  eta: 0:08:56  lr: 0.000004  loss: 0.4529  time: 0.6382  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 350/1125]  eta: 0:08:22  lr: 0.000004  loss: 0.2136  time: 0.6458  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 400/1125]  eta: 0:07:49  lr: 0.000004  loss: 0.3097  time: 0.6394  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 450/1125]  eta: 0:07:16  lr: 0.000004  loss: 0.5353  time: 0.6423  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 500/1125]  eta: 0:06:43  lr: 0.000004  loss: 0.3350  time: 0.6382  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 550/1125]  eta: 0:06:11  lr: 0.000004  loss: 0.3095  time: 0.6401  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 600/1125]  eta: 0:05:38  lr: 0.000004  loss: 0.3041  time: 0.6466  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 650/1125]  eta: 0:05:06  lr: 0.000004  loss: 0.5654  time: 0.6414  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 700/1125]  eta: 0:04:34  lr: 0.000004  loss: 0.4470  time: 0.6428  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 750/1125]  eta: 0:04:01  lr: 0.000004  loss: 0.4328  time: 0.6318  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 800/1125]  eta: 0:03:29  lr: 0.000004  loss: 0.5238  time: 0.6405  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 850/1125]  eta: 0:02:57  lr: 0.000004  loss: 0.1862  time: 0.6422  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 900/1125]  eta: 0:02:24  lr: 0.000004  loss: 0.4028  time: 0.6408  data: 0.0001  max mem: 15655
Train Epoch: [6]  [ 950/1125]  eta: 0:01:52  lr: 0.000004  loss: 0.3849  time: 0.6412  data: 0.0001  max mem: 15655
Train Epoch: [6]  [1000/1125]  eta: 0:01:20  lr: 0.000004  loss: 0.3052  time: 0.6442  data: 0.0001  max mem: 15655
Train Epoch: [6]  [1050/1125]  eta: 0:00:48  lr: 0.000004  loss: 0.2778  time: 0.6468  data: 0.0001  max mem: 15655
Train Epoch: [6]  [1100/1125]  eta: 0:00:16  lr: 0.000004  loss: 0.2796  time: 0.6376  data: 0.0001  max mem: 15655
Train Epoch: [6]  [1124/1125]  eta: 0:00:00  lr: 0.000004  loss: 0.2414  time: 0.6289  data: 0.0002  max mem: 15655
Train Epoch: [6] Total time: 0:12:04 (0.6441 s / it)
Averaged stats: lr: 0.0000  loss: 0.3477
Generate VQA test result:  [  0/563]  eta: 0:05:24    time: 0.5756  data: 0.3435  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:51    time: 0.2091  data: 0.0001  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2090  data: 0.0001  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2100  data: 0.0002  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2094  data: 0.0002  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2087  data: 0.0001  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2095  data: 0.0001  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2093  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2092  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2091  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2092  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2096  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2082  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:58 (0.2101 s / it)
0.808392539964476
Train Epoch: [7]  [   0/1125]  eta: 0:32:42  lr: 0.000002  loss: 0.3358  time: 1.7447  data: 0.8282  max mem: 15655
Train Epoch: [7]  [  50/1125]  eta: 0:11:52  lr: 0.000002  loss: 0.1932  time: 0.6371  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 100/1125]  eta: 0:11:10  lr: 0.000002  loss: 0.1411  time: 0.6430  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 150/1125]  eta: 0:10:33  lr: 0.000002  loss: 0.4594  time: 0.6412  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 200/1125]  eta: 0:09:59  lr: 0.000002  loss: 0.2283  time: 0.6383  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 250/1125]  eta: 0:09:25  lr: 0.000002  loss: 0.2581  time: 0.6372  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 300/1125]  eta: 0:08:52  lr: 0.000002  loss: 0.5892  time: 0.6440  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 350/1125]  eta: 0:08:19  lr: 0.000002  loss: 0.3731  time: 0.6384  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 400/1125]  eta: 0:07:47  lr: 0.000002  loss: 0.3754  time: 0.6424  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 450/1125]  eta: 0:07:15  lr: 0.000002  loss: 0.1289  time: 0.6330  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 500/1125]  eta: 0:06:43  lr: 0.000002  loss: 0.4465  time: 0.6481  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 550/1125]  eta: 0:06:10  lr: 0.000002  loss: 0.4063  time: 0.6433  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 600/1125]  eta: 0:05:38  lr: 0.000002  loss: 0.1936  time: 0.6359  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 650/1125]  eta: 0:05:05  lr: 0.000002  loss: 0.2804  time: 0.6382  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 700/1125]  eta: 0:04:33  lr: 0.000002  loss: 0.2128  time: 0.6494  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 750/1125]  eta: 0:04:01  lr: 0.000002  loss: 0.3185  time: 0.6420  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 800/1125]  eta: 0:03:29  lr: 0.000002  loss: 0.1195  time: 0.6390  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 850/1125]  eta: 0:02:57  lr: 0.000002  loss: 0.1971  time: 0.6374  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 900/1125]  eta: 0:02:24  lr: 0.000002  loss: 0.2811  time: 0.6521  data: 0.0001  max mem: 15655
Train Epoch: [7]  [ 950/1125]  eta: 0:01:52  lr: 0.000002  loss: 0.5806  time: 0.6546  data: 0.0001  max mem: 15655
Train Epoch: [7]  [1000/1125]  eta: 0:01:20  lr: 0.000002  loss: 0.4988  time: 0.6316  data: 0.0001  max mem: 15655
Train Epoch: [7]  [1050/1125]  eta: 0:00:48  lr: 0.000002  loss: 0.2717  time: 0.6438  data: 0.0001  max mem: 15655
Train Epoch: [7]  [1100/1125]  eta: 0:00:16  lr: 0.000002  loss: 0.4672  time: 0.6419  data: 0.0001  max mem: 15655
Train Epoch: [7]  [1124/1125]  eta: 0:00:00  lr: 0.000002  loss: 0.3959  time: 0.6315  data: 0.0002  max mem: 15655
Train Epoch: [7] Total time: 0:12:03 (0.6435 s / it)
Averaged stats: lr: 0.0000  loss: 0.3161
Generate VQA test result:  [  0/563]  eta: 0:05:18    time: 0.5661  data: 0.3348  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2095  data: 0.0002  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2090  data: 0.0001  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2093  data: 0.0001  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2096  data: 0.0001  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2094  data: 0.0001  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2102  data: 0.0001  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2097  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2097  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2093  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2095  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2087  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2075  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:58 (0.2102 s / it)
0.8261545293072824
Generate VQA test result:  [  0/563]  eta: 0:05:10    time: 0.5519  data: 0.3229  max mem: 15655
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2085  data: 0.0002  max mem: 15655
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2084  data: 0.0001  max mem: 15655
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2093  data: 0.0001  max mem: 15655
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2095  data: 0.0001  max mem: 15655
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2091  data: 0.0001  max mem: 15655
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2088  data: 0.0001  max mem: 15655
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2091  data: 0.0001  max mem: 15655
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2092  data: 0.0001  max mem: 15655
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2091  data: 0.0001  max mem: 15655
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2091  data: 0.0001  max mem: 15655
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2089  data: 0.0001  max mem: 15655
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2078  data: 0.0001  max mem: 15655
Generate VQA test result: Total time: 0:01:58 (0.2097 s / it)
result file saved to output_optimal/vqa/result/vqa_result_epoch7.json
Training time 1:55:08