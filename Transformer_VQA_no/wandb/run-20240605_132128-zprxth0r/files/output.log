Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['text_encoder.encoder.layer.12.attention.self.query.weight', 'text_encoder.encoder.layer.12.attention.self.query.bias', 'text_encoder.encoder.layer.12.attention.self.key.weight', 'text_encoder.encoder.layer.12.attention.self.key.bias', 'text_encoder.encoder.layer.12.attention.self.value.weight', 'text_encoder.encoder.layer.12.attention.self.value.bias', 'text_encoder.encoder.layer.12.attention.output.dense.weight', 'text_encoder.encoder.layer.12.attention.output.dense.bias', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.crossattention.self.query.weight', 'text_encoder.encoder.layer.12.crossattention.self.query.bias', 'text_encoder.encoder.layer.12.crossattention.self.key.weight', 'text_encoder.encoder.layer.12.crossattention.self.key.bias', 'text_encoder.encoder.layer.12.crossattention.self.value.weight', 'text_encoder.encoder.layer.12.crossattention.self.value.bias', 'text_encoder.encoder.layer.12.crossattention.output.dense.weight', 'text_encoder.encoder.layer.12.crossattention.output.dense.bias', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.intermediate.dense.weight', 'text_encoder.encoder.layer.12.intermediate.dense.bias', 'text_encoder.encoder.layer.12.output.dense.weight', 'text_encoder.encoder.layer.12.output.dense.bias', 'text_encoder.encoder.layer.12.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.attention.self.query.weight', 'text_encoder.encoder.layer.13.attention.self.query.bias', 'text_encoder.encoder.layer.13.attention.self.key.weight', 'text_encoder.encoder.layer.13.attention.self.key.bias', 'text_encoder.encoder.layer.13.attention.self.value.weight', 'text_encoder.encoder.layer.13.attention.self.value.bias', 'text_encoder.encoder.layer.13.attention.output.dense.weight', 'text_encoder.encoder.layer.13.attention.output.dense.bias', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.crossattention.self.query.weight', 'text_encoder.encoder.layer.13.crossattention.self.query.bias', 'text_encoder.encoder.layer.13.crossattention.self.key.weight', 'text_encoder.encoder.layer.13.crossattention.self.key.bias', 'text_encoder.encoder.layer.13.crossattention.self.value.weight', 'text_encoder.encoder.layer.13.crossattention.self.value.bias', 'text_encoder.encoder.layer.13.crossattention.output.dense.weight', 'text_encoder.encoder.layer.13.crossattention.output.dense.bias', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.intermediate.dense.weight', 'text_encoder.encoder.layer.13.intermediate.dense.bias', 'text_encoder.encoder.layer.13.output.dense.weight', 'text_encoder.encoder.layer.13.output.dense.bias', 'text_encoder.encoder.layer.13.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.attention.self.query.weight', 'text_encoder.encoder.layer.14.attention.self.query.bias', 'text_encoder.encoder.layer.14.attention.self.key.weight', 'text_encoder.encoder.layer.14.attention.self.key.bias', 'text_encoder.encoder.layer.14.attention.self.value.weight', 'text_encoder.encoder.layer.14.attention.self.value.bias', 'text_encoder.encoder.layer.14.attention.output.dense.weight', 'text_encoder.encoder.layer.14.attention.output.dense.bias', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.crossattention.self.query.weight', 'text_encoder.encoder.layer.14.crossattention.self.query.bias', 'text_encoder.encoder.layer.14.crossattention.self.key.weight', 'text_encoder.encoder.layer.14.crossattention.self.key.bias', 'text_encoder.encoder.layer.14.crossattention.self.value.weight', 'text_encoder.encoder.layer.14.crossattention.self.value.bias', 'text_encoder.encoder.layer.14.crossattention.output.dense.weight', 'text_encoder.encoder.layer.14.crossattention.output.dense.bias', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.intermediate.dense.weight', 'text_encoder.encoder.layer.14.intermediate.dense.bias', 'text_encoder.encoder.layer.14.output.dense.weight', 'text_encoder.encoder.layer.14.output.dense.bias', 'text_encoder.encoder.layer.14.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.attention.self.query.weight', 'text_encoder.encoder.layer.15.attention.self.query.bias', 'text_encoder.encoder.layer.15.attention.self.key.weight', 'text_encoder.encoder.layer.15.attention.self.key.bias', 'text_encoder.encoder.layer.15.attention.self.value.weight', 'text_encoder.encoder.layer.15.attention.self.value.bias', 'text_encoder.encoder.layer.15.attention.output.dense.weight', 'text_encoder.encoder.layer.15.attention.output.dense.bias', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.crossattention.self.query.weight', 'text_encoder.encoder.layer.15.crossattention.self.query.bias', 'text_encoder.encoder.layer.15.crossattention.self.key.weight', 'text_encoder.encoder.layer.15.crossattention.self.key.bias', 'text_encoder.encoder.layer.15.crossattention.self.value.weight', 'text_encoder.encoder.layer.15.crossattention.self.value.bias', 'text_encoder.encoder.layer.15.crossattention.output.dense.weight', 'text_encoder.encoder.layer.15.crossattention.output.dense.bias', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.intermediate.dense.weight', 'text_encoder.encoder.layer.15.intermediate.dense.bias', 'text_encoder.encoder.layer.15.output.dense.weight', 'text_encoder.encoder.layer.15.output.dense.bias', 'text_encoder.encoder.layer.15.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.output.LayerNorm.bias', 'inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [   0/1125]  eta: 0:54:02  lr: 0.000010  loss: 1.6340  time: 2.8821  data: 1.2383  max mem: 11560
Train Epoch: [0]  [  50/1125]  eta: 0:11:19  lr: 0.000010  loss: 0.4761  time: 0.5815  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 100/1125]  eta: 0:10:23  lr: 0.000010  loss: 0.5289  time: 0.5860  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 150/1125]  eta: 0:09:43  lr: 0.000012  loss: 0.2791  time: 0.5725  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 200/1125]  eta: 0:09:11  lr: 0.000012  loss: 0.2979  time: 0.5885  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 250/1125]  eta: 0:08:39  lr: 0.000014  loss: 0.3105  time: 0.5993  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 300/1125]  eta: 0:08:08  lr: 0.000014  loss: 0.3644  time: 0.5784  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 350/1125]  eta: 0:07:38  lr: 0.000016  loss: 0.2842  time: 0.5887  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 400/1125]  eta: 0:07:07  lr: 0.000016  loss: 0.3936  time: 0.5801  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 450/1125]  eta: 0:06:38  lr: 0.000018  loss: 0.5233  time: 0.5794  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 500/1125]  eta: 0:06:08  lr: 0.000018  loss: 0.4488  time: 0.5911  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 550/1125]  eta: 0:05:39  lr: 0.000020  loss: 0.1965  time: 0.5877  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 600/1125]  eta: 0:05:09  lr: 0.000020  loss: 0.1959  time: 0.5864  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 650/1125]  eta: 0:04:40  lr: 0.000020  loss: 0.1729  time: 0.5938  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 700/1125]  eta: 0:04:10  lr: 0.000020  loss: 0.1633  time: 0.5916  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 750/1125]  eta: 0:03:41  lr: 0.000020  loss: 0.2292  time: 0.5936  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 800/1125]  eta: 0:03:11  lr: 0.000020  loss: 0.1952  time: 0.5822  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 850/1125]  eta: 0:02:42  lr: 0.000020  loss: 0.1210  time: 0.5840  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.2674  time: 0.5849  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 950/1125]  eta: 0:01:43  lr: 0.000020  loss: 0.2047  time: 0.5798  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.1614  time: 0.5845  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.2630  time: 0.5774  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.1754  time: 0.5760  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.2139  time: 0.5761  data: 0.0001  max mem: 15660
Train Epoch: [0] Total time: 0:11:01 (0.5878 s / it)
Averaged stats: lr: 0.0000  loss: 0.2613
Generate VQA test result:  [  0/563]  eta: 0:07:43    time: 0.8234  data: 0.2959  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:52    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2098  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2088  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2088  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2072  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2099 s / it)
0.9367229129662522
Train Epoch: [1]  [   0/1125]  eta: 0:36:49  lr: 0.000019  loss: 0.1300  time: 1.9640  data: 1.2132  max mem: 15660
Train Epoch: [1]  [  50/1125]  eta: 0:10:55  lr: 0.000019  loss: 0.1588  time: 0.5841  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 100/1125]  eta: 0:10:17  lr: 0.000019  loss: 0.1147  time: 0.5950  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 150/1125]  eta: 0:09:42  lr: 0.000019  loss: 0.1467  time: 0.5926  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 200/1125]  eta: 0:09:09  lr: 0.000019  loss: 0.1596  time: 0.5789  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 250/1125]  eta: 0:08:37  lr: 0.000019  loss: 0.1686  time: 0.5828  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 300/1125]  eta: 0:08:07  lr: 0.000019  loss: 0.0798  time: 0.5852  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 350/1125]  eta: 0:07:37  lr: 0.000019  loss: 0.1339  time: 0.5801  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 400/1125]  eta: 0:07:07  lr: 0.000019  loss: 0.2544  time: 0.5927  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 450/1125]  eta: 0:06:38  lr: 0.000019  loss: 0.0954  time: 0.5996  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 500/1125]  eta: 0:06:09  lr: 0.000019  loss: 0.0339  time: 0.5990  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 550/1125]  eta: 0:05:39  lr: 0.000019  loss: 0.0284  time: 0.5903  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 600/1125]  eta: 0:05:10  lr: 0.000019  loss: 0.0147  time: 0.5916  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 650/1125]  eta: 0:04:40  lr: 0.000019  loss: 0.0853  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 700/1125]  eta: 0:04:10  lr: 0.000019  loss: 0.0276  time: 0.5910  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 750/1125]  eta: 0:03:41  lr: 0.000019  loss: 0.1031  time: 0.5859  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 800/1125]  eta: 0:03:11  lr: 0.000019  loss: 0.0275  time: 0.5912  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 850/1125]  eta: 0:02:42  lr: 0.000019  loss: 0.0865  time: 0.5890  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 900/1125]  eta: 0:02:12  lr: 0.000019  loss: 0.0249  time: 0.5853  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 950/1125]  eta: 0:01:43  lr: 0.000019  loss: 0.1426  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1000/1125]  eta: 0:01:13  lr: 0.000019  loss: 0.1117  time: 0.5854  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1050/1125]  eta: 0:00:44  lr: 0.000019  loss: 0.1081  time: 0.5856  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1100/1125]  eta: 0:00:14  lr: 0.000019  loss: 0.0121  time: 0.5832  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1124/1125]  eta: 0:00:00  lr: 0.000019  loss: 0.0332  time: 0.5776  data: 0.0001  max mem: 15660
Train Epoch: [1] Total time: 0:11:02 (0.5890 s / it)
Averaged stats: lr: 0.0000  loss: 0.1036
Generate VQA test result:  [  0/563]  eta: 0:05:05    time: 0.5419  data: 0.3169  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2093  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2093 s / it)
0.9817939609236235
Train Epoch: [2]  [   0/1125]  eta: 0:32:10  lr: 0.000017  loss: 0.0477  time: 1.7157  data: 0.8089  max mem: 15660
Train Epoch: [2]  [  50/1125]  eta: 0:10:59  lr: 0.000017  loss: 0.0362  time: 0.5889  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 100/1125]  eta: 0:10:18  lr: 0.000017  loss: 0.1326  time: 0.5874  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 150/1125]  eta: 0:09:44  lr: 0.000017  loss: 0.0689  time: 0.5952  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 200/1125]  eta: 0:09:13  lr: 0.000017  loss: 0.0973  time: 0.5941  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 250/1125]  eta: 0:08:42  lr: 0.000017  loss: 0.0101  time: 0.5912  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 300/1125]  eta: 0:08:10  lr: 0.000017  loss: 0.0011  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 350/1125]  eta: 0:07:40  lr: 0.000017  loss: 0.0061  time: 0.5918  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 400/1125]  eta: 0:07:10  lr: 0.000017  loss: 0.0732  time: 0.5964  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 450/1125]  eta: 0:06:40  lr: 0.000017  loss: 0.0558  time: 0.5880  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 500/1125]  eta: 0:06:10  lr: 0.000017  loss: 0.0198  time: 0.5894  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 550/1125]  eta: 0:05:40  lr: 0.000017  loss: 0.0227  time: 0.5912  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 600/1125]  eta: 0:05:11  lr: 0.000017  loss: 0.0213  time: 0.5943  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 650/1125]  eta: 0:04:41  lr: 0.000017  loss: 0.0169  time: 0.5944  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 700/1125]  eta: 0:04:11  lr: 0.000017  loss: 0.0362  time: 0.5941  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 750/1125]  eta: 0:03:42  lr: 0.000017  loss: 0.0703  time: 0.5940  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 800/1125]  eta: 0:03:12  lr: 0.000017  loss: 0.0145  time: 0.5890  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 850/1125]  eta: 0:02:42  lr: 0.000017  loss: 0.0082  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 900/1125]  eta: 0:02:13  lr: 0.000017  loss: 0.1162  time: 0.5853  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 950/1125]  eta: 0:01:43  lr: 0.000017  loss: 0.0174  time: 0.5889  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1000/1125]  eta: 0:01:13  lr: 0.000017  loss: 0.0028  time: 0.5847  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1050/1125]  eta: 0:00:44  lr: 0.000017  loss: 0.0229  time: 0.5886  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1100/1125]  eta: 0:00:14  lr: 0.000017  loss: 0.1406  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1124/1125]  eta: 0:00:00  lr: 0.000017  loss: 0.0059  time: 0.5708  data: 0.0001  max mem: 15660
Train Epoch: [2] Total time: 0:11:04 (0.5904 s / it)
Averaged stats: lr: 0.0000  loss: 0.0497
Generate VQA test result:  [  0/563]  eta: 0:05:08    time: 0.5487  data: 0.3238  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2091  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2094  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2093  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2093  data: 0.0002  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2100  data: 0.0002  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2095  data: 0.0002  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2101  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2101 s / it)
0.9817939609236235
Train Epoch: [3]  [   0/1125]  eta: 0:35:03  lr: 0.000014  loss: 0.0033  time: 1.8693  data: 1.1111  max mem: 15660
Train Epoch: [3]  [  50/1125]  eta: 0:10:58  lr: 0.000014  loss: 0.1439  time: 0.5899  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 100/1125]  eta: 0:10:17  lr: 0.000014  loss: 0.0042  time: 0.5863  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 150/1125]  eta: 0:09:40  lr: 0.000014  loss: 0.0586  time: 0.5778  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 200/1125]  eta: 0:09:09  lr: 0.000014  loss: 0.0325  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 250/1125]  eta: 0:08:38  lr: 0.000014  loss: 0.0040  time: 0.5841  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 300/1125]  eta: 0:08:08  lr: 0.000014  loss: 0.1699  time: 0.5848  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 350/1125]  eta: 0:07:37  lr: 0.000014  loss: 0.0085  time: 0.5919  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 400/1125]  eta: 0:07:08  lr: 0.000014  loss: 0.0143  time: 0.5892  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 450/1125]  eta: 0:06:38  lr: 0.000014  loss: 0.0029  time: 0.5898  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 500/1125]  eta: 0:06:09  lr: 0.000014  loss: 0.0450  time: 0.5933  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 550/1125]  eta: 0:05:39  lr: 0.000014  loss: 0.1052  time: 0.5980  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 600/1125]  eta: 0:05:10  lr: 0.000014  loss: 0.0032  time: 0.5888  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 650/1125]  eta: 0:04:40  lr: 0.000014  loss: 0.0012  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 700/1125]  eta: 0:04:10  lr: 0.000014  loss: 0.1193  time: 0.5854  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 750/1125]  eta: 0:03:41  lr: 0.000014  loss: 0.0188  time: 0.5988  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 800/1125]  eta: 0:03:11  lr: 0.000014  loss: 0.0037  time: 0.5865  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 850/1125]  eta: 0:02:42  lr: 0.000014  loss: 0.2473  time: 0.5835  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 900/1125]  eta: 0:02:12  lr: 0.000014  loss: 0.0021  time: 0.5909  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 950/1125]  eta: 0:01:43  lr: 0.000014  loss: 0.0321  time: 0.5872  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1000/1125]  eta: 0:01:13  lr: 0.000014  loss: 0.0024  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1050/1125]  eta: 0:00:44  lr: 0.000014  loss: 0.0060  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1100/1125]  eta: 0:00:14  lr: 0.000014  loss: 0.0045  time: 0.5851  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1124/1125]  eta: 0:00:00  lr: 0.000014  loss: 0.0148  time: 0.5727  data: 0.0002  max mem: 15660
Train Epoch: [3] Total time: 0:11:02 (0.5890 s / it)
Averaged stats: lr: 0.0000  loss: 0.0406
Generate VQA test result:  [  0/563]  eta: 0:05:08    time: 0.5471  data: 0.3175  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2066  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2091 s / it)
0.9913410301953819
Train Epoch: [4]  [   0/1125]  eta: 0:30:19  lr: 0.000011  loss: 0.0044  time: 1.6169  data: 0.8994  max mem: 15660
Train Epoch: [4]  [  50/1125]  eta: 0:10:58  lr: 0.000011  loss: 0.0017  time: 0.5904  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 100/1125]  eta: 0:10:15  lr: 0.000011  loss: 0.0007  time: 0.5804  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 150/1125]  eta: 0:09:42  lr: 0.000011  loss: 0.0005  time: 0.5975  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 200/1125]  eta: 0:09:10  lr: 0.000011  loss: 0.0276  time: 0.5832  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 250/1125]  eta: 0:08:38  lr: 0.000011  loss: 0.0023  time: 0.5776  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 300/1125]  eta: 0:08:08  lr: 0.000011  loss: 0.0005  time: 0.5862  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 350/1125]  eta: 0:07:38  lr: 0.000011  loss: 0.0013  time: 0.5957  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 400/1125]  eta: 0:07:08  lr: 0.000011  loss: 0.0053  time: 0.5863  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 450/1125]  eta: 0:06:39  lr: 0.000011  loss: 0.0005  time: 0.5881  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 500/1125]  eta: 0:06:09  lr: 0.000011  loss: 0.0129  time: 0.5849  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 550/1125]  eta: 0:05:39  lr: 0.000011  loss: 0.0060  time: 0.5951  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 600/1125]  eta: 0:05:09  lr: 0.000011  loss: 0.0014  time: 0.5917  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 650/1125]  eta: 0:04:40  lr: 0.000011  loss: 0.0021  time: 0.5975  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 700/1125]  eta: 0:04:10  lr: 0.000011  loss: 0.0008  time: 0.5842  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 750/1125]  eta: 0:03:41  lr: 0.000011  loss: 0.0062  time: 0.5876  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 800/1125]  eta: 0:03:11  lr: 0.000011  loss: 0.0008  time: 0.5782  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 850/1125]  eta: 0:02:42  lr: 0.000011  loss: 0.0918  time: 0.5860  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 900/1125]  eta: 0:02:12  lr: 0.000011  loss: 0.0029  time: 0.5852  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 950/1125]  eta: 0:01:43  lr: 0.000011  loss: 0.0010  time: 0.5825  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1000/1125]  eta: 0:01:13  lr: 0.000011  loss: 0.0029  time: 0.5841  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1050/1125]  eta: 0:00:44  lr: 0.000011  loss: 0.0027  time: 0.5922  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1100/1125]  eta: 0:00:14  lr: 0.000011  loss: 0.0014  time: 0.5845  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1124/1125]  eta: 0:00:00  lr: 0.000011  loss: 0.1974  time: 0.5715  data: 0.0002  max mem: 15660
Train Epoch: [4] Total time: 0:11:02 (0.5887 s / it)
Averaged stats: lr: 0.0000  loss: 0.0184
Generate VQA test result:  [  0/563]  eta: 0:05:24    time: 0.5767  data: 0.3520  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2100  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2092  data: 0.0002  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2097 s / it)
0.9948934280639432
Train Epoch: [5]  [   0/1125]  eta: 0:34:55  lr: 0.000007  loss: 0.0007  time: 1.8628  data: 1.1704  max mem: 15660
Train Epoch: [5]  [  50/1125]  eta: 0:10:56  lr: 0.000007  loss: 0.0041  time: 0.5836  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 100/1125]  eta: 0:10:11  lr: 0.000007  loss: 0.0351  time: 0.5781  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 150/1125]  eta: 0:09:37  lr: 0.000007  loss: 0.0027  time: 0.5896  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 200/1125]  eta: 0:09:07  lr: 0.000007  loss: 0.0006  time: 0.5797  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 250/1125]  eta: 0:08:36  lr: 0.000007  loss: 0.0758  time: 0.5893  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 300/1125]  eta: 0:08:06  lr: 0.000007  loss: 0.0005  time: 0.5909  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 350/1125]  eta: 0:07:37  lr: 0.000007  loss: 0.0007  time: 0.5855  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 400/1125]  eta: 0:07:07  lr: 0.000007  loss: 0.0009  time: 0.5873  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 450/1125]  eta: 0:06:37  lr: 0.000007  loss: 0.0012  time: 0.5875  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 500/1125]  eta: 0:06:08  lr: 0.000007  loss: 0.0019  time: 0.5907  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 550/1125]  eta: 0:05:38  lr: 0.000007  loss: 0.0007  time: 0.5808  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 600/1125]  eta: 0:05:09  lr: 0.000007  loss: 0.0031  time: 0.5737  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 650/1125]  eta: 0:04:39  lr: 0.000007  loss: 0.0006  time: 0.5921  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 700/1125]  eta: 0:04:10  lr: 0.000007  loss: 0.0076  time: 0.5956  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 750/1125]  eta: 0:03:40  lr: 0.000007  loss: 0.0013  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 800/1125]  eta: 0:03:11  lr: 0.000007  loss: 0.0042  time: 0.5805  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 850/1125]  eta: 0:02:41  lr: 0.000007  loss: 0.0016  time: 0.5961  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 900/1125]  eta: 0:02:12  lr: 0.000007  loss: 0.0004  time: 0.5817  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 950/1125]  eta: 0:01:42  lr: 0.000007  loss: 0.0003  time: 0.5858  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1000/1125]  eta: 0:01:13  lr: 0.000007  loss: 0.0003  time: 0.5912  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1050/1125]  eta: 0:00:44  lr: 0.000007  loss: 0.0002  time: 0.5823  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1100/1125]  eta: 0:00:14  lr: 0.000007  loss: 0.0020  time: 0.5837  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1124/1125]  eta: 0:00:00  lr: 0.000007  loss: 0.0074  time: 0.5751  data: 0.0002  max mem: 15660
Train Epoch: [5] Total time: 0:11:01 (0.5880 s / it)
Averaged stats: lr: 0.0000  loss: 0.0122
Generate VQA test result:  [  0/563]  eta: 0:05:01    time: 0.5352  data: 0.3010  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2089  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2090  data: 0.0002  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2088  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2099 s / it)
0.9873445825932504
Train Epoch: [6]  [   0/1125]  eta: 0:34:12  lr: 0.000004  loss: 0.0012  time: 1.8241  data: 0.9032  max mem: 15660
Train Epoch: [6]  [  50/1125]  eta: 0:10:58  lr: 0.000004  loss: 0.0007  time: 0.5913  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 100/1125]  eta: 0:10:15  lr: 0.000004  loss: 0.0010  time: 0.5861  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 150/1125]  eta: 0:09:40  lr: 0.000004  loss: 0.0025  time: 0.5809  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 200/1125]  eta: 0:09:10  lr: 0.000004  loss: 0.0010  time: 0.5923  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 250/1125]  eta: 0:08:38  lr: 0.000004  loss: 0.0008  time: 0.5838  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 300/1125]  eta: 0:08:08  lr: 0.000004  loss: 0.0012  time: 0.5927  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 350/1125]  eta: 0:07:39  lr: 0.000004  loss: 0.0007  time: 0.5952  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 400/1125]  eta: 0:07:10  lr: 0.000004  loss: 0.0011  time: 0.5999  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 450/1125]  eta: 0:06:40  lr: 0.000004  loss: 0.0024  time: 0.5806  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 500/1125]  eta: 0:06:09  lr: 0.000004  loss: 0.0006  time: 0.5838  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 550/1125]  eta: 0:05:40  lr: 0.000004  loss: 0.0008  time: 0.5912  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 600/1125]  eta: 0:05:10  lr: 0.000004  loss: 0.0007  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 650/1125]  eta: 0:04:40  lr: 0.000004  loss: 0.0008  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 700/1125]  eta: 0:04:11  lr: 0.000004  loss: 0.0237  time: 0.5852  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 750/1125]  eta: 0:03:41  lr: 0.000004  loss: 0.0078  time: 0.5941  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 800/1125]  eta: 0:03:12  lr: 0.000004  loss: 0.0009  time: 0.5835  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 850/1125]  eta: 0:02:42  lr: 0.000004  loss: 0.0008  time: 0.5898  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 900/1125]  eta: 0:02:13  lr: 0.000004  loss: 0.0003  time: 0.5924  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 950/1125]  eta: 0:01:43  lr: 0.000004  loss: 0.0013  time: 0.5861  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1000/1125]  eta: 0:01:13  lr: 0.000004  loss: 0.0010  time: 0.5884  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1050/1125]  eta: 0:00:44  lr: 0.000004  loss: 0.0005  time: 0.5807  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1100/1125]  eta: 0:00:14  lr: 0.000004  loss: 0.1608  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1124/1125]  eta: 0:00:00  lr: 0.000004  loss: 0.0005  time: 0.5795  data: 0.0002  max mem: 15660
Train Epoch: [6] Total time: 0:11:04 (0.5906 s / it)
Averaged stats: lr: 0.0000  loss: 0.0111
Generate VQA test result:  [  0/563]  eta: 0:05:28    time: 0.5837  data: 0.3538  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:51    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2099  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2103  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2099  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2100  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2106 s / it)
0.9962255772646537
Train Epoch: [7]  [   0/1125]  eta: 0:30:29  lr: 0.000002  loss: 0.0004  time: 1.6261  data: 0.6917  max mem: 15660
Train Epoch: [7]  [  50/1125]  eta: 0:10:50  lr: 0.000002  loss: 0.0011  time: 0.5871  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 100/1125]  eta: 0:10:09  lr: 0.000002  loss: 0.0002  time: 0.5827  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 150/1125]  eta: 0:09:37  lr: 0.000002  loss: 0.0014  time: 0.5895  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 200/1125]  eta: 0:09:07  lr: 0.000002  loss: 0.0013  time: 0.5921  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 250/1125]  eta: 0:08:35  lr: 0.000002  loss: 0.0005  time: 0.5758  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 300/1125]  eta: 0:08:06  lr: 0.000002  loss: 0.0010  time: 0.5909  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 350/1125]  eta: 0:07:36  lr: 0.000002  loss: 0.0005  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 400/1125]  eta: 0:07:07  lr: 0.000002  loss: 0.0009  time: 0.5944  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 450/1125]  eta: 0:06:38  lr: 0.000002  loss: 0.0041  time: 0.6020  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 500/1125]  eta: 0:06:08  lr: 0.000002  loss: 0.0004  time: 0.5897  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 550/1125]  eta: 0:05:39  lr: 0.000002  loss: 0.0005  time: 0.5807  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 600/1125]  eta: 0:05:09  lr: 0.000002  loss: 0.0003  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 650/1125]  eta: 0:04:39  lr: 0.000002  loss: 0.0004  time: 0.5861  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 700/1125]  eta: 0:04:10  lr: 0.000002  loss: 0.0006  time: 0.5845  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 750/1125]  eta: 0:03:40  lr: 0.000002  loss: 0.0009  time: 0.5871  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 800/1125]  eta: 0:03:11  lr: 0.000002  loss: 0.0007  time: 0.5802  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 850/1125]  eta: 0:02:41  lr: 0.000002  loss: 0.0003  time: 0.5911  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 900/1125]  eta: 0:02:12  lr: 0.000002  loss: 0.0005  time: 0.5797  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 950/1125]  eta: 0:01:42  lr: 0.000002  loss: 0.0006  time: 0.5878  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1000/1125]  eta: 0:01:13  lr: 0.000002  loss: 0.0018  time: 0.5856  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1050/1125]  eta: 0:00:44  lr: 0.000002  loss: 0.0006  time: 0.5881  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1100/1125]  eta: 0:00:14  lr: 0.000002  loss: 0.0002  time: 0.5880  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1124/1125]  eta: 0:00:00  lr: 0.000002  loss: 0.0151  time: 0.5797  data: 0.0001  max mem: 15660
Train Epoch: [7] Total time: 0:11:01 (0.5879 s / it)
Averaged stats: lr: 0.0000  loss: 0.0064
Generate VQA test result:  [  0/563]  eta: 0:05:29    time: 0.5848  data: 0.3531  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2094  data: 0.0002  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2096  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2097  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2068  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2096 s / it)
0.9964476021314387
Generate VQA test result:  [  0/563]  eta: 0:05:18    time: 0.5653  data: 0.3360  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2095  data: 0.0002  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2094  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2099 s / it)
result file saved to output_optimal/vqa/result/vqa_result_epoch7.json
Training time 1:47:00