Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['text_encoder.encoder.layer.12.attention.self.query.weight', 'text_encoder.encoder.layer.12.attention.self.query.bias', 'text_encoder.encoder.layer.12.attention.self.key.weight', 'text_encoder.encoder.layer.12.attention.self.key.bias', 'text_encoder.encoder.layer.12.attention.self.value.weight', 'text_encoder.encoder.layer.12.attention.self.value.bias', 'text_encoder.encoder.layer.12.attention.output.dense.weight', 'text_encoder.encoder.layer.12.attention.output.dense.bias', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.crossattention.self.query.weight', 'text_encoder.encoder.layer.12.crossattention.self.query.bias', 'text_encoder.encoder.layer.12.crossattention.self.key.weight', 'text_encoder.encoder.layer.12.crossattention.self.key.bias', 'text_encoder.encoder.layer.12.crossattention.self.value.weight', 'text_encoder.encoder.layer.12.crossattention.self.value.bias', 'text_encoder.encoder.layer.12.crossattention.output.dense.weight', 'text_encoder.encoder.layer.12.crossattention.output.dense.bias', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.intermediate.dense.weight', 'text_encoder.encoder.layer.12.intermediate.dense.bias', 'text_encoder.encoder.layer.12.output.dense.weight', 'text_encoder.encoder.layer.12.output.dense.bias', 'text_encoder.encoder.layer.12.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.attention.self.query.weight', 'text_encoder.encoder.layer.13.attention.self.query.bias', 'text_encoder.encoder.layer.13.attention.self.key.weight', 'text_encoder.encoder.layer.13.attention.self.key.bias', 'text_encoder.encoder.layer.13.attention.self.value.weight', 'text_encoder.encoder.layer.13.attention.self.value.bias', 'text_encoder.encoder.layer.13.attention.output.dense.weight', 'text_encoder.encoder.layer.13.attention.output.dense.bias', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.crossattention.self.query.weight', 'text_encoder.encoder.layer.13.crossattention.self.query.bias', 'text_encoder.encoder.layer.13.crossattention.self.key.weight', 'text_encoder.encoder.layer.13.crossattention.self.key.bias', 'text_encoder.encoder.layer.13.crossattention.self.value.weight', 'text_encoder.encoder.layer.13.crossattention.self.value.bias', 'text_encoder.encoder.layer.13.crossattention.output.dense.weight', 'text_encoder.encoder.layer.13.crossattention.output.dense.bias', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.intermediate.dense.weight', 'text_encoder.encoder.layer.13.intermediate.dense.bias', 'text_encoder.encoder.layer.13.output.dense.weight', 'text_encoder.encoder.layer.13.output.dense.bias', 'text_encoder.encoder.layer.13.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.attention.self.query.weight', 'text_encoder.encoder.layer.14.attention.self.query.bias', 'text_encoder.encoder.layer.14.attention.self.key.weight', 'text_encoder.encoder.layer.14.attention.self.key.bias', 'text_encoder.encoder.layer.14.attention.self.value.weight', 'text_encoder.encoder.layer.14.attention.self.value.bias', 'text_encoder.encoder.layer.14.attention.output.dense.weight', 'text_encoder.encoder.layer.14.attention.output.dense.bias', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.crossattention.self.query.weight', 'text_encoder.encoder.layer.14.crossattention.self.query.bias', 'text_encoder.encoder.layer.14.crossattention.self.key.weight', 'text_encoder.encoder.layer.14.crossattention.self.key.bias', 'text_encoder.encoder.layer.14.crossattention.self.value.weight', 'text_encoder.encoder.layer.14.crossattention.self.value.bias', 'text_encoder.encoder.layer.14.crossattention.output.dense.weight', 'text_encoder.encoder.layer.14.crossattention.output.dense.bias', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.intermediate.dense.weight', 'text_encoder.encoder.layer.14.intermediate.dense.bias', 'text_encoder.encoder.layer.14.output.dense.weight', 'text_encoder.encoder.layer.14.output.dense.bias', 'text_encoder.encoder.layer.14.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.attention.self.query.weight', 'text_encoder.encoder.layer.15.attention.self.query.bias', 'text_encoder.encoder.layer.15.attention.self.key.weight', 'text_encoder.encoder.layer.15.attention.self.key.bias', 'text_encoder.encoder.layer.15.attention.self.value.weight', 'text_encoder.encoder.layer.15.attention.self.value.bias', 'text_encoder.encoder.layer.15.attention.output.dense.weight', 'text_encoder.encoder.layer.15.attention.output.dense.bias', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.crossattention.self.query.weight', 'text_encoder.encoder.layer.15.crossattention.self.query.bias', 'text_encoder.encoder.layer.15.crossattention.self.key.weight', 'text_encoder.encoder.layer.15.crossattention.self.key.bias', 'text_encoder.encoder.layer.15.crossattention.self.value.weight', 'text_encoder.encoder.layer.15.crossattention.self.value.bias', 'text_encoder.encoder.layer.15.crossattention.output.dense.weight', 'text_encoder.encoder.layer.15.crossattention.output.dense.bias', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.intermediate.dense.weight', 'text_encoder.encoder.layer.15.intermediate.dense.bias', 'text_encoder.encoder.layer.15.output.dense.weight', 'text_encoder.encoder.layer.15.output.dense.bias', 'text_encoder.encoder.layer.15.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.output.LayerNorm.bias', 'inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [   0/1125]  eta: 0:52:15  lr: 0.000010  loss: 1.6340  time: 2.7874  data: 0.7413  max mem: 11560
Train Epoch: [0]  [  50/1125]  eta: 0:11:15  lr: 0.000010  loss: 0.4820  time: 0.5911  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 100/1125]  eta: 0:10:20  lr: 0.000010  loss: 0.5325  time: 0.5730  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 150/1125]  eta: 0:09:44  lr: 0.000058  loss: 0.4744  time: 0.5877  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 200/1125]  eta: 0:09:10  lr: 0.000058  loss: 0.5200  time: 0.5803  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 250/1125]  eta: 0:08:40  lr: 0.000105  loss: 0.4612  time: 0.5889  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 300/1125]  eta: 0:08:09  lr: 0.000105  loss: 0.4376  time: 0.5959  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 350/1125]  eta: 0:07:39  lr: 0.000152  loss: 0.8455  time: 0.5965  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 400/1125]  eta: 0:07:09  lr: 0.000152  loss: 0.6921  time: 0.5853  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 450/1125]  eta: 0:06:39  lr: 0.000200  loss: 0.5982  time: 0.5945  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 500/1125]  eta: 0:06:10  lr: 0.000200  loss: 0.7819  time: 0.5929  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 550/1125]  eta: 0:05:39  lr: 0.000200  loss: 0.5175  time: 0.5828  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 600/1125]  eta: 0:05:10  lr: 0.000200  loss: 0.8207  time: 0.5819  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 650/1125]  eta: 0:04:40  lr: 0.000200  loss: 0.9748  time: 0.5900  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 700/1125]  eta: 0:04:10  lr: 0.000200  loss: 0.9973  time: 0.5848  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 750/1125]  eta: 0:03:41  lr: 0.000200  loss: 0.9868  time: 0.5801  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 800/1125]  eta: 0:03:11  lr: 0.000200  loss: 1.0957  time: 0.5913  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 850/1125]  eta: 0:02:42  lr: 0.000200  loss: 1.0780  time: 0.5904  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 900/1125]  eta: 0:02:12  lr: 0.000200  loss: 1.0532  time: 0.5835  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 950/1125]  eta: 0:01:43  lr: 0.000200  loss: 1.1299  time: 0.5860  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1000/1125]  eta: 0:01:13  lr: 0.000200  loss: 0.9976  time: 0.5877  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1050/1125]  eta: 0:00:44  lr: 0.000200  loss: 1.0103  time: 0.5841  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1100/1125]  eta: 0:00:14  lr: 0.000200  loss: 0.9633  time: 0.5888  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1124/1125]  eta: 0:00:00  lr: 0.000200  loss: 1.2975  time: 0.5755  data: 0.0002  max mem: 15660
Train Epoch: [0] Total time: 0:11:02 (0.5888 s / it)
Averaged stats: lr: 0.0002  loss: 0.8482
Generate VQA test result:  [  0/563]  eta: 0:07:45    time: 0.8274  data: 0.3082  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:52    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2061  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2130  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2069  data: 0.0002  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2077  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2066  data: 0.0002  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2060  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2052  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2085 s / it)
0.13898756660746003
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Train Epoch: [1]  [   0/1125]  eta: 0:33:04  lr: 0.000192  loss: 1.0332  time: 1.7644  data: 1.0349  max mem: 15660
Train Epoch: [1]  [  50/1125]  eta: 0:10:54  lr: 0.000192  loss: 1.0072  time: 0.5877  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 100/1125]  eta: 0:10:11  lr: 0.000192  loss: 0.9865  time: 0.5877  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 150/1125]  eta: 0:09:36  lr: 0.000192  loss: 1.3186  time: 0.5859  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 200/1125]  eta: 0:09:06  lr: 0.000192  loss: 1.1316  time: 0.5848  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 250/1125]  eta: 0:08:36  lr: 0.000192  loss: 1.1141  time: 0.5876  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 300/1125]  eta: 0:08:07  lr: 0.000192  loss: 1.1112  time: 0.5957  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 350/1125]  eta: 0:07:37  lr: 0.000192  loss: 1.1256  time: 0.5950  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 400/1125]  eta: 0:07:07  lr: 0.000192  loss: 1.0046  time: 0.5900  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 450/1125]  eta: 0:06:38  lr: 0.000192  loss: 0.9649  time: 0.5806  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 500/1125]  eta: 0:06:08  lr: 0.000192  loss: 0.8902  time: 0.5978  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 550/1125]  eta: 0:05:38  lr: 0.000192  loss: 1.0600  time: 0.5876  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 600/1125]  eta: 0:05:09  lr: 0.000192  loss: 0.9547  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 650/1125]  eta: 0:04:39  lr: 0.000192  loss: 1.0836  time: 0.5803  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 700/1125]  eta: 0:04:10  lr: 0.000192  loss: 1.1388  time: 0.5908  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 750/1125]  eta: 0:03:40  lr: 0.000192  loss: 1.0510  time: 0.5861  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 800/1125]  eta: 0:03:11  lr: 0.000192  loss: 1.0207  time: 0.5928  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 850/1125]  eta: 0:02:41  lr: 0.000192  loss: 1.0626  time: 0.5768  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 900/1125]  eta: 0:02:12  lr: 0.000192  loss: 1.1171  time: 0.5960  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 950/1125]  eta: 0:01:42  lr: 0.000192  loss: 0.9801  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1000/1125]  eta: 0:01:13  lr: 0.000192  loss: 1.0151  time: 0.5838  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1050/1125]  eta: 0:00:44  lr: 0.000192  loss: 1.0228  time: 0.5753  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1100/1125]  eta: 0:00:14  lr: 0.000192  loss: 1.1152  time: 0.5780  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1124/1125]  eta: 0:00:00  lr: 0.000192  loss: 1.1022  time: 0.5690  data: 0.0002  max mem: 15660
Train Epoch: [1] Total time: 0:11:01 (0.5877 s / it)
Averaged stats: lr: 0.0002  loss: 1.0453
Generate VQA test result:  [  0/563]  eta: 0:05:26    time: 0.5804  data: 0.3563  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2061  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2066  data: 0.0002  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2062  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2065  data: 0.0002  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2063  data: 0.0002  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2060  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:56 (0.2074 s / it)
0.23201598579040852
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Train Epoch: [2]  [   0/1125]  eta: 0:31:36  lr: 0.000171  loss: 1.0023  time: 1.6860  data: 0.9729  max mem: 15660
Train Epoch: [2]  [  50/1125]  eta: 0:10:58  lr: 0.000171  loss: 1.0128  time: 0.5934  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 100/1125]  eta: 0:10:15  lr: 0.000171  loss: 1.0136  time: 0.5908  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 150/1125]  eta: 0:09:40  lr: 0.000171  loss: 0.9421  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 200/1125]  eta: 0:09:09  lr: 0.000171  loss: 0.9118  time: 0.5944  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 250/1125]  eta: 0:08:39  lr: 0.000171  loss: 1.0018  time: 0.5824  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 300/1125]  eta: 0:08:08  lr: 0.000171  loss: 1.0377  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 350/1125]  eta: 0:07:38  lr: 0.000171  loss: 1.1695  time: 0.5828  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 400/1125]  eta: 0:07:08  lr: 0.000171  loss: 1.0269  time: 0.5892  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 450/1125]  eta: 0:06:38  lr: 0.000171  loss: 0.9958  time: 0.5907  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 500/1125]  eta: 0:06:08  lr: 0.000171  loss: 1.0674  time: 0.5828  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 550/1125]  eta: 0:05:38  lr: 0.000171  loss: 0.9831  time: 0.5747  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 600/1125]  eta: 0:05:09  lr: 0.000171  loss: 1.0402  time: 0.5890  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 650/1125]  eta: 0:04:39  lr: 0.000171  loss: 1.0783  time: 0.5777  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 700/1125]  eta: 0:04:10  lr: 0.000171  loss: 1.0886  time: 0.5821  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 750/1125]  eta: 0:03:40  lr: 0.000171  loss: 0.9954  time: 0.5862  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 800/1125]  eta: 0:03:10  lr: 0.000171  loss: 1.0180  time: 0.5838  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 850/1125]  eta: 0:02:41  lr: 0.000171  loss: 0.8795  time: 0.5765  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 900/1125]  eta: 0:02:12  lr: 0.000171  loss: 1.0433  time: 0.5933  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 950/1125]  eta: 0:01:42  lr: 0.000171  loss: 1.0017  time: 0.5760  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1000/1125]  eta: 0:01:13  lr: 0.000171  loss: 1.0097  time: 0.5860  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1050/1125]  eta: 0:00:44  lr: 0.000171  loss: 1.0729  time: 0.5863  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1100/1125]  eta: 0:00:14  lr: 0.000171  loss: 0.9998  time: 0.5876  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1124/1125]  eta: 0:00:00  lr: 0.000171  loss: 1.0216  time: 0.5744  data: 0.0002  max mem: 15660
Train Epoch: [2] Total time: 0:11:00 (0.5871 s / it)
Averaged stats: lr: 0.0002  loss: 1.0376
Generate VQA test result:  [  0/563]  eta: 0:05:05    time: 0.5422  data: 0.3153  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2077  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2083  data: 0.0002  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2098  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2084  data: 0.0002  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2082  data: 0.0002  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2076  data: 0.0002  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2095  data: 0.0001  max mem: 15660
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2089 s / it)
0.23201598579040852
Train Epoch: [3]  [   0/1125]  eta: 0:36:17  lr: 0.000139  loss: 0.9487  time: 1.9358  data: 1.2255  max mem: 15660
Train Epoch: [3]  [  50/1125]  eta: 0:10:52  lr: 0.000139  loss: 1.0551  time: 0.5832  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 100/1125]  eta: 0:10:10  lr: 0.000139  loss: 1.0107  time: 0.5863  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 150/1125]  eta: 0:09:38  lr: 0.000139  loss: 1.0143  time: 0.5955  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 200/1125]  eta: 0:09:08  lr: 0.000139  loss: 1.8234  time: 0.5846  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 250/1125]  eta: 0:08:37  lr: 0.000139  loss: 1.8030  time: 0.5829  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 300/1125]  eta: 0:08:07  lr: 0.000139  loss: 1.7191  time: 0.5805  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 350/1125]  eta: 0:07:37  lr: 0.000139  loss: 1.8108  time: 0.5912  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 400/1125]  eta: 0:07:07  lr: 0.000139  loss: 1.7151  time: 0.5793  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 450/1125]  eta: 0:06:37  lr: 0.000139  loss: 1.7561  time: 0.5873  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 500/1125]  eta: 0:06:08  lr: 0.000139  loss: 1.7142  time: 0.5875  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 550/1125]  eta: 0:05:38  lr: 0.000139  loss: 1.7387  time: 0.5991  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 600/1125]  eta: 0:05:09  lr: 0.000139  loss: 1.7581  time: 0.5836  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 650/1125]  eta: 0:04:39  lr: 0.000139  loss: 1.7090  time: 0.5794  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 700/1125]  eta: 0:04:10  lr: 0.000139  loss: 1.6480  time: 0.5856  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 750/1125]  eta: 0:03:40  lr: 0.000139  loss: 1.7992  time: 0.5891  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 800/1125]  eta: 0:03:11  lr: 0.000139  loss: 1.6524  time: 0.5803  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 850/1125]  eta: 0:02:41  lr: 0.000139  loss: 1.7578  time: 0.5901  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 900/1125]  eta: 0:02:12  lr: 0.000139  loss: 1.6567  time: 0.5781  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 950/1125]  eta: 0:01:42  lr: 0.000139  loss: 1.7337  time: 0.5801  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1000/1125]  eta: 0:01:13  lr: 0.000139  loss: 1.7421  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1050/1125]  eta: 0:00:44  lr: 0.000139  loss: 1.8522  time: 0.5925  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1100/1125]  eta: 0:00:14  lr: 0.000139  loss: 1.6842  time: 0.5806  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1124/1125]  eta: 0:00:00  lr: 0.000139  loss: 1.8312  time: 0.5766  data: 0.0002  max mem: 15660
Train Epoch: [3] Total time: 0:11:01 (0.5877 s / it)
Averaged stats: lr: 0.0001  loss: 1.6469
Generate VQA test result:  [  0/563]  eta: 0:05:08    time: 0.5485  data: 0.3181  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2072  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2069  data: 0.0002  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2064  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2056  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2067  data: 0.0002  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2073  data: 0.0002  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2069  data: 0.0002  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2069  data: 0.0001  max mem: 15660
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:56 (0.2073 s / it)
0.18095026642984013
Train Epoch: [4]  [   0/1125]  eta: 0:36:30  lr: 0.000101  loss: 1.6740  time: 1.9474  data: 1.1681  max mem: 15660
Train Epoch: [4]  [  50/1125]  eta: 0:10:58  lr: 0.000101  loss: 1.7996  time: 0.5915  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 100/1125]  eta: 0:10:17  lr: 0.000101  loss: 1.7013  time: 0.5986  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 150/1125]  eta: 0:09:40  lr: 0.000101  loss: 1.6666  time: 0.5831  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 200/1125]  eta: 0:09:09  lr: 0.000101  loss: 1.7881  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 250/1125]  eta: 0:08:38  lr: 0.000101  loss: 1.7839  time: 0.5905  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 300/1125]  eta: 0:08:07  lr: 0.000101  loss: 1.7825  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 350/1125]  eta: 0:07:37  lr: 0.000101  loss: 1.8237  time: 0.6007  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 400/1125]  eta: 0:07:07  lr: 0.000101  loss: 1.8684  time: 0.5877  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 450/1125]  eta: 0:06:37  lr: 0.000101  loss: 1.7121  time: 0.5811  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 500/1125]  eta: 0:06:07  lr: 0.000101  loss: 1.7892  time: 0.5805  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 550/1125]  eta: 0:05:38  lr: 0.000101  loss: 1.7116  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 600/1125]  eta: 0:05:08  lr: 0.000101  loss: 1.6857  time: 0.5865  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 650/1125]  eta: 0:04:39  lr: 0.000101  loss: 1.1653  time: 0.5884  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 700/1125]  eta: 0:04:10  lr: 0.000101  loss: 1.7034  time: 0.5896  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 750/1125]  eta: 0:03:40  lr: 0.000101  loss: 1.6337  time: 0.5898  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 800/1125]  eta: 0:03:11  lr: 0.000101  loss: 1.7697  time: 0.5917  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 850/1125]  eta: 0:02:41  lr: 0.000101  loss: 1.6755  time: 0.5846  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 900/1125]  eta: 0:02:12  lr: 0.000101  loss: 1.6619  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 950/1125]  eta: 0:01:42  lr: 0.000101  loss: 1.7681  time: 0.5825  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1000/1125]  eta: 0:01:13  lr: 0.000101  loss: 1.6337  time: 0.5804  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1050/1125]  eta: 0:00:44  lr: 0.000101  loss: 1.7621  time: 0.5795  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1100/1125]  eta: 0:00:14  lr: 0.000101  loss: 1.7809  time: 0.5832  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1124/1125]  eta: 0:00:00  lr: 0.000101  loss: 1.8091  time: 0.5828  data: 0.0002  max mem: 15660
Train Epoch: [4] Total time: 0:11:01 (0.5876 s / it)
Averaged stats: lr: 0.0001  loss: 1.7221
Generate VQA test result:  [  0/563]  eta: 0:05:04    time: 0.5411  data: 0.3125  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2073  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2066  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2062  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2061  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2045  data: 0.0001  max mem: 15660
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Generate VQA test result: Total time: 0:01:56 (0.2075 s / it)
0.23201598579040852
Train Epoch: [5]  [   0/1125]  eta: 0:34:10  lr: 0.000062  loss: 1.7238  time: 1.8228  data: 0.9937  max mem: 15660
Train Epoch: [5]  [  50/1125]  eta: 0:11:00  lr: 0.000062  loss: 1.6507  time: 0.5933  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 100/1125]  eta: 0:10:15  lr: 0.000062  loss: 1.7125  time: 0.5987  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 150/1125]  eta: 0:09:40  lr: 0.000062  loss: 1.6274  time: 0.5849  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 200/1125]  eta: 0:09:08  lr: 0.000062  loss: 1.5133  time: 0.5877  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 250/1125]  eta: 0:08:38  lr: 0.000062  loss: 1.6997  time: 0.5915  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 300/1125]  eta: 0:08:08  lr: 0.000062  loss: 1.5545  time: 0.5893  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 350/1125]  eta: 0:07:38  lr: 0.000062  loss: 1.4816  time: 0.5829  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 400/1125]  eta: 0:07:08  lr: 0.000062  loss: 1.5383  time: 0.5946  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 450/1125]  eta: 0:06:39  lr: 0.000062  loss: 1.5620  time: 0.5857  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 500/1125]  eta: 0:06:08  lr: 0.000062  loss: 1.4961  time: 0.5847  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 550/1125]  eta: 0:05:38  lr: 0.000062  loss: 1.5021  time: 0.5777  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 600/1125]  eta: 0:05:09  lr: 0.000062  loss: 1.5746  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 650/1125]  eta: 0:04:39  lr: 0.000062  loss: 0.9840  time: 0.5904  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 700/1125]  eta: 0:04:10  lr: 0.000062  loss: 1.6141  time: 0.5864  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 750/1125]  eta: 0:03:40  lr: 0.000062  loss: 1.3495  time: 0.5858  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 800/1125]  eta: 0:03:11  lr: 0.000062  loss: 1.2211  time: 0.5739  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 850/1125]  eta: 0:02:41  lr: 0.000062  loss: 1.3017  time: 0.5826  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 900/1125]  eta: 0:02:12  lr: 0.000062  loss: 1.2618  time: 0.5995  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 950/1125]  eta: 0:01:42  lr: 0.000062  loss: 1.3849  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1000/1125]  eta: 0:01:13  lr: 0.000062  loss: 1.4021  time: 0.5902  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1050/1125]  eta: 0:00:44  lr: 0.000062  loss: 1.3992  time: 0.5817  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1100/1125]  eta: 0:00:14  lr: 0.000062  loss: 1.2521  time: 0.5901  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1124/1125]  eta: 0:00:00  lr: 0.000062  loss: 1.3351  time: 0.5794  data: 0.0002  max mem: 15660
Train Epoch: [5] Total time: 0:11:01 (0.5876 s / it)
Averaged stats: lr: 0.0001  loss: 1.5003
Generate VQA test result:  [  0/563]  eta: 0:05:06    time: 0.5444  data: 0.3143  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2066  data: 0.0002  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2063  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2066  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2072  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2072  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2067  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2072  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2064  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2055  data: 0.0001  max mem: 15660
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Generate VQA test result: Total time: 0:01:56 (0.2076 s / it)
0.23201598579040852
Train Epoch: [6]  [   0/1125]  eta: 0:35:05  lr: 0.000030  loss: 1.1237  time: 1.8712  data: 0.9585  max mem: 15660
Train Epoch: [6]  [  50/1125]  eta: 0:11:02  lr: 0.000030  loss: 1.3157  time: 0.5852  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 100/1125]  eta: 0:10:20  lr: 0.000030  loss: 1.1329  time: 0.5957  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 150/1125]  eta: 0:09:44  lr: 0.000030  loss: 1.1680  time: 0.5888  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 200/1125]  eta: 0:09:12  lr: 0.000030  loss: 1.2196  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 250/1125]  eta: 0:08:41  lr: 0.000030  loss: 1.0730  time: 0.5978  data: 0.0002  max mem: 15660
Train Epoch: [6]  [ 300/1125]  eta: 0:08:11  lr: 0.000030  loss: 1.1529  time: 0.5873  data: 0.0002  max mem: 15660
Train Epoch: [6]  [ 350/1125]  eta: 0:07:41  lr: 0.000030  loss: 0.9549  time: 0.5987  data: 0.0002  max mem: 15660
Train Epoch: [6]  [ 400/1125]  eta: 0:07:11  lr: 0.000030  loss: 1.2496  time: 0.5911  data: 0.0002  max mem: 15660
Train Epoch: [6]  [ 450/1125]  eta: 0:06:41  lr: 0.000030  loss: 1.5356  time: 0.5917  data: 0.0002  max mem: 15660
Train Epoch: [6]  [ 500/1125]  eta: 0:06:11  lr: 0.000030  loss: 1.0069  time: 0.5855  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 550/1125]  eta: 0:05:40  lr: 0.000030  loss: 1.1358  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 600/1125]  eta: 0:05:11  lr: 0.000030  loss: 1.1311  time: 0.5888  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 650/1125]  eta: 0:04:40  lr: 0.000030  loss: 1.1382  time: 0.5821  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 700/1125]  eta: 0:04:11  lr: 0.000030  loss: 1.1032  time: 0.5951  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 750/1125]  eta: 0:03:41  lr: 0.000030  loss: 1.1066  time: 0.5886  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 800/1125]  eta: 0:03:12  lr: 0.000030  loss: 1.1915  time: 0.5813  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 850/1125]  eta: 0:02:42  lr: 0.000030  loss: 1.4335  time: 0.5779  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 900/1125]  eta: 0:02:12  lr: 0.000030  loss: 1.0745  time: 0.5835  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 950/1125]  eta: 0:01:43  lr: 0.000030  loss: 1.0930  time: 0.5914  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1000/1125]  eta: 0:01:13  lr: 0.000030  loss: 1.1530  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1050/1125]  eta: 0:00:44  lr: 0.000030  loss: 1.1270  time: 0.5906  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1100/1125]  eta: 0:00:14  lr: 0.000030  loss: 1.1038  time: 0.5944  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1124/1125]  eta: 0:00:00  lr: 0.000030  loss: 1.1196  time: 0.5770  data: 0.0002  max mem: 15660
Train Epoch: [6] Total time: 0:11:04 (0.5906 s / it)
Averaged stats: lr: 0.0000  loss: 1.1967
Generate VQA test result:  [  0/563]  eta: 0:06:58    time: 0.7430  data: 0.5175  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:52    time: 0.2068  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2066  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2059  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2060  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2072  data: 0.0002  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2059  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2058  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2055  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2044  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:56 (0.2074 s / it)
0.23201598579040852
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Train Epoch: [7]  [   0/1125]  eta: 0:30:48  lr: 0.000009  loss: 1.1416  time: 1.6433  data: 0.9332  max mem: 15660
Train Epoch: [7]  [  50/1125]  eta: 0:10:52  lr: 0.000009  loss: 1.1018  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 100/1125]  eta: 0:10:15  lr: 0.000009  loss: 1.2079  time: 0.5948  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 150/1125]  eta: 0:09:40  lr: 0.000009  loss: 1.1394  time: 0.5845  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 200/1125]  eta: 0:09:09  lr: 0.000009  loss: 1.1673  time: 0.5822  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 250/1125]  eta: 0:08:37  lr: 0.000009  loss: 1.0595  time: 0.5870  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 300/1125]  eta: 0:08:06  lr: 0.000009  loss: 1.2783  time: 0.5765  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 350/1125]  eta: 0:07:36  lr: 0.000009  loss: 1.0175  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 400/1125]  eta: 0:07:07  lr: 0.000009  loss: 1.0644  time: 0.5881  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 450/1125]  eta: 0:06:38  lr: 0.000009  loss: 1.0673  time: 0.5783  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 500/1125]  eta: 0:06:08  lr: 0.000009  loss: 1.3104  time: 0.5868  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 550/1125]  eta: 0:05:39  lr: 0.000009  loss: 1.0011  time: 0.5933  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 600/1125]  eta: 0:05:09  lr: 0.000009  loss: 1.0039  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 650/1125]  eta: 0:04:39  lr: 0.000009  loss: 1.1923  time: 0.5915  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 700/1125]  eta: 0:04:10  lr: 0.000009  loss: 1.1622  time: 0.5911  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 750/1125]  eta: 0:03:40  lr: 0.000009  loss: 1.1106  time: 0.5808  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 800/1125]  eta: 0:03:11  lr: 0.000009  loss: 1.0248  time: 0.5962  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 850/1125]  eta: 0:02:41  lr: 0.000009  loss: 1.1240  time: 0.5883  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 900/1125]  eta: 0:02:12  lr: 0.000009  loss: 1.0927  time: 0.5926  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 950/1125]  eta: 0:01:43  lr: 0.000009  loss: 1.0454  time: 0.5905  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1000/1125]  eta: 0:01:13  lr: 0.000009  loss: 1.0272  time: 0.5938  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1050/1125]  eta: 0:00:44  lr: 0.000009  loss: 1.4438  time: 0.5871  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1100/1125]  eta: 0:00:14  lr: 0.000009  loss: 1.0729  time: 0.5859  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1124/1125]  eta: 0:00:00  lr: 0.000009  loss: 1.2312  time: 0.5742  data: 0.0002  max mem: 15660
Train Epoch: [7] Total time: 0:11:02 (0.5889 s / it)
Averaged stats: lr: 0.0000  loss: 1.1147
Generate VQA test result:  [  0/563]  eta: 0:05:05    time: 0.5424  data: 0.3157  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2070  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2072  data: 0.0002  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2068  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2072  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2062  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2060  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2068  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2068  data: 0.0001  max mem: 15660
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2056  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:56 (0.2075 s / it)
0.23201598579040852
Generate VQA test result:  [  0/563]  eta: 0:05:11    time: 0.5529  data: 0.3201  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2060  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2064  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2063  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2063  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2060  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2073  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2068  data: 0.0001  max mem: 15660
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2056  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:56 (0.2075 s / it)
result file saved to output_optimal/vqa/result/vqa_result_epoch7.json
Training time 1:46:42