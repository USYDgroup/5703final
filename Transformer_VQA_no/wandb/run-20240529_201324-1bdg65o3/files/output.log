Not using distributed mode
Creating vqa datasets
Creating model
reshape position embedding from 256 to 576
Traceback (most recent call last):
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 388, in <module>
    main(args, config)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 263, in main
    msg = model.load_state_dict(state_dict,strict=False)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PreVQA:
	size mismatch for fusion_encoder.encoder.layer.5.output.LayerNorm.bias: copying a param with shape torch.Size([30522]) from checkpoint, the shape in current model is torch.Size([768]).