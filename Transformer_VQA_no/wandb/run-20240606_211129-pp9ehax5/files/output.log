Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/output_vqa2/vqa/checkpoint_07.pth ,evaluate.
<All keys matched successfully>
Start training
Traceback (most recent call last):
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 399, in <module>
    main(args, config)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 358, in main
    vqa_result = evaluation(model, test_loader, tokenizer, device, config)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 136, in evaluation
    for n, (image, question, question_id),ans in enumerate(metric_logger.log_every(data_loader, print_freq, header)):
ValueError: not enough values to unpack (expected 3, got 2)