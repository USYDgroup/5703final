Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['text_encoder.encoder.layer.12.attention.self.query.weight', 'text_encoder.encoder.layer.12.attention.self.query.bias', 'text_encoder.encoder.layer.12.attention.self.key.weight', 'text_encoder.encoder.layer.12.attention.self.key.bias', 'text_encoder.encoder.layer.12.attention.self.value.weight', 'text_encoder.encoder.layer.12.attention.self.value.bias', 'text_encoder.encoder.layer.12.attention.output.dense.weight', 'text_encoder.encoder.layer.12.attention.output.dense.bias', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.crossattention.self.query.weight', 'text_encoder.encoder.layer.12.crossattention.self.query.bias', 'text_encoder.encoder.layer.12.crossattention.self.key.weight', 'text_encoder.encoder.layer.12.crossattention.self.key.bias', 'text_encoder.encoder.layer.12.crossattention.self.value.weight', 'text_encoder.encoder.layer.12.crossattention.self.value.bias', 'text_encoder.encoder.layer.12.crossattention.output.dense.weight', 'text_encoder.encoder.layer.12.crossattention.output.dense.bias', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.intermediate.dense.weight', 'text_encoder.encoder.layer.12.intermediate.dense.bias', 'text_encoder.encoder.layer.12.output.dense.weight', 'text_encoder.encoder.layer.12.output.dense.bias', 'text_encoder.encoder.layer.12.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.attention.self.query.weight', 'text_encoder.encoder.layer.13.attention.self.query.bias', 'text_encoder.encoder.layer.13.attention.self.key.weight', 'text_encoder.encoder.layer.13.attention.self.key.bias', 'text_encoder.encoder.layer.13.attention.self.value.weight', 'text_encoder.encoder.layer.13.attention.self.value.bias', 'text_encoder.encoder.layer.13.attention.output.dense.weight', 'text_encoder.encoder.layer.13.attention.output.dense.bias', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.crossattention.self.query.weight', 'text_encoder.encoder.layer.13.crossattention.self.query.bias', 'text_encoder.encoder.layer.13.crossattention.self.key.weight', 'text_encoder.encoder.layer.13.crossattention.self.key.bias', 'text_encoder.encoder.layer.13.crossattention.self.value.weight', 'text_encoder.encoder.layer.13.crossattention.self.value.bias', 'text_encoder.encoder.layer.13.crossattention.output.dense.weight', 'text_encoder.encoder.layer.13.crossattention.output.dense.bias', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.intermediate.dense.weight', 'text_encoder.encoder.layer.13.intermediate.dense.bias', 'text_encoder.encoder.layer.13.output.dense.weight', 'text_encoder.encoder.layer.13.output.dense.bias', 'text_encoder.encoder.layer.13.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.attention.self.query.weight', 'text_encoder.encoder.layer.14.attention.self.query.bias', 'text_encoder.encoder.layer.14.attention.self.key.weight', 'text_encoder.encoder.layer.14.attention.self.key.bias', 'text_encoder.encoder.layer.14.attention.self.value.weight', 'text_encoder.encoder.layer.14.attention.self.value.bias', 'text_encoder.encoder.layer.14.attention.output.dense.weight', 'text_encoder.encoder.layer.14.attention.output.dense.bias', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.crossattention.self.query.weight', 'text_encoder.encoder.layer.14.crossattention.self.query.bias', 'text_encoder.encoder.layer.14.crossattention.self.key.weight', 'text_encoder.encoder.layer.14.crossattention.self.key.bias', 'text_encoder.encoder.layer.14.crossattention.self.value.weight', 'text_encoder.encoder.layer.14.crossattention.self.value.bias', 'text_encoder.encoder.layer.14.crossattention.output.dense.weight', 'text_encoder.encoder.layer.14.crossattention.output.dense.bias', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.intermediate.dense.weight', 'text_encoder.encoder.layer.14.intermediate.dense.bias', 'text_encoder.encoder.layer.14.output.dense.weight', 'text_encoder.encoder.layer.14.output.dense.bias', 'text_encoder.encoder.layer.14.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.attention.self.query.weight', 'text_encoder.encoder.layer.15.attention.self.query.bias', 'text_encoder.encoder.layer.15.attention.self.key.weight', 'text_encoder.encoder.layer.15.attention.self.key.bias', 'text_encoder.encoder.layer.15.attention.self.value.weight', 'text_encoder.encoder.layer.15.attention.self.value.bias', 'text_encoder.encoder.layer.15.attention.output.dense.weight', 'text_encoder.encoder.layer.15.attention.output.dense.bias', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.crossattention.self.query.weight', 'text_encoder.encoder.layer.15.crossattention.self.query.bias', 'text_encoder.encoder.layer.15.crossattention.self.key.weight', 'text_encoder.encoder.layer.15.crossattention.self.key.bias', 'text_encoder.encoder.layer.15.crossattention.self.value.weight', 'text_encoder.encoder.layer.15.crossattention.self.value.bias', 'text_encoder.encoder.layer.15.crossattention.output.dense.weight', 'text_encoder.encoder.layer.15.crossattention.output.dense.bias', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.intermediate.dense.weight', 'text_encoder.encoder.layer.15.intermediate.dense.bias', 'text_encoder.encoder.layer.15.output.dense.weight', 'text_encoder.encoder.layer.15.output.dense.bias', 'text_encoder.encoder.layer.15.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.output.LayerNorm.bias', 'inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [   0/1125]  eta: 0:56:23  lr: 0.000010  loss: 1.6340  time: 3.0078  data: 1.1151  max mem: 11560
Train Epoch: [0]  [  50/1125]  eta: 0:11:19  lr: 0.000010  loss: 0.4762  time: 0.5903  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 100/1125]  eta: 0:10:29  lr: 0.000010  loss: 0.5221  time: 0.5989  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 150/1125]  eta: 0:09:51  lr: 0.000013  loss: 0.2786  time: 0.5935  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 200/1125]  eta: 0:09:17  lr: 0.000013  loss: 0.2965  time: 0.5914  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 250/1125]  eta: 0:08:46  lr: 0.000015  loss: 0.3198  time: 0.6014  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 300/1125]  eta: 0:08:13  lr: 0.000015  loss: 0.3594  time: 0.5845  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 350/1125]  eta: 0:07:41  lr: 0.000018  loss: 0.2750  time: 0.5866  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 400/1125]  eta: 0:07:11  lr: 0.000018  loss: 0.3797  time: 0.5886  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 450/1125]  eta: 0:06:41  lr: 0.000020  loss: 0.3097  time: 0.5968  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 500/1125]  eta: 0:06:11  lr: 0.000020  loss: 0.2467  time: 0.5896  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 550/1125]  eta: 0:05:41  lr: 0.000020  loss: 0.1145  time: 0.5901  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 600/1125]  eta: 0:05:11  lr: 0.000020  loss: 0.1426  time: 0.5911  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 650/1125]  eta: 0:04:41  lr: 0.000020  loss: 0.1528  time: 0.5775  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 700/1125]  eta: 0:04:11  lr: 0.000020  loss: 0.1601  time: 0.5879  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 750/1125]  eta: 0:03:41  lr: 0.000020  loss: 0.1002  time: 0.5823  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 800/1125]  eta: 0:03:11  lr: 0.000020  loss: 0.1503  time: 0.5854  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 850/1125]  eta: 0:02:42  lr: 0.000020  loss: 0.2457  time: 0.5869  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.1542  time: 0.5905  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 950/1125]  eta: 0:01:43  lr: 0.000020  loss: 0.2045  time: 0.5806  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.1143  time: 0.5931  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.1361  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.0430  time: 0.5880  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.0601  time: 0.5800  data: 0.0001  max mem: 15660
Train Epoch: [0] Total time: 0:11:03 (0.5895 s / it)
Averaged stats: lr: 0.0000  loss: 0.2629
Generate VQA test result:  [  0/563]  eta: 0:08:20    time: 0.8884  data: 0.3544  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:53    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:39    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2110  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2067  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2093 s / it)
0.9449378330373002
Train Epoch: [1]  [   0/1125]  eta: 0:39:27  lr: 0.000019  loss: 0.0860  time: 2.1044  data: 1.4646  max mem: 15660
Train Epoch: [1]  [  50/1125]  eta: 0:10:54  lr: 0.000019  loss: 0.1056  time: 0.5734  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 100/1125]  eta: 0:10:12  lr: 0.000019  loss: 0.1103  time: 0.5861  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 150/1125]  eta: 0:09:38  lr: 0.000019  loss: 0.0745  time: 0.5891  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 200/1125]  eta: 0:09:09  lr: 0.000019  loss: 0.0353  time: 0.5969  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 250/1125]  eta: 0:08:37  lr: 0.000019  loss: 0.1061  time: 0.5743  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 300/1125]  eta: 0:08:06  lr: 0.000019  loss: 0.3986  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 350/1125]  eta: 0:07:36  lr: 0.000019  loss: 0.0877  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 400/1125]  eta: 0:07:07  lr: 0.000019  loss: 0.0352  time: 0.5936  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 450/1125]  eta: 0:06:37  lr: 0.000019  loss: 0.0468  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 500/1125]  eta: 0:06:07  lr: 0.000019  loss: 0.3243  time: 0.5825  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 550/1125]  eta: 0:05:38  lr: 0.000019  loss: 0.1680  time: 0.5889  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 600/1125]  eta: 0:05:08  lr: 0.000019  loss: 0.0810  time: 0.5916  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 650/1125]  eta: 0:04:39  lr: 0.000019  loss: 0.0334  time: 0.5849  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 700/1125]  eta: 0:04:09  lr: 0.000019  loss: 0.0934  time: 0.5827  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 750/1125]  eta: 0:03:40  lr: 0.000019  loss: 0.0130  time: 0.5838  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 800/1125]  eta: 0:03:10  lr: 0.000019  loss: 0.1024  time: 0.5782  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 850/1125]  eta: 0:02:41  lr: 0.000019  loss: 0.0232  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 900/1125]  eta: 0:02:11  lr: 0.000019  loss: 0.1244  time: 0.5851  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 950/1125]  eta: 0:01:42  lr: 0.000019  loss: 0.2041  time: 0.5806  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1000/1125]  eta: 0:01:13  lr: 0.000019  loss: 0.0998  time: 0.5870  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1050/1125]  eta: 0:00:43  lr: 0.000019  loss: 0.0056  time: 0.5829  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1100/1125]  eta: 0:00:14  lr: 0.000019  loss: 0.1084  time: 0.5923  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1124/1125]  eta: 0:00:00  lr: 0.000019  loss: 0.0942  time: 0.5762  data: 0.0002  max mem: 15660
Train Epoch: [1] Total time: 0:10:59 (0.5860 s / it)
Averaged stats: lr: 0.0000  loss: 0.1016
Generate VQA test result:  [  0/563]  eta: 0:05:14    time: 0.5587  data: 0.3279  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2082  data: 0.0002  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2093  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2072  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2091 s / it)
0.9769094138543517
Train Epoch: [2]  [   0/1125]  eta: 0:33:15  lr: 0.000017  loss: 0.0328  time: 1.7734  data: 0.8017  max mem: 15660
Train Epoch: [2]  [  50/1125]  eta: 0:11:01  lr: 0.000017  loss: 0.0382  time: 0.5928  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 100/1125]  eta: 0:10:18  lr: 0.000017  loss: 0.0076  time: 0.5914  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 150/1125]  eta: 0:09:40  lr: 0.000017  loss: 0.0096  time: 0.5826  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 200/1125]  eta: 0:09:08  lr: 0.000017  loss: 0.0184  time: 0.5845  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 250/1125]  eta: 0:08:37  lr: 0.000017  loss: 0.0084  time: 0.5778  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 300/1125]  eta: 0:08:07  lr: 0.000017  loss: 0.0049  time: 0.5937  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 350/1125]  eta: 0:07:36  lr: 0.000017  loss: 0.1289  time: 0.5796  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 400/1125]  eta: 0:07:06  lr: 0.000017  loss: 0.0257  time: 0.5891  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 450/1125]  eta: 0:06:37  lr: 0.000017  loss: 0.0042  time: 0.5846  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 500/1125]  eta: 0:06:07  lr: 0.000017  loss: 0.0033  time: 0.5919  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 550/1125]  eta: 0:05:38  lr: 0.000017  loss: 0.2099  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 600/1125]  eta: 0:05:08  lr: 0.000017  loss: 0.0082  time: 0.5776  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 650/1125]  eta: 0:04:38  lr: 0.000017  loss: 0.0070  time: 0.5747  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 700/1125]  eta: 0:04:09  lr: 0.000017  loss: 0.0345  time: 0.5864  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 750/1125]  eta: 0:03:39  lr: 0.000017  loss: 0.0955  time: 0.5765  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 800/1125]  eta: 0:03:10  lr: 0.000017  loss: 0.0048  time: 0.5846  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 850/1125]  eta: 0:02:41  lr: 0.000017  loss: 0.0577  time: 0.5801  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 900/1125]  eta: 0:02:11  lr: 0.000017  loss: 0.0023  time: 0.5847  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 950/1125]  eta: 0:01:42  lr: 0.000017  loss: 0.0427  time: 0.5941  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1000/1125]  eta: 0:01:13  lr: 0.000017  loss: 0.0019  time: 0.5850  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1050/1125]  eta: 0:00:43  lr: 0.000017  loss: 0.1792  time: 0.5835  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1100/1125]  eta: 0:00:14  lr: 0.000017  loss: 0.2802  time: 0.5867  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1124/1125]  eta: 0:00:00  lr: 0.000017  loss: 0.0052  time: 0.5802  data: 0.0002  max mem: 15660
Train Epoch: [2] Total time: 0:10:59 (0.5860 s / it)
Averaged stats: lr: 0.0000  loss: 0.0528
Generate VQA test result:  [  0/563]  eta: 0:05:38    time: 0.6005  data: 0.3728  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2092 s / it)
0.9771314387211367
Train Epoch: [3]  [   0/1125]  eta: 0:38:39  lr: 0.000014  loss: 0.0812  time: 2.0615  data: 1.2299  max mem: 15660
Train Epoch: [3]  [  50/1125]  eta: 0:11:02  lr: 0.000014  loss: 0.0701  time: 0.5876  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 100/1125]  eta: 0:10:16  lr: 0.000014  loss: 0.0024  time: 0.5815  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 150/1125]  eta: 0:09:42  lr: 0.000014  loss: 0.0048  time: 0.5984  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 200/1125]  eta: 0:09:09  lr: 0.000014  loss: 0.0494  time: 0.5807  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 250/1125]  eta: 0:08:38  lr: 0.000014  loss: 0.2743  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 300/1125]  eta: 0:08:08  lr: 0.000014  loss: 0.0040  time: 0.5864  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 350/1125]  eta: 0:07:38  lr: 0.000014  loss: 0.0097  time: 0.5903  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 400/1125]  eta: 0:07:08  lr: 0.000014  loss: 0.0258  time: 0.5851  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 450/1125]  eta: 0:06:38  lr: 0.000014  loss: 0.0065  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 500/1125]  eta: 0:06:08  lr: 0.000014  loss: 0.0024  time: 0.5818  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 550/1125]  eta: 0:05:39  lr: 0.000014  loss: 0.1666  time: 0.5933  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 600/1125]  eta: 0:05:09  lr: 0.000014  loss: 0.0129  time: 0.5943  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 650/1125]  eta: 0:04:40  lr: 0.000014  loss: 0.0033  time: 0.5920  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 700/1125]  eta: 0:04:10  lr: 0.000014  loss: 0.2175  time: 0.5931  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 750/1125]  eta: 0:03:41  lr: 0.000014  loss: 0.0097  time: 0.5936  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 800/1125]  eta: 0:03:11  lr: 0.000014  loss: 0.0014  time: 0.5839  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 850/1125]  eta: 0:02:42  lr: 0.000014  loss: 0.0154  time: 0.5862  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 900/1125]  eta: 0:02:12  lr: 0.000014  loss: 0.0092  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 950/1125]  eta: 0:01:43  lr: 0.000014  loss: 0.0011  time: 0.5831  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1000/1125]  eta: 0:01:13  lr: 0.000014  loss: 0.1564  time: 0.5940  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1050/1125]  eta: 0:00:44  lr: 0.000014  loss: 0.0464  time: 0.5956  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1100/1125]  eta: 0:00:14  lr: 0.000014  loss: 0.0036  time: 0.5809  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1124/1125]  eta: 0:00:00  lr: 0.000014  loss: 0.0226  time: 0.5706  data: 0.0002  max mem: 15660
Train Epoch: [3] Total time: 0:11:02 (0.5886 s / it)
Averaged stats: lr: 0.0000  loss: 0.0381
Generate VQA test result:  [  0/563]  eta: 0:05:11    time: 0.5531  data: 0.3309  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2068  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2077  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2073  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2066  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2056  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2079 s / it)
0.977797513321492
Train Epoch: [4]  [   0/1125]  eta: 0:35:35  lr: 0.000011  loss: 0.0205  time: 1.8983  data: 1.1992  max mem: 15660
Train Epoch: [4]  [  50/1125]  eta: 0:10:55  lr: 0.000011  loss: 0.0071  time: 0.5864  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 100/1125]  eta: 0:10:13  lr: 0.000011  loss: 0.0024  time: 0.5848  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 150/1125]  eta: 0:09:42  lr: 0.000011  loss: 0.0006  time: 0.5961  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 200/1125]  eta: 0:09:10  lr: 0.000011  loss: 0.0072  time: 0.5809  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 250/1125]  eta: 0:08:39  lr: 0.000011  loss: 0.0021  time: 0.5852  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 300/1125]  eta: 0:08:08  lr: 0.000011  loss: 0.0004  time: 0.5835  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 350/1125]  eta: 0:07:38  lr: 0.000011  loss: 0.0013  time: 0.5930  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 400/1125]  eta: 0:07:08  lr: 0.000011  loss: 0.0146  time: 0.5847  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 450/1125]  eta: 0:06:38  lr: 0.000011  loss: 0.0007  time: 0.6007  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 500/1125]  eta: 0:06:09  lr: 0.000011  loss: 0.0042  time: 0.5872  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 550/1125]  eta: 0:05:39  lr: 0.000011  loss: 0.0058  time: 0.5863  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 600/1125]  eta: 0:05:09  lr: 0.000011  loss: 0.0027  time: 0.5873  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 650/1125]  eta: 0:04:40  lr: 0.000011  loss: 0.0040  time: 0.5877  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 700/1125]  eta: 0:04:10  lr: 0.000011  loss: 0.0187  time: 0.5829  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 750/1125]  eta: 0:03:40  lr: 0.000011  loss: 0.0005  time: 0.5853  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 800/1125]  eta: 0:03:11  lr: 0.000011  loss: 0.0098  time: 0.5753  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 850/1125]  eta: 0:02:41  lr: 0.000011  loss: 0.0050  time: 0.5879  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 900/1125]  eta: 0:02:12  lr: 0.000011  loss: 0.0007  time: 0.5850  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 950/1125]  eta: 0:01:42  lr: 0.000011  loss: 0.0014  time: 0.5858  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1000/1125]  eta: 0:01:13  lr: 0.000011  loss: 0.0141  time: 0.5998  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1050/1125]  eta: 0:00:44  lr: 0.000011  loss: 0.0011  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1100/1125]  eta: 0:00:14  lr: 0.000011  loss: 0.1816  time: 0.5876  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1124/1125]  eta: 0:00:00  lr: 0.000011  loss: 0.1031  time: 0.5771  data: 0.0002  max mem: 15660
Train Epoch: [4] Total time: 0:11:01 (0.5881 s / it)
Averaged stats: lr: 0.0000  loss: 0.0219
Generate VQA test result:  [  0/563]  eta: 0:05:07    time: 0.5460  data: 0.3109  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2090  data: 0.0002  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2092 s / it)
0.9915630550621669
Train Epoch: [5]  [   0/1125]  eta: 0:38:47  lr: 0.000007  loss: 0.0216  time: 2.0689  data: 1.4383  max mem: 15660
Train Epoch: [5]  [  50/1125]  eta: 0:11:12  lr: 0.000007  loss: 0.0039  time: 0.5995  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 100/1125]  eta: 0:10:17  lr: 0.000007  loss: 0.0117  time: 0.5703  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 150/1125]  eta: 0:09:41  lr: 0.000007  loss: 0.0012  time: 0.5887  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 200/1125]  eta: 0:09:09  lr: 0.000007  loss: 0.0017  time: 0.5857  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 250/1125]  eta: 0:08:40  lr: 0.000007  loss: 0.0114  time: 0.5940  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 300/1125]  eta: 0:08:09  lr: 0.000007  loss: 0.0008  time: 0.5847  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 350/1125]  eta: 0:07:39  lr: 0.000007  loss: 0.0008  time: 0.5888  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 400/1125]  eta: 0:07:09  lr: 0.000007  loss: 0.0040  time: 0.5855  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 450/1125]  eta: 0:06:38  lr: 0.000007  loss: 0.0026  time: 0.5831  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 500/1125]  eta: 0:06:09  lr: 0.000007  loss: 0.0016  time: 0.5850  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 550/1125]  eta: 0:05:38  lr: 0.000007  loss: 0.0111  time: 0.5782  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 600/1125]  eta: 0:05:09  lr: 0.000007  loss: 0.0010  time: 0.5830  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 650/1125]  eta: 0:04:39  lr: 0.000007  loss: 0.0018  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 700/1125]  eta: 0:04:10  lr: 0.000007  loss: 0.0047  time: 0.5957  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 750/1125]  eta: 0:03:40  lr: 0.000007  loss: 0.0016  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 800/1125]  eta: 0:03:11  lr: 0.000007  loss: 0.0041  time: 0.5958  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 850/1125]  eta: 0:02:41  lr: 0.000007  loss: 0.0010  time: 0.5800  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 900/1125]  eta: 0:02:12  lr: 0.000007  loss: 0.0015  time: 0.5858  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 950/1125]  eta: 0:01:43  lr: 0.000007  loss: 0.0005  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1000/1125]  eta: 0:01:13  lr: 0.000007  loss: 0.0002  time: 0.5883  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1050/1125]  eta: 0:00:44  lr: 0.000007  loss: 0.0040  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1100/1125]  eta: 0:00:14  lr: 0.000007  loss: 0.0026  time: 0.5699  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1124/1125]  eta: 0:00:00  lr: 0.000007  loss: 0.0007  time: 0.5726  data: 0.0002  max mem: 15660
Train Epoch: [5] Total time: 0:11:01 (0.5877 s / it)
Averaged stats: lr: 0.0000  loss: 0.0163
Generate VQA test result:  [  0/563]  eta: 0:05:08    time: 0.5484  data: 0.3223  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2089  data: 0.0002  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2082  data: 0.0002  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2070  data: 0.0002  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2088 s / it)
0.9937833037300178
Train Epoch: [6]  [   0/1125]  eta: 0:34:13  lr: 0.000004  loss: 0.0028  time: 1.8254  data: 0.9642  max mem: 15660
Train Epoch: [6]  [  50/1125]  eta: 0:10:56  lr: 0.000004  loss: 0.0008  time: 0.5785  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 100/1125]  eta: 0:10:11  lr: 0.000004  loss: 0.0537  time: 0.5838  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 150/1125]  eta: 0:09:36  lr: 0.000004  loss: 0.0032  time: 0.5884  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 200/1125]  eta: 0:09:06  lr: 0.000004  loss: 0.0007  time: 0.5828  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 250/1125]  eta: 0:08:36  lr: 0.000004  loss: 0.0009  time: 0.5889  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 300/1125]  eta: 0:08:06  lr: 0.000004  loss: 0.0004  time: 0.5769  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 350/1125]  eta: 0:07:37  lr: 0.000004  loss: 0.0006  time: 0.5935  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 400/1125]  eta: 0:07:07  lr: 0.000004  loss: 0.0005  time: 0.5824  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 450/1125]  eta: 0:06:37  lr: 0.000004  loss: 0.0107  time: 0.5813  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 500/1125]  eta: 0:06:07  lr: 0.000004  loss: 0.0008  time: 0.5750  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 550/1125]  eta: 0:05:37  lr: 0.000004  loss: 0.0006  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 600/1125]  eta: 0:05:08  lr: 0.000004  loss: 0.0006  time: 0.5786  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 650/1125]  eta: 0:04:38  lr: 0.000004  loss: 0.0005  time: 0.5895  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 700/1125]  eta: 0:04:09  lr: 0.000004  loss: 0.0024  time: 0.5827  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 750/1125]  eta: 0:03:40  lr: 0.000004  loss: 0.0021  time: 0.5871  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 800/1125]  eta: 0:03:10  lr: 0.000004  loss: 0.0006  time: 0.5877  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 850/1125]  eta: 0:02:41  lr: 0.000004  loss: 0.0007  time: 0.5854  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 900/1125]  eta: 0:02:12  lr: 0.000004  loss: 0.0003  time: 0.5813  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 950/1125]  eta: 0:01:42  lr: 0.000004  loss: 0.0010  time: 0.5806  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1000/1125]  eta: 0:01:13  lr: 0.000004  loss: 0.0007  time: 0.5828  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1050/1125]  eta: 0:00:44  lr: 0.000004  loss: 0.0005  time: 0.6028  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1100/1125]  eta: 0:00:14  lr: 0.000004  loss: 0.2371  time: 0.5900  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1124/1125]  eta: 0:00:00  lr: 0.000004  loss: 0.0039  time: 0.5745  data: 0.0002  max mem: 15660
Train Epoch: [6] Total time: 0:11:00 (0.5868 s / it)
Averaged stats: lr: 0.0000  loss: 0.0118
Generate VQA test result:  [  0/563]  eta: 0:05:19    time: 0.5677  data: 0.3242  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2089  data: 0.0002  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2082  data: 0.0002  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2091 s / it)
0.997113676731794
Train Epoch: [7]  [   0/1125]  eta: 0:34:43  lr: 0.000002  loss: 0.0022  time: 1.8519  data: 1.0432  max mem: 15660
Train Epoch: [7]  [  50/1125]  eta: 0:10:51  lr: 0.000002  loss: 0.0017  time: 0.5821  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 100/1125]  eta: 0:10:10  lr: 0.000002  loss: 0.0005  time: 0.5919  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 150/1125]  eta: 0:09:35  lr: 0.000002  loss: 0.0012  time: 0.5830  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 200/1125]  eta: 0:09:04  lr: 0.000002  loss: 0.0608  time: 0.5802  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 250/1125]  eta: 0:08:34  lr: 0.000002  loss: 0.0006  time: 0.5842  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 300/1125]  eta: 0:08:04  lr: 0.000002  loss: 0.0006  time: 0.5828  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 350/1125]  eta: 0:07:36  lr: 0.000002  loss: 0.0005  time: 0.5988  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 400/1125]  eta: 0:07:06  lr: 0.000002  loss: 0.0004  time: 0.5779  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 450/1125]  eta: 0:06:36  lr: 0.000002  loss: 0.0070  time: 0.5835  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 500/1125]  eta: 0:06:07  lr: 0.000002  loss: 0.0013  time: 0.5890  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 550/1125]  eta: 0:05:37  lr: 0.000002  loss: 0.0004  time: 0.5867  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 600/1125]  eta: 0:05:08  lr: 0.000002  loss: 0.0003  time: 0.5900  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 650/1125]  eta: 0:04:38  lr: 0.000002  loss: 0.0004  time: 0.5780  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 700/1125]  eta: 0:04:09  lr: 0.000002  loss: 0.0006  time: 0.5820  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 750/1125]  eta: 0:03:40  lr: 0.000002  loss: 0.0007  time: 0.5914  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 800/1125]  eta: 0:03:10  lr: 0.000002  loss: 0.0006  time: 0.5794  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 850/1125]  eta: 0:02:41  lr: 0.000002  loss: 0.0007  time: 0.5859  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 900/1125]  eta: 0:02:12  lr: 0.000002  loss: 0.0010  time: 0.5883  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 950/1125]  eta: 0:01:42  lr: 0.000002  loss: 0.0006  time: 0.5938  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1000/1125]  eta: 0:01:13  lr: 0.000002  loss: 0.0007  time: 0.5850  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1050/1125]  eta: 0:00:43  lr: 0.000002  loss: 0.0008  time: 0.5789  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1100/1125]  eta: 0:00:14  lr: 0.000002  loss: 0.0005  time: 0.5827  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1124/1125]  eta: 0:00:00  lr: 0.000002  loss: 0.0032  time: 0.5756  data: 0.0002  max mem: 15660
Train Epoch: [7] Total time: 0:10:59 (0.5863 s / it)
Averaged stats: lr: 0.0000  loss: 0.0063
Generate VQA test result:  [  0/563]  eta: 0:05:14    time: 0.5583  data: 0.3303  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2073  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2077  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2072  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2073  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2086 s / it)
0.9980017761989343
Generate VQA test result:  [  0/563]  eta: 0:05:09    time: 0.5503  data: 0.3235  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2077  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2091 s / it)
result file saved to output_optimal/vqa/result/vqa_result_epoch7.json
Training time 1:46:40