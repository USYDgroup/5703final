Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['text_encoder.encoder.layer.12.attention.self.query.weight', 'text_encoder.encoder.layer.12.attention.self.query.bias', 'text_encoder.encoder.layer.12.attention.self.key.weight', 'text_encoder.encoder.layer.12.attention.self.key.bias', 'text_encoder.encoder.layer.12.attention.self.value.weight', 'text_encoder.encoder.layer.12.attention.self.value.bias', 'text_encoder.encoder.layer.12.attention.output.dense.weight', 'text_encoder.encoder.layer.12.attention.output.dense.bias', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.crossattention.self.query.weight', 'text_encoder.encoder.layer.12.crossattention.self.query.bias', 'text_encoder.encoder.layer.12.crossattention.self.key.weight', 'text_encoder.encoder.layer.12.crossattention.self.key.bias', 'text_encoder.encoder.layer.12.crossattention.self.value.weight', 'text_encoder.encoder.layer.12.crossattention.self.value.bias', 'text_encoder.encoder.layer.12.crossattention.output.dense.weight', 'text_encoder.encoder.layer.12.crossattention.output.dense.bias', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.12.intermediate.dense.weight', 'text_encoder.encoder.layer.12.intermediate.dense.bias', 'text_encoder.encoder.layer.12.output.dense.weight', 'text_encoder.encoder.layer.12.output.dense.bias', 'text_encoder.encoder.layer.12.output.LayerNorm.weight', 'text_encoder.encoder.layer.12.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.attention.self.query.weight', 'text_encoder.encoder.layer.13.attention.self.query.bias', 'text_encoder.encoder.layer.13.attention.self.key.weight', 'text_encoder.encoder.layer.13.attention.self.key.bias', 'text_encoder.encoder.layer.13.attention.self.value.weight', 'text_encoder.encoder.layer.13.attention.self.value.bias', 'text_encoder.encoder.layer.13.attention.output.dense.weight', 'text_encoder.encoder.layer.13.attention.output.dense.bias', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.crossattention.self.query.weight', 'text_encoder.encoder.layer.13.crossattention.self.query.bias', 'text_encoder.encoder.layer.13.crossattention.self.key.weight', 'text_encoder.encoder.layer.13.crossattention.self.key.bias', 'text_encoder.encoder.layer.13.crossattention.self.value.weight', 'text_encoder.encoder.layer.13.crossattention.self.value.bias', 'text_encoder.encoder.layer.13.crossattention.output.dense.weight', 'text_encoder.encoder.layer.13.crossattention.output.dense.bias', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.13.intermediate.dense.weight', 'text_encoder.encoder.layer.13.intermediate.dense.bias', 'text_encoder.encoder.layer.13.output.dense.weight', 'text_encoder.encoder.layer.13.output.dense.bias', 'text_encoder.encoder.layer.13.output.LayerNorm.weight', 'text_encoder.encoder.layer.13.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.attention.self.query.weight', 'text_encoder.encoder.layer.14.attention.self.query.bias', 'text_encoder.encoder.layer.14.attention.self.key.weight', 'text_encoder.encoder.layer.14.attention.self.key.bias', 'text_encoder.encoder.layer.14.attention.self.value.weight', 'text_encoder.encoder.layer.14.attention.self.value.bias', 'text_encoder.encoder.layer.14.attention.output.dense.weight', 'text_encoder.encoder.layer.14.attention.output.dense.bias', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.crossattention.self.query.weight', 'text_encoder.encoder.layer.14.crossattention.self.query.bias', 'text_encoder.encoder.layer.14.crossattention.self.key.weight', 'text_encoder.encoder.layer.14.crossattention.self.key.bias', 'text_encoder.encoder.layer.14.crossattention.self.value.weight', 'text_encoder.encoder.layer.14.crossattention.self.value.bias', 'text_encoder.encoder.layer.14.crossattention.output.dense.weight', 'text_encoder.encoder.layer.14.crossattention.output.dense.bias', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.14.intermediate.dense.weight', 'text_encoder.encoder.layer.14.intermediate.dense.bias', 'text_encoder.encoder.layer.14.output.dense.weight', 'text_encoder.encoder.layer.14.output.dense.bias', 'text_encoder.encoder.layer.14.output.LayerNorm.weight', 'text_encoder.encoder.layer.14.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.attention.self.query.weight', 'text_encoder.encoder.layer.15.attention.self.query.bias', 'text_encoder.encoder.layer.15.attention.self.key.weight', 'text_encoder.encoder.layer.15.attention.self.key.bias', 'text_encoder.encoder.layer.15.attention.self.value.weight', 'text_encoder.encoder.layer.15.attention.self.value.bias', 'text_encoder.encoder.layer.15.attention.output.dense.weight', 'text_encoder.encoder.layer.15.attention.output.dense.bias', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.crossattention.self.query.weight', 'text_encoder.encoder.layer.15.crossattention.self.query.bias', 'text_encoder.encoder.layer.15.crossattention.self.key.weight', 'text_encoder.encoder.layer.15.crossattention.self.key.bias', 'text_encoder.encoder.layer.15.crossattention.self.value.weight', 'text_encoder.encoder.layer.15.crossattention.self.value.bias', 'text_encoder.encoder.layer.15.crossattention.output.dense.weight', 'text_encoder.encoder.layer.15.crossattention.output.dense.bias', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.15.intermediate.dense.weight', 'text_encoder.encoder.layer.15.intermediate.dense.bias', 'text_encoder.encoder.layer.15.output.dense.weight', 'text_encoder.encoder.layer.15.output.dense.bias', 'text_encoder.encoder.layer.15.output.LayerNorm.weight', 'text_encoder.encoder.layer.15.output.LayerNorm.bias', 'inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [   0/1125]  eta: 0:55:40  lr: 0.000010  loss: 1.6340  time: 2.9694  data: 1.3905  max mem: 11560
Train Epoch: [0]  [  50/1125]  eta: 0:11:13  lr: 0.000010  loss: 0.4763  time: 0.5825  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 100/1125]  eta: 0:10:22  lr: 0.000010  loss: 0.5360  time: 0.5885  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 150/1125]  eta: 0:09:44  lr: 0.000013  loss: 0.2889  time: 0.5907  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 200/1125]  eta: 0:09:10  lr: 0.000013  loss: 0.2957  time: 0.5766  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 250/1125]  eta: 0:08:39  lr: 0.000015  loss: 0.2740  time: 0.5893  data: 0.0001  max mem: 15655
Train Epoch: [0]  [ 300/1125]  eta: 0:08:09  lr: 0.000015  loss: 0.3642  time: 0.5964  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 350/1125]  eta: 0:07:39  lr: 0.000018  loss: 0.2952  time: 0.5966  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 400/1125]  eta: 0:07:09  lr: 0.000018  loss: 0.3270  time: 0.5889  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 450/1125]  eta: 0:06:39  lr: 0.000020  loss: 0.5373  time: 0.5858  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 500/1125]  eta: 0:06:09  lr: 0.000020  loss: 0.3255  time: 0.5815  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 550/1125]  eta: 0:05:39  lr: 0.000020  loss: 0.1422  time: 0.5919  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 600/1125]  eta: 0:05:10  lr: 0.000020  loss: 0.1551  time: 0.5865  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 650/1125]  eta: 0:04:40  lr: 0.000020  loss: 0.1257  time: 0.5850  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 700/1125]  eta: 0:04:10  lr: 0.000020  loss: 0.2130  time: 0.5862  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 750/1125]  eta: 0:03:41  lr: 0.000020  loss: 0.1392  time: 0.5921  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 800/1125]  eta: 0:03:11  lr: 0.000020  loss: 0.4232  time: 0.5835  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 850/1125]  eta: 0:02:42  lr: 0.000020  loss: 0.1207  time: 0.5817  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.1902  time: 0.5869  data: 0.0001  max mem: 15656
Train Epoch: [0]  [ 950/1125]  eta: 0:01:43  lr: 0.000020  loss: 0.1557  time: 0.5876  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.0923  time: 0.5872  data: 0.0001  max mem: 15656
Train Epoch: [0]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.0510  time: 0.5871  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.1314  time: 0.5776  data: 0.0001  max mem: 15660
Train Epoch: [0]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.4407  time: 0.5843  data: 0.0001  max mem: 15660
Train Epoch: [0] Total time: 0:11:02 (0.5892 s / it)
Averaged stats: lr: 0.0000  loss: 0.2643
Generate VQA test result:  [  0/563]  eta: 0:07:54    time: 0.8422  data: 0.3166  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:52    time: 0.2082  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:39    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2133  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2093  data: 0.0002  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2085  data: 0.0002  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2067  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2096 s / it)
0.8625666074600356
Train Epoch: [1]  [   0/1125]  eta: 0:35:17  lr: 0.000020  loss: 0.1267  time: 1.8823  data: 1.1339  max mem: 15660
Train Epoch: [1]  [  50/1125]  eta: 0:10:53  lr: 0.000020  loss: 0.0783  time: 0.5800  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 100/1125]  eta: 0:10:15  lr: 0.000020  loss: 0.0648  time: 0.5957  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 150/1125]  eta: 0:09:41  lr: 0.000020  loss: 0.0490  time: 0.5825  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 200/1125]  eta: 0:09:09  lr: 0.000020  loss: 0.1813  time: 0.5940  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 250/1125]  eta: 0:08:38  lr: 0.000020  loss: 0.0600  time: 0.5857  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 300/1125]  eta: 0:08:07  lr: 0.000020  loss: 0.0949  time: 0.5759  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 350/1125]  eta: 0:07:36  lr: 0.000020  loss: 0.1888  time: 0.5791  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 400/1125]  eta: 0:07:06  lr: 0.000020  loss: 0.1207  time: 0.5880  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 450/1125]  eta: 0:06:36  lr: 0.000020  loss: 0.0305  time: 0.5784  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 500/1125]  eta: 0:06:06  lr: 0.000020  loss: 0.0150  time: 0.5818  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 550/1125]  eta: 0:05:37  lr: 0.000020  loss: 0.0426  time: 0.5897  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 600/1125]  eta: 0:05:08  lr: 0.000020  loss: 0.1272  time: 0.5890  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 650/1125]  eta: 0:04:39  lr: 0.000020  loss: 0.1000  time: 0.5906  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 700/1125]  eta: 0:04:09  lr: 0.000020  loss: 0.0298  time: 0.5895  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 750/1125]  eta: 0:03:40  lr: 0.000020  loss: 0.0398  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 800/1125]  eta: 0:03:11  lr: 0.000020  loss: 0.0568  time: 0.5965  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 850/1125]  eta: 0:02:41  lr: 0.000020  loss: 0.2844  time: 0.5838  data: 0.0002  max mem: 15660
Train Epoch: [1]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.0170  time: 0.5900  data: 0.0001  max mem: 15660
Train Epoch: [1]  [ 950/1125]  eta: 0:01:43  lr: 0.000020  loss: 0.0105  time: 0.5910  data: 0.0002  max mem: 15660
Train Epoch: [1]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.2702  time: 0.5960  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.0377  time: 0.5857  data: 0.0002  max mem: 15660
Train Epoch: [1]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.0736  time: 0.5990  data: 0.0001  max mem: 15660
Train Epoch: [1]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.0322  time: 0.5817  data: 0.0002  max mem: 15660
Train Epoch: [1] Total time: 0:11:02 (0.5893 s / it)
Averaged stats: lr: 0.0000  loss: 0.1051
Generate VQA test result:  [  0/563]  eta: 0:05:04    time: 0.5413  data: 0.3093  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:51    time: 0.2090  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2112  data: 0.0002  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:28    time: 0.2119  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:17    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:06    time: 0.2088  data: 0.0002  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2091  data: 0.0002  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2116  data: 0.0002  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2091  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2088  data: 0.0002  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:58 (0.2103 s / it)
0.9700266429840142
Train Epoch: [2]  [   0/1125]  eta: 0:34:47  lr: 0.000020  loss: 0.0693  time: 1.8559  data: 1.1241  max mem: 15660
Train Epoch: [2]  [  50/1125]  eta: 0:10:53  lr: 0.000020  loss: 0.0191  time: 0.5856  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 100/1125]  eta: 0:10:14  lr: 0.000020  loss: 0.3388  time: 0.5968  data: 0.0002  max mem: 15660
Train Epoch: [2]  [ 150/1125]  eta: 0:09:40  lr: 0.000020  loss: 0.0347  time: 0.5919  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 200/1125]  eta: 0:09:07  lr: 0.000020  loss: 0.0950  time: 0.5821  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 250/1125]  eta: 0:08:37  lr: 0.000020  loss: 0.0222  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 300/1125]  eta: 0:08:06  lr: 0.000020  loss: 0.0024  time: 0.5779  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 350/1125]  eta: 0:07:37  lr: 0.000020  loss: 0.0074  time: 0.5847  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 400/1125]  eta: 0:07:07  lr: 0.000020  loss: 0.1081  time: 0.5815  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 450/1125]  eta: 0:06:37  lr: 0.000020  loss: 0.0066  time: 0.5891  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 500/1125]  eta: 0:06:07  lr: 0.000020  loss: 0.0027  time: 0.5806  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 550/1125]  eta: 0:05:38  lr: 0.000020  loss: 0.0506  time: 0.5801  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 600/1125]  eta: 0:05:08  lr: 0.000020  loss: 0.0055  time: 0.5883  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 650/1125]  eta: 0:04:39  lr: 0.000020  loss: 0.0044  time: 0.5909  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 700/1125]  eta: 0:04:09  lr: 0.000020  loss: 0.0051  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 750/1125]  eta: 0:03:40  lr: 0.000020  loss: 0.0050  time: 0.5825  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 800/1125]  eta: 0:03:11  lr: 0.000020  loss: 0.0208  time: 0.5882  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 850/1125]  eta: 0:02:41  lr: 0.000020  loss: 0.0188  time: 0.5828  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.1091  time: 0.5815  data: 0.0001  max mem: 15660
Train Epoch: [2]  [ 950/1125]  eta: 0:01:42  lr: 0.000020  loss: 0.0101  time: 0.5814  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.0078  time: 0.5862  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.2397  time: 0.5924  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.2637  time: 0.5934  data: 0.0001  max mem: 15660
Train Epoch: [2]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.0475  time: 0.5774  data: 0.0002  max mem: 15660
Train Epoch: [2] Total time: 0:11:01 (0.5877 s / it)
Averaged stats: lr: 0.0000  loss: 0.0552
Generate VQA test result:  [  0/563]  eta: 0:05:27    time: 0.5811  data: 0.3514  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2095  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2088 s / it)
0.9840142095914742
Train Epoch: [3]  [   0/1125]  eta: 0:33:14  lr: 0.000020  loss: 0.0668  time: 1.7726  data: 0.9195  max mem: 15660
Train Epoch: [3]  [  50/1125]  eta: 0:10:54  lr: 0.000020  loss: 0.1062  time: 0.5886  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 100/1125]  eta: 0:10:12  lr: 0.000020  loss: 0.0149  time: 0.5814  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 150/1125]  eta: 0:09:39  lr: 0.000020  loss: 0.0186  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 200/1125]  eta: 0:09:07  lr: 0.000020  loss: 0.0307  time: 0.5795  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 250/1125]  eta: 0:08:36  lr: 0.000020  loss: 0.0164  time: 0.5902  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 300/1125]  eta: 0:08:06  lr: 0.000020  loss: 0.0032  time: 0.5796  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 350/1125]  eta: 0:07:36  lr: 0.000020  loss: 0.0121  time: 0.5820  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 400/1125]  eta: 0:07:06  lr: 0.000020  loss: 0.0057  time: 0.5805  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 450/1125]  eta: 0:06:36  lr: 0.000020  loss: 0.0949  time: 0.5931  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 500/1125]  eta: 0:06:07  lr: 0.000020  loss: 0.0090  time: 0.5847  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 550/1125]  eta: 0:05:37  lr: 0.000020  loss: 0.0124  time: 0.5916  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 600/1125]  eta: 0:05:08  lr: 0.000020  loss: 0.0494  time: 0.5908  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 650/1125]  eta: 0:04:38  lr: 0.000020  loss: 0.0043  time: 0.5859  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 700/1125]  eta: 0:04:09  lr: 0.000020  loss: 0.0926  time: 0.5902  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 750/1125]  eta: 0:03:40  lr: 0.000020  loss: 0.0018  time: 0.5925  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 800/1125]  eta: 0:03:11  lr: 0.000020  loss: 0.0012  time: 0.5883  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 850/1125]  eta: 0:02:41  lr: 0.000020  loss: 0.0133  time: 0.5864  data: 0.0002  max mem: 15660
Train Epoch: [3]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.2120  time: 0.5948  data: 0.0001  max mem: 15660
Train Epoch: [3]  [ 950/1125]  eta: 0:01:42  lr: 0.000020  loss: 0.0203  time: 0.5916  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.0750  time: 0.6015  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.0201  time: 0.5985  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.0048  time: 0.5957  data: 0.0001  max mem: 15660
Train Epoch: [3]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.0096  time: 0.5808  data: 0.0002  max mem: 15660
Train Epoch: [3] Total time: 0:11:02 (0.5892 s / it)
Averaged stats: lr: 0.0000  loss: 0.0463
Generate VQA test result:  [  0/563]  eta: 0:05:11    time: 0.5539  data: 0.3253  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2077  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2072  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2078  data: 0.0002  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2081  data: 0.0002  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2079  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2066  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2088 s / it)
0.9837921847246892
Train Epoch: [4]  [   0/1125]  eta: 0:37:37  lr: 0.000020  loss: 0.0043  time: 2.0070  data: 1.1539  max mem: 15660
Train Epoch: [4]  [  50/1125]  eta: 0:11:01  lr: 0.000020  loss: 0.0030  time: 0.5783  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 100/1125]  eta: 0:10:16  lr: 0.000020  loss: 0.0033  time: 0.5829  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 150/1125]  eta: 0:09:40  lr: 0.000020  loss: 0.1055  time: 0.5869  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 200/1125]  eta: 0:09:10  lr: 0.000020  loss: 0.0037  time: 0.5974  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 250/1125]  eta: 0:08:39  lr: 0.000020  loss: 0.0046  time: 0.5895  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 300/1125]  eta: 0:08:09  lr: 0.000020  loss: 0.0098  time: 0.5941  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 350/1125]  eta: 0:07:39  lr: 0.000020  loss: 0.0316  time: 0.5927  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 400/1125]  eta: 0:07:09  lr: 0.000020  loss: 0.0993  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 450/1125]  eta: 0:06:38  lr: 0.000020  loss: 0.0012  time: 0.5847  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 500/1125]  eta: 0:06:08  lr: 0.000020  loss: 0.0059  time: 0.5776  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 550/1125]  eta: 0:05:39  lr: 0.000020  loss: 0.0412  time: 0.5919  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 600/1125]  eta: 0:05:09  lr: 0.000020  loss: 0.0121  time: 0.5844  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 650/1125]  eta: 0:04:39  lr: 0.000020  loss: 0.0276  time: 0.5717  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 700/1125]  eta: 0:04:10  lr: 0.000020  loss: 0.0656  time: 0.5983  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 750/1125]  eta: 0:03:40  lr: 0.000020  loss: 0.0174  time: 0.5873  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 800/1125]  eta: 0:03:11  lr: 0.000020  loss: 0.0022  time: 0.5834  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 850/1125]  eta: 0:02:41  lr: 0.000020  loss: 0.0064  time: 0.5905  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.1017  time: 0.5815  data: 0.0001  max mem: 15660
Train Epoch: [4]  [ 950/1125]  eta: 0:01:42  lr: 0.000020  loss: 0.1208  time: 0.5882  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.0103  time: 0.5770  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.0014  time: 0.5822  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.0055  time: 0.5866  data: 0.0001  max mem: 15660
Train Epoch: [4]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.2737  time: 0.5672  data: 0.0002  max mem: 15660
Train Epoch: [4] Total time: 0:11:01 (0.5876 s / it)
Averaged stats: lr: 0.0000  loss: 0.0373
Generate VQA test result:  [  0/563]  eta: 0:05:11    time: 0.5533  data: 0.3243  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2078  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2076  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2084  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2083  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2087  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2068  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2089 s / it)
0.9933392539964476
Train Epoch: [5]  [   0/1125]  eta: 0:33:05  lr: 0.000020  loss: 0.0089  time: 1.7650  data: 0.8812  max mem: 15660
Train Epoch: [5]  [  50/1125]  eta: 0:10:47  lr: 0.000020  loss: 0.0078  time: 0.5783  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 100/1125]  eta: 0:10:10  lr: 0.000020  loss: 0.0293  time: 0.5905  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 150/1125]  eta: 0:09:37  lr: 0.000020  loss: 0.0022  time: 0.5912  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 200/1125]  eta: 0:09:06  lr: 0.000020  loss: 0.0021  time: 0.5831  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 250/1125]  eta: 0:08:35  lr: 0.000020  loss: 0.0021  time: 0.5932  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 300/1125]  eta: 0:08:05  lr: 0.000020  loss: 0.0015  time: 0.5822  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 350/1125]  eta: 0:07:35  lr: 0.000020  loss: 0.0008  time: 0.5871  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 400/1125]  eta: 0:07:06  lr: 0.000020  loss: 0.0013  time: 0.5860  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 450/1125]  eta: 0:06:36  lr: 0.000020  loss: 0.0015  time: 0.5804  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 500/1125]  eta: 0:06:06  lr: 0.000020  loss: 0.0022  time: 0.5854  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 550/1125]  eta: 0:05:37  lr: 0.000020  loss: 0.0028  time: 0.5901  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 600/1125]  eta: 0:05:08  lr: 0.000020  loss: 0.0211  time: 0.5812  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 650/1125]  eta: 0:04:38  lr: 0.000020  loss: 0.0821  time: 0.5880  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 700/1125]  eta: 0:04:09  lr: 0.000020  loss: 0.0042  time: 0.5798  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 750/1125]  eta: 0:03:40  lr: 0.000020  loss: 0.0062  time: 0.5874  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 800/1125]  eta: 0:03:10  lr: 0.000020  loss: 0.0365  time: 0.5950  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 850/1125]  eta: 0:02:41  lr: 0.000020  loss: 0.0077  time: 0.5852  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.0249  time: 0.5833  data: 0.0001  max mem: 15660
Train Epoch: [5]  [ 950/1125]  eta: 0:01:42  lr: 0.000020  loss: 0.0897  time: 0.5782  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.0117  time: 0.5872  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1050/1125]  eta: 0:00:43  lr: 0.000020  loss: 0.0014  time: 0.5863  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.0672  time: 0.5858  data: 0.0001  max mem: 15660
Train Epoch: [5]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.0018  time: 0.5701  data: 0.0001  max mem: 15660
Train Epoch: [5] Total time: 0:10:59 (0.5861 s / it)
Averaged stats: lr: 0.0000  loss: 0.0390
Generate VQA test result:  [  0/563]  eta: 0:05:11    time: 0.5527  data: 0.3244  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:37    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2088  data: 0.0002  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2106  data: 0.0002  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2109  data: 0.0002  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2071  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2095 s / it)
0.9922291296625222
Train Epoch: [6]  [   0/1125]  eta: 0:33:11  lr: 0.000020  loss: 0.0047  time: 1.7699  data: 0.9920  max mem: 15660
Train Epoch: [6]  [  50/1125]  eta: 0:10:52  lr: 0.000020  loss: 0.0067  time: 0.5809  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 100/1125]  eta: 0:10:08  lr: 0.000020  loss: 0.0010  time: 0.5841  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 150/1125]  eta: 0:09:37  lr: 0.000020  loss: 0.0024  time: 0.5878  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 200/1125]  eta: 0:09:05  lr: 0.000020  loss: 0.0010  time: 0.5842  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 250/1125]  eta: 0:08:35  lr: 0.000020  loss: 0.0016  time: 0.5807  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 300/1125]  eta: 0:08:05  lr: 0.000020  loss: 0.0952  time: 0.5830  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 350/1125]  eta: 0:07:36  lr: 0.000020  loss: 0.0024  time: 0.5929  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 400/1125]  eta: 0:07:07  lr: 0.000020  loss: 0.0948  time: 0.5902  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 450/1125]  eta: 0:06:37  lr: 0.000020  loss: 0.0048  time: 0.5920  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 500/1125]  eta: 0:06:08  lr: 0.000020  loss: 0.0021  time: 0.5896  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 550/1125]  eta: 0:05:38  lr: 0.000020  loss: 0.0011  time: 0.5917  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 600/1125]  eta: 0:05:09  lr: 0.000020  loss: 0.0019  time: 0.5832  data: 0.0002  max mem: 15660
Train Epoch: [6]  [ 650/1125]  eta: 0:04:39  lr: 0.000020  loss: 0.0010  time: 0.5803  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 700/1125]  eta: 0:04:10  lr: 0.000020  loss: 0.0205  time: 0.5891  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 750/1125]  eta: 0:03:40  lr: 0.000020  loss: 0.1076  time: 0.5875  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 800/1125]  eta: 0:03:11  lr: 0.000020  loss: 0.0122  time: 0.5821  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 850/1125]  eta: 0:02:41  lr: 0.000020  loss: 0.1261  time: 0.5891  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 900/1125]  eta: 0:02:12  lr: 0.000020  loss: 0.0011  time: 0.5818  data: 0.0001  max mem: 15660
Train Epoch: [6]  [ 950/1125]  eta: 0:01:42  lr: 0.000020  loss: 0.0046  time: 0.5818  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.0165  time: 0.5864  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1050/1125]  eta: 0:00:44  lr: 0.000020  loss: 0.0010  time: 0.5864  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.2170  time: 0.5779  data: 0.0001  max mem: 15660
Train Epoch: [6]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.0141  time: 0.5813  data: 0.0002  max mem: 15660
Train Epoch: [6] Total time: 0:11:00 (0.5871 s / it)
Averaged stats: lr: 0.0000  loss: 0.0329
Generate VQA test result:  [  0/563]  eta: 0:05:34    time: 0.5947  data: 0.3616  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2076  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2089  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2092  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2080  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2078  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2082  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2077  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2064  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2089 s / it)
0.9769094138543517
Train Epoch: [7]  [   0/1125]  eta: 0:34:15  lr: 0.000020  loss: 0.0019  time: 1.8270  data: 0.9964  max mem: 15660
Train Epoch: [7]  [  50/1125]  eta: 0:10:55  lr: 0.000020  loss: 0.0025  time: 0.5873  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 100/1125]  eta: 0:10:15  lr: 0.000020  loss: 0.0009  time: 0.5981  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 150/1125]  eta: 0:09:41  lr: 0.000020  loss: 0.0016  time: 0.5802  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 200/1125]  eta: 0:09:09  lr: 0.000020  loss: 0.0022  time: 0.5873  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 250/1125]  eta: 0:08:38  lr: 0.000020  loss: 0.0020  time: 0.5846  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 300/1125]  eta: 0:08:08  lr: 0.000020  loss: 0.0030  time: 0.5974  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 350/1125]  eta: 0:07:38  lr: 0.000020  loss: 0.0023  time: 0.5840  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 400/1125]  eta: 0:07:08  lr: 0.000020  loss: 0.0010  time: 0.5812  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 450/1125]  eta: 0:06:38  lr: 0.000020  loss: 0.1593  time: 0.5859  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 500/1125]  eta: 0:06:07  lr: 0.000020  loss: 0.0013  time: 0.5779  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 550/1125]  eta: 0:05:38  lr: 0.000020  loss: 0.0007  time: 0.5906  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 600/1125]  eta: 0:05:08  lr: 0.000020  loss: 0.0028  time: 0.5820  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 650/1125]  eta: 0:04:39  lr: 0.000020  loss: 0.0004  time: 0.5794  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 700/1125]  eta: 0:04:09  lr: 0.000020  loss: 0.0010  time: 0.5760  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 750/1125]  eta: 0:03:40  lr: 0.000020  loss: 0.0068  time: 0.5904  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 800/1125]  eta: 0:03:10  lr: 0.000020  loss: 0.0035  time: 0.5854  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 850/1125]  eta: 0:02:41  lr: 0.000020  loss: 0.1246  time: 0.5843  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 900/1125]  eta: 0:02:11  lr: 0.000020  loss: 0.0543  time: 0.5885  data: 0.0001  max mem: 15660
Train Epoch: [7]  [ 950/1125]  eta: 0:01:42  lr: 0.000020  loss: 0.0012  time: 0.5782  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1000/1125]  eta: 0:01:13  lr: 0.000020  loss: 0.0017  time: 0.5823  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1050/1125]  eta: 0:00:43  lr: 0.000020  loss: 0.0342  time: 0.5845  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1100/1125]  eta: 0:00:14  lr: 0.000020  loss: 0.0054  time: 0.5845  data: 0.0001  max mem: 15660
Train Epoch: [7]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.3278  time: 0.5724  data: 0.0001  max mem: 15660
Train Epoch: [7] Total time: 0:10:59 (0.5864 s / it)
Averaged stats: lr: 0.0000  loss: 0.0252
Generate VQA test result:  [  0/563]  eta: 0:05:12    time: 0.5549  data: 0.3215  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:50    time: 0.2091  data: 0.0002  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:38    time: 0.2085  data: 0.0002  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:27    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:16    time: 0.2081  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2085  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:55    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2079  data: 0.0002  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:34    time: 0.2077  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2086  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2090  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2074  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2060  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:57 (0.2091 s / it)
0.9931172291296625
Generate VQA test result:  [  0/563]  eta: 0:05:10    time: 0.5512  data: 0.3215  max mem: 15660
Generate VQA test result:  [ 50/563]  eta: 0:01:49    time: 0.2058  data: 0.0001  max mem: 15660
Generate VQA test result:  [100/563]  eta: 0:01:36    time: 0.2059  data: 0.0001  max mem: 15660
Generate VQA test result:  [150/563]  eta: 0:01:26    time: 0.2061  data: 0.0001  max mem: 15660
Generate VQA test result:  [200/563]  eta: 0:01:15    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result:  [250/563]  eta: 0:01:05    time: 0.2065  data: 0.0001  max mem: 15660
Generate VQA test result:  [300/563]  eta: 0:00:54    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result:  [350/563]  eta: 0:00:44    time: 0.2075  data: 0.0001  max mem: 15660
Generate VQA test result:  [400/563]  eta: 0:00:33    time: 0.2070  data: 0.0001  max mem: 15660
Generate VQA test result:  [450/563]  eta: 0:00:23    time: 0.2073  data: 0.0001  max mem: 15660
Generate VQA test result:  [500/563]  eta: 0:00:13    time: 0.2069  data: 0.0001  max mem: 15660
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.2067  data: 0.0001  max mem: 15660
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.2057  data: 0.0001  max mem: 15660
Generate VQA test result: Total time: 0:01:56 (0.2076 s / it)
result file saved to output_optimal/vqa/result/vqa_result_epoch7.json
Training time 1:46:47