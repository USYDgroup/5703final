Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['text_encoder.encoder.layer.8.attention.self.query.weight', 'text_encoder.encoder.layer.8.attention.self.query.bias', 'text_encoder.encoder.layer.8.attention.self.key.weight', 'text_encoder.encoder.layer.8.attention.self.key.bias', 'text_encoder.encoder.layer.8.attention.self.value.weight', 'text_encoder.encoder.layer.8.attention.self.value.bias', 'text_encoder.encoder.layer.8.attention.output.dense.weight', 'text_encoder.encoder.layer.8.attention.output.dense.bias', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.crossattention.self.query.weight', 'text_encoder.encoder.layer.8.crossattention.self.query.bias', 'text_encoder.encoder.layer.8.crossattention.self.key.weight', 'text_encoder.encoder.layer.8.crossattention.self.key.bias', 'text_encoder.encoder.layer.8.crossattention.self.value.weight', 'text_encoder.encoder.layer.8.crossattention.self.value.bias', 'text_encoder.encoder.layer.8.crossattention.output.dense.weight', 'text_encoder.encoder.layer.8.crossattention.output.dense.bias', 'text_encoder.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.intermediate.dense.weight', 'text_encoder.encoder.layer.8.intermediate.dense.bias', 'text_encoder.encoder.layer.8.output.dense.weight', 'text_encoder.encoder.layer.8.output.dense.bias', 'text_encoder.encoder.layer.8.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.attention.self.query.weight', 'text_encoder.encoder.layer.9.attention.self.query.bias', 'text_encoder.encoder.layer.9.attention.self.key.weight', 'text_encoder.encoder.layer.9.attention.self.key.bias', 'text_encoder.encoder.layer.9.attention.self.value.weight', 'text_encoder.encoder.layer.9.attention.self.value.bias', 'text_encoder.encoder.layer.9.attention.output.dense.weight', 'text_encoder.encoder.layer.9.attention.output.dense.bias', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.crossattention.self.query.weight', 'text_encoder.encoder.layer.9.crossattention.self.query.bias', 'text_encoder.encoder.layer.9.crossattention.self.key.weight', 'text_encoder.encoder.layer.9.crossattention.self.key.bias', 'text_encoder.encoder.layer.9.crossattention.self.value.weight', 'text_encoder.encoder.layer.9.crossattention.self.value.bias', 'text_encoder.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.intermediate.dense.weight', 'text_encoder.encoder.layer.9.intermediate.dense.bias', 'text_encoder.encoder.layer.9.output.dense.weight', 'text_encoder.encoder.layer.9.output.dense.bias', 'text_encoder.encoder.layer.9.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.attention.self.query.weight', 'text_encoder.encoder.layer.10.attention.self.query.bias', 'text_encoder.encoder.layer.10.attention.self.key.weight', 'text_encoder.encoder.layer.10.attention.self.key.bias', 'text_encoder.encoder.layer.10.attention.self.value.weight', 'text_encoder.encoder.layer.10.attention.self.value.bias', 'text_encoder.encoder.layer.10.attention.output.dense.weight', 'text_encoder.encoder.layer.10.attention.output.dense.bias', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.crossattention.self.query.weight', 'text_encoder.encoder.layer.10.crossattention.self.query.bias', 'text_encoder.encoder.layer.10.crossattention.self.key.weight', 'text_encoder.encoder.layer.10.crossattention.self.key.bias', 'text_encoder.encoder.layer.10.crossattention.self.value.weight', 'text_encoder.encoder.layer.10.crossattention.self.value.bias', 'text_encoder.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.intermediate.dense.weight', 'text_encoder.encoder.layer.10.intermediate.dense.bias', 'text_encoder.encoder.layer.10.output.dense.weight', 'text_encoder.encoder.layer.10.output.dense.bias', 'text_encoder.encoder.layer.10.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.attention.self.query.weight', 'text_encoder.encoder.layer.11.attention.self.query.bias', 'text_encoder.encoder.layer.11.attention.self.key.weight', 'text_encoder.encoder.layer.11.attention.self.key.bias', 'text_encoder.encoder.layer.11.attention.self.value.weight', 'text_encoder.encoder.layer.11.attention.self.value.bias', 'text_encoder.encoder.layer.11.attention.output.dense.weight', 'text_encoder.encoder.layer.11.attention.output.dense.bias', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.crossattention.self.query.weight', 'text_encoder.encoder.layer.11.crossattention.self.query.bias', 'text_encoder.encoder.layer.11.crossattention.self.key.weight', 'text_encoder.encoder.layer.11.crossattention.self.key.bias', 'text_encoder.encoder.layer.11.crossattention.self.value.weight', 'text_encoder.encoder.layer.11.crossattention.self.value.bias', 'text_encoder.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.intermediate.dense.weight', 'text_encoder.encoder.layer.11.intermediate.dense.bias', 'text_encoder.encoder.layer.11.output.dense.weight', 'text_encoder.encoder.layer.11.output.dense.bias', 'text_encoder.encoder.layer.11.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.output.LayerNorm.bias', 'fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [   0/1125]  eta: 0:56:40  lr: 0.000010  loss: 1.2202  time: 3.0225  data: 1.5003  max mem: 10602
Train Epoch: [0]  [  50/1125]  eta: 0:09:18  lr: 0.000010  loss: 0.5523  time: 0.4688  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 100/1125]  eta: 0:08:28  lr: 0.000010  loss: 0.5061  time: 0.4730  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 150/1125]  eta: 0:07:55  lr: 0.000013  loss: 0.1860  time: 0.4695  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 200/1125]  eta: 0:07:27  lr: 0.000013  loss: 0.3842  time: 0.4718  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 250/1125]  eta: 0:07:01  lr: 0.000015  loss: 0.4363  time: 0.4747  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 300/1125]  eta: 0:06:36  lr: 0.000015  loss: 0.3130  time: 0.4688  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 350/1125]  eta: 0:06:11  lr: 0.000018  loss: 0.3102  time: 0.4766  data: 0.0001  max mem: 12685
Train Epoch: [0]  [ 400/1125]  eta: 0:05:47  lr: 0.000018  loss: 0.2592  time: 0.4737  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 450/1125]  eta: 0:05:22  lr: 0.000020  loss: 0.5111  time: 0.4731  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 500/1125]  eta: 0:04:58  lr: 0.000020  loss: 0.3715  time: 0.4716  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 550/1125]  eta: 0:04:34  lr: 0.000020  loss: 0.1896  time: 0.4705  data: 0.0001  max mem: 12685
Train Epoch: [0]  [ 600/1125]  eta: 0:04:10  lr: 0.000020  loss: 0.1229  time: 0.4722  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 650/1125]  eta: 0:03:46  lr: 0.000020  loss: 0.2250  time: 0.4760  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 700/1125]  eta: 0:03:22  lr: 0.000020  loss: 0.1833  time: 0.4718  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 750/1125]  eta: 0:02:58  lr: 0.000020  loss: 0.2096  time: 0.4782  data: 0.0001  max mem: 12685
Train Epoch: [0]  [ 800/1125]  eta: 0:02:34  lr: 0.000020  loss: 0.0684  time: 0.4757  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 850/1125]  eta: 0:02:10  lr: 0.000020  loss: 0.1640  time: 0.4752  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 900/1125]  eta: 0:01:47  lr: 0.000020  loss: 0.6129  time: 0.4745  data: 0.0002  max mem: 12685
Train Epoch: [0]  [ 950/1125]  eta: 0:01:23  lr: 0.000020  loss: 0.0321  time: 0.4742  data: 0.0002  max mem: 12685
Train Epoch: [0]  [1000/1125]  eta: 0:00:59  lr: 0.000020  loss: 0.0793  time: 0.4691  data: 0.0002  max mem: 12685
Train Epoch: [0]  [1050/1125]  eta: 0:00:35  lr: 0.000020  loss: 0.0311  time: 0.4733  data: 0.0002  max mem: 12685
Train Epoch: [0]  [1100/1125]  eta: 0:00:11  lr: 0.000020  loss: 0.0857  time: 0.4718  data: 0.0001  max mem: 12685
Train Epoch: [0]  [1124/1125]  eta: 0:00:00  lr: 0.000020  loss: 0.0808  time: 0.4665  data: 0.0002  max mem: 12685
Train Epoch: [0] Total time: 0:08:54 (0.4750 s / it)
Averaged stats: lr: 0.0000  loss: 0.2823
Generate VQA test result:  [  0/563]  eta: 0:06:49    time: 0.7272  data: 0.3342  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:37    time: 0.1790  data: 0.0001  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:25    time: 0.1792  data: 0.0001  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:15    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1785  data: 0.0001  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1782  data: 0.0001  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1788  data: 0.0001  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1785  data: 0.0002  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1787  data: 0.0001  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1782  data: 0.0002  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1786  data: 0.0001  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1786  data: 0.0002  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1774  data: 0.0001  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1797 s / it)
0.9551509769094139
Train Epoch: [1]  [   0/1125]  eta: 0:32:11  lr: 0.000019  loss: 0.1620  time: 1.7172  data: 1.2175  max mem: 12685
Train Epoch: [1]  [  50/1125]  eta: 0:08:53  lr: 0.000019  loss: 0.0805  time: 0.4727  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 100/1125]  eta: 0:08:16  lr: 0.000019  loss: 0.0322  time: 0.4729  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 150/1125]  eta: 0:07:49  lr: 0.000019  loss: 0.0111  time: 0.4757  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 200/1125]  eta: 0:07:23  lr: 0.000019  loss: 0.0537  time: 0.4693  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 250/1125]  eta: 0:06:58  lr: 0.000019  loss: 0.4831  time: 0.4724  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 300/1125]  eta: 0:06:33  lr: 0.000019  loss: 0.0826  time: 0.4712  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 350/1125]  eta: 0:06:09  lr: 0.000019  loss: 0.1469  time: 0.4727  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 400/1125]  eta: 0:05:45  lr: 0.000019  loss: 0.1725  time: 0.4716  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 450/1125]  eta: 0:05:21  lr: 0.000019  loss: 0.0137  time: 0.4732  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 500/1125]  eta: 0:04:57  lr: 0.000019  loss: 0.0422  time: 0.4756  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 550/1125]  eta: 0:04:33  lr: 0.000019  loss: 0.1078  time: 0.4723  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 600/1125]  eta: 0:04:09  lr: 0.000019  loss: 0.0097  time: 0.4729  data: 0.0001  max mem: 12685
Train Epoch: [1]  [ 650/1125]  eta: 0:03:45  lr: 0.000019  loss: 0.1333  time: 0.4790  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 700/1125]  eta: 0:03:21  lr: 0.000019  loss: 0.0199  time: 0.4704  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 750/1125]  eta: 0:02:58  lr: 0.000019  loss: 0.0200  time: 0.4726  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 800/1125]  eta: 0:02:34  lr: 0.000019  loss: 0.0067  time: 0.4712  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 850/1125]  eta: 0:02:10  lr: 0.000019  loss: 0.0096  time: 0.4733  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 900/1125]  eta: 0:01:46  lr: 0.000019  loss: 0.0154  time: 0.4750  data: 0.0002  max mem: 12685
Train Epoch: [1]  [ 950/1125]  eta: 0:01:23  lr: 0.000019  loss: 0.0090  time: 0.4708  data: 0.0002  max mem: 12685
Train Epoch: [1]  [1000/1125]  eta: 0:00:59  lr: 0.000019  loss: 0.0065  time: 0.4710  data: 0.0002  max mem: 12685
Train Epoch: [1]  [1050/1125]  eta: 0:00:35  lr: 0.000019  loss: 0.0715  time: 0.4750  data: 0.0002  max mem: 12685
Train Epoch: [1]  [1100/1125]  eta: 0:00:11  lr: 0.000019  loss: 0.0026  time: 0.4706  data: 0.0002  max mem: 12685
Train Epoch: [1]  [1124/1125]  eta: 0:00:00  lr: 0.000019  loss: 0.0773  time: 0.4671  data: 0.0002  max mem: 12685
Train Epoch: [1] Total time: 0:08:53 (0.4742 s / it)
Averaged stats: lr: 0.0000  loss: 0.0731
Generate VQA test result:  [  0/563]  eta: 0:05:31    time: 0.5893  data: 0.3966  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:35    time: 0.1785  data: 0.0001  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:24    time: 0.1789  data: 0.0002  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:14    time: 0.1790  data: 0.0001  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1794  data: 0.0001  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1791  data: 0.0001  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1793  data: 0.0001  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1795  data: 0.0001  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1783  data: 0.0002  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1789  data: 0.0002  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1785  data: 0.0002  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1798 s / it)
0.9826820603907638
Train Epoch: [2]  [   0/1125]  eta: 0:28:20  lr: 0.000017  loss: 0.0319  time: 1.5119  data: 1.0231  max mem: 12685
Train Epoch: [2]  [  50/1125]  eta: 0:08:51  lr: 0.000017  loss: 0.0330  time: 0.4737  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 100/1125]  eta: 0:08:15  lr: 0.000017  loss: 0.0096  time: 0.4716  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 150/1125]  eta: 0:07:47  lr: 0.000017  loss: 0.0099  time: 0.4762  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 200/1125]  eta: 0:07:23  lr: 0.000017  loss: 0.0220  time: 0.4770  data: 0.0001  max mem: 12685
Train Epoch: [2]  [ 250/1125]  eta: 0:06:58  lr: 0.000017  loss: 0.0453  time: 0.4767  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 300/1125]  eta: 0:06:33  lr: 0.000017  loss: 0.0675  time: 0.4733  data: 0.0003  max mem: 12685
Train Epoch: [2]  [ 350/1125]  eta: 0:06:09  lr: 0.000017  loss: 0.0013  time: 0.4758  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 400/1125]  eta: 0:05:45  lr: 0.000017  loss: 0.0471  time: 0.4763  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 450/1125]  eta: 0:05:21  lr: 0.000017  loss: 0.0112  time: 0.4739  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 500/1125]  eta: 0:04:57  lr: 0.000017  loss: 0.0244  time: 0.4743  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 550/1125]  eta: 0:04:33  lr: 0.000017  loss: 0.0063  time: 0.4727  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 600/1125]  eta: 0:04:09  lr: 0.000017  loss: 0.0038  time: 0.4756  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 650/1125]  eta: 0:03:45  lr: 0.000017  loss: 0.0071  time: 0.4728  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 700/1125]  eta: 0:03:22  lr: 0.000017  loss: 0.0170  time: 0.4707  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 750/1125]  eta: 0:02:58  lr: 0.000017  loss: 0.0108  time: 0.4770  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 800/1125]  eta: 0:02:34  lr: 0.000017  loss: 0.0018  time: 0.4702  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 850/1125]  eta: 0:02:10  lr: 0.000017  loss: 0.4031  time: 0.4725  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 900/1125]  eta: 0:01:46  lr: 0.000017  loss: 0.1097  time: 0.4758  data: 0.0002  max mem: 12685
Train Epoch: [2]  [ 950/1125]  eta: 0:01:23  lr: 0.000017  loss: 0.1039  time: 0.4718  data: 0.0002  max mem: 12685
Train Epoch: [2]  [1000/1125]  eta: 0:00:59  lr: 0.000017  loss: 0.0252  time: 0.4732  data: 0.0002  max mem: 12685
Train Epoch: [2]  [1050/1125]  eta: 0:00:35  lr: 0.000017  loss: 0.0012  time: 0.4716  data: 0.0002  max mem: 12685
Train Epoch: [2]  [1100/1125]  eta: 0:00:11  lr: 0.000017  loss: 0.0047  time: 0.4742  data: 0.0002  max mem: 12685
Train Epoch: [2]  [1124/1125]  eta: 0:00:00  lr: 0.000017  loss: 0.0024  time: 0.4712  data: 0.0001  max mem: 12685
Train Epoch: [2] Total time: 0:08:53 (0.4744 s / it)
Averaged stats: lr: 0.0000  loss: 0.0350
Generate VQA test result:  [  0/563]  eta: 0:05:57    time: 0.6354  data: 0.4468  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:36    time: 0.1782  data: 0.0001  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:24    time: 0.1783  data: 0.0002  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:14    time: 0.1788  data: 0.0001  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1792  data: 0.0001  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1786  data: 0.0001  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1790  data: 0.0001  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1796  data: 0.0001  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1791  data: 0.0001  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1784  data: 0.0001  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1783  data: 0.0002  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1778  data: 0.0001  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1799 s / it)
0.9820159857904085
Train Epoch: [3]  [   0/1125]  eta: 0:29:57  lr: 0.000014  loss: 0.2900  time: 1.5976  data: 1.0628  max mem: 12685
Train Epoch: [3]  [  50/1125]  eta: 0:08:50  lr: 0.000014  loss: 0.0058  time: 0.4714  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 100/1125]  eta: 0:08:15  lr: 0.000014  loss: 0.0048  time: 0.4744  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 150/1125]  eta: 0:07:46  lr: 0.000014  loss: 0.0010  time: 0.4698  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 200/1125]  eta: 0:07:20  lr: 0.000014  loss: 0.0051  time: 0.4707  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 250/1125]  eta: 0:06:56  lr: 0.000014  loss: 0.0052  time: 0.4761  data: 0.0001  max mem: 12685
Train Epoch: [3]  [ 300/1125]  eta: 0:06:32  lr: 0.000014  loss: 0.0023  time: 0.4719  data: 0.0001  max mem: 12685
Train Epoch: [3]  [ 350/1125]  eta: 0:06:08  lr: 0.000014  loss: 0.1604  time: 0.4729  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 400/1125]  eta: 0:05:44  lr: 0.000014  loss: 0.0010  time: 0.4734  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 450/1125]  eta: 0:05:20  lr: 0.000014  loss: 0.0040  time: 0.4731  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 500/1125]  eta: 0:04:56  lr: 0.000014  loss: 0.0015  time: 0.4748  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 550/1125]  eta: 0:04:33  lr: 0.000014  loss: 0.0012  time: 0.4747  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 600/1125]  eta: 0:04:09  lr: 0.000014  loss: 0.0131  time: 0.4705  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 650/1125]  eta: 0:03:45  lr: 0.000014  loss: 0.0017  time: 0.4707  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 700/1125]  eta: 0:03:21  lr: 0.000014  loss: 0.0007  time: 0.4772  data: 0.0001  max mem: 12685
Train Epoch: [3]  [ 750/1125]  eta: 0:02:57  lr: 0.000014  loss: 0.0199  time: 0.4704  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 800/1125]  eta: 0:02:34  lr: 0.000014  loss: 0.0028  time: 0.4731  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 850/1125]  eta: 0:02:10  lr: 0.000014  loss: 0.0014  time: 0.4745  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 900/1125]  eta: 0:01:46  lr: 0.000014  loss: 0.0011  time: 0.4733  data: 0.0002  max mem: 12685
Train Epoch: [3]  [ 950/1125]  eta: 0:01:23  lr: 0.000014  loss: 0.0243  time: 0.4739  data: 0.0002  max mem: 12685
Train Epoch: [3]  [1000/1125]  eta: 0:00:59  lr: 0.000014  loss: 0.0248  time: 0.4741  data: 0.0002  max mem: 12685
Train Epoch: [3]  [1050/1125]  eta: 0:00:35  lr: 0.000014  loss: 0.0019  time: 0.4728  data: 0.0002  max mem: 12685
Train Epoch: [3]  [1100/1125]  eta: 0:00:11  lr: 0.000014  loss: 0.0270  time: 0.4762  data: 0.0002  max mem: 12685
Train Epoch: [3]  [1124/1125]  eta: 0:00:00  lr: 0.000014  loss: 0.0505  time: 0.4693  data: 0.0002  max mem: 12685
Train Epoch: [3] Total time: 0:08:53 (0.4745 s / it)
Averaged stats: lr: 0.0000  loss: 0.0241
Generate VQA test result:  [  0/563]  eta: 0:05:04    time: 0.5409  data: 0.3521  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:35    time: 0.1788  data: 0.0002  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:24    time: 0.1791  data: 0.0001  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:15    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1793  data: 0.0002  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1792  data: 0.0001  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1788  data: 0.0001  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1792  data: 0.0001  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1792  data: 0.0001  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1787  data: 0.0001  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1790  data: 0.0001  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1787  data: 0.0001  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1781  data: 0.0001  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1799 s / it)
0.9960035523978685
Train Epoch: [4]  [   0/1125]  eta: 0:33:30  lr: 0.000011  loss: 0.0007  time: 1.7873  data: 1.1906  max mem: 12685
Train Epoch: [4]  [  50/1125]  eta: 0:08:53  lr: 0.000011  loss: 0.0893  time: 0.4710  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 100/1125]  eta: 0:08:15  lr: 0.000011  loss: 0.0055  time: 0.4742  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 150/1125]  eta: 0:07:47  lr: 0.000011  loss: 0.0011  time: 0.4723  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 200/1125]  eta: 0:07:22  lr: 0.000011  loss: 0.0010  time: 0.4731  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 250/1125]  eta: 0:06:57  lr: 0.000011  loss: 0.0010  time: 0.4738  data: 0.0001  max mem: 12685
Train Epoch: [4]  [ 300/1125]  eta: 0:06:33  lr: 0.000011  loss: 0.0018  time: 0.4718  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 350/1125]  eta: 0:06:09  lr: 0.000011  loss: 0.0080  time: 0.4775  data: 0.0001  max mem: 12685
Train Epoch: [4]  [ 400/1125]  eta: 0:05:45  lr: 0.000011  loss: 0.0025  time: 0.4754  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 450/1125]  eta: 0:05:21  lr: 0.000011  loss: 0.0437  time: 0.4728  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 500/1125]  eta: 0:04:57  lr: 0.000011  loss: 0.0449  time: 0.4754  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 550/1125]  eta: 0:04:33  lr: 0.000011  loss: 0.1011  time: 0.4712  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 600/1125]  eta: 0:04:09  lr: 0.000011  loss: 0.0270  time: 0.4690  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 650/1125]  eta: 0:03:45  lr: 0.000011  loss: 0.0008  time: 0.4713  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 700/1125]  eta: 0:03:21  lr: 0.000011  loss: 0.0023  time: 0.4758  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 750/1125]  eta: 0:02:57  lr: 0.000011  loss: 0.0038  time: 0.4746  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 800/1125]  eta: 0:02:34  lr: 0.000011  loss: 0.0004  time: 0.4736  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 850/1125]  eta: 0:02:10  lr: 0.000011  loss: 0.0636  time: 0.4719  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 900/1125]  eta: 0:01:46  lr: 0.000011  loss: 0.0260  time: 0.4735  data: 0.0002  max mem: 12685
Train Epoch: [4]  [ 950/1125]  eta: 0:01:22  lr: 0.000011  loss: 0.1818  time: 0.4732  data: 0.0002  max mem: 12685
Train Epoch: [4]  [1000/1125]  eta: 0:00:59  lr: 0.000011  loss: 0.0008  time: 0.4745  data: 0.0002  max mem: 12685
Train Epoch: [4]  [1050/1125]  eta: 0:00:35  lr: 0.000011  loss: 0.0009  time: 0.4723  data: 0.0002  max mem: 12685
Train Epoch: [4]  [1100/1125]  eta: 0:00:11  lr: 0.000011  loss: 0.0002  time: 0.4735  data: 0.0002  max mem: 12685
Train Epoch: [4]  [1124/1125]  eta: 0:00:00  lr: 0.000011  loss: 0.0190  time: 0.4684  data: 0.0002  max mem: 12685
Train Epoch: [4] Total time: 0:08:53 (0.4741 s / it)
Averaged stats: lr: 0.0000  loss: 0.0160
Generate VQA test result:  [  0/563]  eta: 0:05:15    time: 0.5596  data: 0.3746  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:35    time: 0.1786  data: 0.0002  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:24    time: 0.1792  data: 0.0002  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:14    time: 0.1790  data: 0.0002  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1788  data: 0.0001  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1787  data: 0.0001  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1789  data: 0.0002  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1790  data: 0.0001  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1784  data: 0.0001  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1797  data: 0.0001  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1791  data: 0.0001  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1781  data: 0.0001  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1796 s / it)
0.9962255772646537
Train Epoch: [5]  [   0/1125]  eta: 0:22:41  lr: 0.000007  loss: 0.0187  time: 1.2101  data: 0.6718  max mem: 12685
Train Epoch: [5]  [  50/1125]  eta: 0:08:46  lr: 0.000007  loss: 0.0018  time: 0.4728  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 100/1125]  eta: 0:08:13  lr: 0.000007  loss: 0.0012  time: 0.4755  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 150/1125]  eta: 0:07:47  lr: 0.000007  loss: 0.0021  time: 0.4757  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 200/1125]  eta: 0:07:21  lr: 0.000007  loss: 0.0107  time: 0.4707  data: 0.0001  max mem: 12685
Train Epoch: [5]  [ 250/1125]  eta: 0:06:56  lr: 0.000007  loss: 0.0093  time: 0.4735  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 300/1125]  eta: 0:06:32  lr: 0.000007  loss: 0.0006  time: 0.4726  data: 0.0001  max mem: 12685
Train Epoch: [5]  [ 350/1125]  eta: 0:06:08  lr: 0.000007  loss: 0.0168  time: 0.4748  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 400/1125]  eta: 0:05:44  lr: 0.000007  loss: 0.0005  time: 0.4752  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 450/1125]  eta: 0:05:20  lr: 0.000007  loss: 0.0028  time: 0.4745  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 500/1125]  eta: 0:04:56  lr: 0.000007  loss: 0.0012  time: 0.4703  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 550/1125]  eta: 0:04:33  lr: 0.000007  loss: 0.0014  time: 0.4749  data: 0.0001  max mem: 12685
Train Epoch: [5]  [ 600/1125]  eta: 0:04:09  lr: 0.000007  loss: 0.0007  time: 0.4691  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 650/1125]  eta: 0:03:45  lr: 0.000007  loss: 0.0006  time: 0.4720  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 700/1125]  eta: 0:03:21  lr: 0.000007  loss: 0.0008  time: 0.4743  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 750/1125]  eta: 0:02:57  lr: 0.000007  loss: 0.0317  time: 0.4729  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 800/1125]  eta: 0:02:34  lr: 0.000007  loss: 0.0010  time: 0.4721  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 850/1125]  eta: 0:02:10  lr: 0.000007  loss: 0.0002  time: 0.4678  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 900/1125]  eta: 0:01:46  lr: 0.000007  loss: 0.0015  time: 0.4721  data: 0.0002  max mem: 12685
Train Epoch: [5]  [ 950/1125]  eta: 0:01:22  lr: 0.000007  loss: 0.0015  time: 0.4744  data: 0.0002  max mem: 12685
Train Epoch: [5]  [1000/1125]  eta: 0:00:59  lr: 0.000007  loss: 0.0008  time: 0.4704  data: 0.0002  max mem: 12685
Train Epoch: [5]  [1050/1125]  eta: 0:00:35  lr: 0.000007  loss: 0.0009  time: 0.4753  data: 0.0002  max mem: 12685
Train Epoch: [5]  [1100/1125]  eta: 0:00:11  lr: 0.000007  loss: 0.0003  time: 0.4709  data: 0.0002  max mem: 12685
Train Epoch: [5]  [1124/1125]  eta: 0:00:00  lr: 0.000007  loss: 0.0005  time: 0.4692  data: 0.0002  max mem: 12685
Train Epoch: [5] Total time: 0:08:52 (0.4736 s / it)
Averaged stats: lr: 0.0000  loss: 0.0099
Generate VQA test result:  [  0/563]  eta: 0:05:04    time: 0.5409  data: 0.3500  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:35    time: 0.1783  data: 0.0002  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:24    time: 0.1788  data: 0.0002  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:14    time: 0.1796  data: 0.0002  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1789  data: 0.0002  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1787  data: 0.0002  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1792  data: 0.0001  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1788  data: 0.0002  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1787  data: 0.0002  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1789  data: 0.0002  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1787  data: 0.0001  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1780  data: 0.0001  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1797 s / it)
0.9966696269982238
Train Epoch: [6]  [   0/1125]  eta: 0:30:21  lr: 0.000004  loss: 0.0008  time: 1.6192  data: 0.9793  max mem: 12685
Train Epoch: [6]  [  50/1125]  eta: 0:08:52  lr: 0.000004  loss: 0.3825  time: 0.4737  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 100/1125]  eta: 0:08:15  lr: 0.000004  loss: 0.0006  time: 0.4741  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 150/1125]  eta: 0:07:47  lr: 0.000004  loss: 0.0003  time: 0.4690  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 200/1125]  eta: 0:07:22  lr: 0.000004  loss: 0.0194  time: 0.4750  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 250/1125]  eta: 0:06:57  lr: 0.000004  loss: 0.0007  time: 0.4735  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 300/1125]  eta: 0:06:33  lr: 0.000004  loss: 0.0007  time: 0.4710  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 350/1125]  eta: 0:06:08  lr: 0.000004  loss: 0.0009  time: 0.4722  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 400/1125]  eta: 0:05:44  lr: 0.000004  loss: 0.0004  time: 0.4766  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 450/1125]  eta: 0:05:20  lr: 0.000004  loss: 0.0003  time: 0.4747  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 500/1125]  eta: 0:04:56  lr: 0.000004  loss: 0.0005  time: 0.4712  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 550/1125]  eta: 0:04:33  lr: 0.000004  loss: 0.0006  time: 0.4736  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 600/1125]  eta: 0:04:09  lr: 0.000004  loss: 0.0007  time: 0.4692  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 650/1125]  eta: 0:03:45  lr: 0.000004  loss: 0.0001  time: 0.4793  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 700/1125]  eta: 0:03:21  lr: 0.000004  loss: 0.0008  time: 0.4736  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 750/1125]  eta: 0:02:57  lr: 0.000004  loss: 0.0005  time: 0.4756  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 800/1125]  eta: 0:02:34  lr: 0.000004  loss: 0.0004  time: 0.4715  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 850/1125]  eta: 0:02:10  lr: 0.000004  loss: 0.0018  time: 0.4752  data: 0.0001  max mem: 12685
Train Epoch: [6]  [ 900/1125]  eta: 0:01:46  lr: 0.000004  loss: 0.0002  time: 0.4749  data: 0.0002  max mem: 12685
Train Epoch: [6]  [ 950/1125]  eta: 0:01:23  lr: 0.000004  loss: 0.0004  time: 0.4719  data: 0.0002  max mem: 12685
Train Epoch: [6]  [1000/1125]  eta: 0:00:59  lr: 0.000004  loss: 0.0009  time: 0.4723  data: 0.0002  max mem: 12685
Train Epoch: [6]  [1050/1125]  eta: 0:00:35  lr: 0.000004  loss: 0.0051  time: 0.4730  data: 0.0001  max mem: 12685
Train Epoch: [6]  [1100/1125]  eta: 0:00:11  lr: 0.000004  loss: 0.0007  time: 0.4732  data: 0.0002  max mem: 12685
Train Epoch: [6]  [1124/1125]  eta: 0:00:00  lr: 0.000004  loss: 0.0003  time: 0.4714  data: 0.0002  max mem: 12685
Train Epoch: [6] Total time: 0:08:53 (0.4743 s / it)
Averaged stats: lr: 0.0000  loss: 0.0073
Generate VQA test result:  [  0/563]  eta: 0:04:48    time: 0.5119  data: 0.3252  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:35    time: 0.1785  data: 0.0002  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:24    time: 0.1793  data: 0.0001  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:14    time: 0.1791  data: 0.0001  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1792  data: 0.0002  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1784  data: 0.0002  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1793  data: 0.0001  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1788  data: 0.0001  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1788  data: 0.0001  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1790  data: 0.0001  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1798  data: 0.0002  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1780  data: 0.0001  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1798 s / it)
0.9973357015985791
Train Epoch: [7]  [   0/1125]  eta: 0:33:17  lr: 0.000002  loss: 0.0005  time: 1.7759  data: 1.2173  max mem: 12685
Train Epoch: [7]  [  50/1125]  eta: 0:08:55  lr: 0.000002  loss: 0.0024  time: 0.4738  data: 0.0001  max mem: 12685
Train Epoch: [7]  [ 100/1125]  eta: 0:08:17  lr: 0.000002  loss: 0.0004  time: 0.4708  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 150/1125]  eta: 0:07:49  lr: 0.000002  loss: 0.0002  time: 0.4725  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 200/1125]  eta: 0:07:23  lr: 0.000002  loss: 0.0002  time: 0.4775  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 250/1125]  eta: 0:06:59  lr: 0.000002  loss: 0.0002  time: 0.4780  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 300/1125]  eta: 0:06:34  lr: 0.000002  loss: 0.0004  time: 0.4721  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 350/1125]  eta: 0:06:10  lr: 0.000002  loss: 0.0002  time: 0.4760  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 400/1125]  eta: 0:05:46  lr: 0.000002  loss: 0.0001  time: 0.4738  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 450/1125]  eta: 0:05:21  lr: 0.000002  loss: 0.0003  time: 0.4720  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 500/1125]  eta: 0:04:57  lr: 0.000002  loss: 0.0007  time: 0.4743  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 550/1125]  eta: 0:04:33  lr: 0.000002  loss: 0.0001  time: 0.4753  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 600/1125]  eta: 0:04:10  lr: 0.000002  loss: 0.1875  time: 0.4749  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 650/1125]  eta: 0:03:46  lr: 0.000002  loss: 0.0001  time: 0.4745  data: 0.0001  max mem: 12685
Train Epoch: [7]  [ 700/1125]  eta: 0:03:22  lr: 0.000002  loss: 0.0012  time: 0.4783  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 750/1125]  eta: 0:02:58  lr: 0.000002  loss: 0.0002  time: 0.4717  data: 0.0001  max mem: 12685
Train Epoch: [7]  [ 800/1125]  eta: 0:02:34  lr: 0.000002  loss: 0.0003  time: 0.4734  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 850/1125]  eta: 0:02:10  lr: 0.000002  loss: 0.0004  time: 0.4702  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 900/1125]  eta: 0:01:46  lr: 0.000002  loss: 0.0006  time: 0.4750  data: 0.0002  max mem: 12685
Train Epoch: [7]  [ 950/1125]  eta: 0:01:23  lr: 0.000002  loss: 0.0004  time: 0.4732  data: 0.0002  max mem: 12685
Train Epoch: [7]  [1000/1125]  eta: 0:00:59  lr: 0.000002  loss: 0.0001  time: 0.4724  data: 0.0002  max mem: 12685
Train Epoch: [7]  [1050/1125]  eta: 0:00:35  lr: 0.000002  loss: 0.0005  time: 0.4745  data: 0.0002  max mem: 12685
Train Epoch: [7]  [1100/1125]  eta: 0:00:11  lr: 0.000002  loss: 0.0007  time: 0.4716  data: 0.0002  max mem: 12685
Train Epoch: [7]  [1124/1125]  eta: 0:00:00  lr: 0.000002  loss: 0.0002  time: 0.4708  data: 0.0002  max mem: 12685
Train Epoch: [7] Total time: 0:08:54 (0.4752 s / it)
Averaged stats: lr: 0.0000  loss: 0.0056
Generate VQA test result:  [  0/563]  eta: 0:04:41    time: 0.4994  data: 0.3059  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:35    time: 0.1791  data: 0.0002  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:24    time: 0.1785  data: 0.0002  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:14    time: 0.1791  data: 0.0001  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1797  data: 0.0002  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1788  data: 0.0001  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1788  data: 0.0002  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1791  data: 0.0002  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1790  data: 0.0001  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1782  data: 0.0001  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1787  data: 0.0001  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1782  data: 0.0002  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1789  data: 0.0001  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1796 s / it)
0.9977797513321492
Generate VQA test result:  [  0/563]  eta: 0:05:08    time: 0.5480  data: 0.3603  max mem: 12685
Generate VQA test result:  [ 50/563]  eta: 0:01:35    time: 0.1782  data: 0.0002  max mem: 12685
Generate VQA test result:  [100/563]  eta: 0:01:24    time: 0.1788  data: 0.0002  max mem: 12685
Generate VQA test result:  [150/563]  eta: 0:01:14    time: 0.1796  data: 0.0002  max mem: 12685
Generate VQA test result:  [200/563]  eta: 0:01:05    time: 0.1798  data: 0.0001  max mem: 12685
Generate VQA test result:  [250/563]  eta: 0:00:56    time: 0.1793  data: 0.0001  max mem: 12685
Generate VQA test result:  [300/563]  eta: 0:00:47    time: 0.1794  data: 0.0002  max mem: 12685
Generate VQA test result:  [350/563]  eta: 0:00:38    time: 0.1802  data: 0.0002  max mem: 12685
Generate VQA test result:  [400/563]  eta: 0:00:29    time: 0.1797  data: 0.0002  max mem: 12685
Generate VQA test result:  [450/563]  eta: 0:00:20    time: 0.1794  data: 0.0001  max mem: 12685
Generate VQA test result:  [500/563]  eta: 0:00:11    time: 0.1788  data: 0.0002  max mem: 12685
Generate VQA test result:  [550/563]  eta: 0:00:02    time: 0.1785  data: 0.0001  max mem: 12685
Generate VQA test result:  [562/563]  eta: 0:00:00    time: 0.1782  data: 0.0001  max mem: 12685
Generate VQA test result: Total time: 0:01:41 (0.1800 s / it)
result file saved to output/vqa/result/vqa_result_epoch7.json
Training time 1:27:01