Not using distributed mode
Creating vqa datasets
Creating model
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/output_vqa2/vqa/checkpoint_07.pth ,evaluate.
<All keys matched successfully>
Start training
Traceback (most recent call last):
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 392, in <module>
    main(args, config)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 351, in main
    vqa_result = evaluation(model, test_loader, tokenizer, device, config)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run_vqa2.py", line 138, in evaluation
    topk_ids, topk_probs = model(image, question_input, answer_input, train=False, k=config['k_test'])
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/pre_vqa.py", line 166, in forward
    topk_ids, topk_probs = self.rank_answer(question_output.last_hidden_state, quesiton.attention_mask,
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/pre_vqa.py", line 220, in rank_answer
    output = self.text_decoder(input_ids,
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/src/xbert.py", line 1299, in forward
    lm_loss = loss_fct(shifted_prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 836.00 MiB (GPU 0; 23.69 GiB total capacity; 3.25 GiB already allocated; 268.44 MiB free; 3.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF