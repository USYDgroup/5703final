Not using distributed mode
Creating vqa datasets
Creating model
reshape position embedding from 256 to 576
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/ALBEF.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['temp', 'image_queue', 'text_queue', 'queue_ptr', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'visual_encoder_m.cls_token', 'visual_encoder_m.pos_embed', 'visual_encoder_m.patch_embed.proj.weight', 'visual_encoder_m.patch_embed.proj.bias', 'visual_encoder_m.blocks.0.norm1.weight', 'visual_encoder_m.blocks.0.norm1.bias', 'visual_encoder_m.blocks.0.attn.qkv.weight', 'visual_encoder_m.blocks.0.attn.qkv.bias', 'visual_encoder_m.blocks.0.attn.proj.weight', 'visual_encoder_m.blocks.0.attn.proj.bias', 'visual_encoder_m.blocks.0.norm2.weight', 'visual_encoder_m.blocks.0.norm2.bias', 'visual_encoder_m.blocks.0.mlp.fc1.weight', 'visual_encoder_m.blocks.0.mlp.fc1.bias', 'visual_encoder_m.blocks.0.mlp.fc2.weight', 'visual_encoder_m.blocks.0.mlp.fc2.bias', 'visual_encoder_m.blocks.1.norm1.weight', 'visual_encoder_m.blocks.1.norm1.bias', 'visual_encoder_m.blocks.1.attn.qkv.weight', 'visual_encoder_m.blocks.1.attn.qkv.bias', 'visual_encoder_m.blocks.1.attn.proj.weight', 'visual_encoder_m.blocks.1.attn.proj.bias', 'visual_encoder_m.blocks.1.norm2.weight', 'visual_encoder_m.blocks.1.norm2.bias', 'visual_encoder_m.blocks.1.mlp.fc1.weight', 'visual_encoder_m.blocks.1.mlp.fc1.bias', 'visual_encoder_m.blocks.1.mlp.fc2.weight', 'visual_encoder_m.blocks.1.mlp.fc2.bias', 'visual_encoder_m.blocks.2.norm1.weight', 'visual_encoder_m.blocks.2.norm1.bias', 'visual_encoder_m.blocks.2.attn.qkv.weight', 'visual_encoder_m.blocks.2.attn.qkv.bias', 'visual_encoder_m.blocks.2.attn.proj.weight', 'visual_encoder_m.blocks.2.attn.proj.bias', 'visual_encoder_m.blocks.2.norm2.weight', 'visual_encoder_m.blocks.2.norm2.bias', 'visual_encoder_m.blocks.2.mlp.fc1.weight', 'visual_encoder_m.blocks.2.mlp.fc1.bias', 'visual_encoder_m.blocks.2.mlp.fc2.weight', 'visual_encoder_m.blocks.2.mlp.fc2.bias', 'visual_encoder_m.blocks.3.norm1.weight', 'visual_encoder_m.blocks.3.norm1.bias', 'visual_encoder_m.blocks.3.attn.qkv.weight', 'visual_encoder_m.blocks.3.attn.qkv.bias', 'visual_encoder_m.blocks.3.attn.proj.weight', 'visual_encoder_m.blocks.3.attn.proj.bias', 'visual_encoder_m.blocks.3.norm2.weight', 'visual_encoder_m.blocks.3.norm2.bias', 'visual_encoder_m.blocks.3.mlp.fc1.weight', 'visual_encoder_m.blocks.3.mlp.fc1.bias', 'visual_encoder_m.blocks.3.mlp.fc2.weight', 'visual_encoder_m.blocks.3.mlp.fc2.bias', 'visual_encoder_m.blocks.4.norm1.weight', 'visual_encoder_m.blocks.4.norm1.bias', 'visual_encoder_m.blocks.4.attn.qkv.weight', 'visual_encoder_m.blocks.4.attn.qkv.bias', 'visual_encoder_m.blocks.4.attn.proj.weight', 'visual_encoder_m.blocks.4.attn.proj.bias', 'visual_encoder_m.blocks.4.norm2.weight', 'visual_encoder_m.blocks.4.norm2.bias', 'visual_encoder_m.blocks.4.mlp.fc1.weight', 'visual_encoder_m.blocks.4.mlp.fc1.bias', 'visual_encoder_m.blocks.4.mlp.fc2.weight', 'visual_encoder_m.blocks.4.mlp.fc2.bias', 'visual_encoder_m.blocks.5.norm1.weight', 'visual_encoder_m.blocks.5.norm1.bias', 'visual_encoder_m.blocks.5.attn.qkv.weight', 'visual_encoder_m.blocks.5.attn.qkv.bias', 'visual_encoder_m.blocks.5.attn.proj.weight', 'visual_encoder_m.blocks.5.attn.proj.bias', 'visual_encoder_m.blocks.5.norm2.weight', 'visual_encoder_m.blocks.5.norm2.bias', 'visual_encoder_m.blocks.5.mlp.fc1.weight', 'visual_encoder_m.blocks.5.mlp.fc1.bias', 'visual_encoder_m.blocks.5.mlp.fc2.weight', 'visual_encoder_m.blocks.5.mlp.fc2.bias', 'visual_encoder_m.blocks.6.norm1.weight', 'visual_encoder_m.blocks.6.norm1.bias', 'visual_encoder_m.blocks.6.attn.qkv.weight', 'visual_encoder_m.blocks.6.attn.qkv.bias', 'visual_encoder_m.blocks.6.attn.proj.weight', 'visual_encoder_m.blocks.6.attn.proj.bias', 'visual_encoder_m.blocks.6.norm2.weight', 'visual_encoder_m.blocks.6.norm2.bias', 'visual_encoder_m.blocks.6.mlp.fc1.weight', 'visual_encoder_m.blocks.6.mlp.fc1.bias', 'visual_encoder_m.blocks.6.mlp.fc2.weight', 'visual_encoder_m.blocks.6.mlp.fc2.bias', 'visual_encoder_m.blocks.7.norm1.weight', 'visual_encoder_m.blocks.7.norm1.bias', 'visual_encoder_m.blocks.7.attn.qkv.weight', 'visual_encoder_m.blocks.7.attn.qkv.bias', 'visual_encoder_m.blocks.7.attn.proj.weight', 'visual_encoder_m.blocks.7.attn.proj.bias', 'visual_encoder_m.blocks.7.norm2.weight', 'visual_encoder_m.blocks.7.norm2.bias', 'visual_encoder_m.blocks.7.mlp.fc1.weight', 'visual_encoder_m.blocks.7.mlp.fc1.bias', 'visual_encoder_m.blocks.7.mlp.fc2.weight', 'visual_encoder_m.blocks.7.mlp.fc2.bias', 'visual_encoder_m.blocks.8.norm1.weight', 'visual_encoder_m.blocks.8.norm1.bias', 'visual_encoder_m.blocks.8.attn.qkv.weight', 'visual_encoder_m.blocks.8.attn.qkv.bias', 'visual_encoder_m.blocks.8.attn.proj.weight', 'visual_encoder_m.blocks.8.attn.proj.bias', 'visual_encoder_m.blocks.8.norm2.weight', 'visual_encoder_m.blocks.8.norm2.bias', 'visual_encoder_m.blocks.8.mlp.fc1.weight', 'visual_encoder_m.blocks.8.mlp.fc1.bias', 'visual_encoder_m.blocks.8.mlp.fc2.weight', 'visual_encoder_m.blocks.8.mlp.fc2.bias', 'visual_encoder_m.blocks.9.norm1.weight', 'visual_encoder_m.blocks.9.norm1.bias', 'visual_encoder_m.blocks.9.attn.qkv.weight', 'visual_encoder_m.blocks.9.attn.qkv.bias', 'visual_encoder_m.blocks.9.attn.proj.weight', 'visual_encoder_m.blocks.9.attn.proj.bias', 'visual_encoder_m.blocks.9.norm2.weight', 'visual_encoder_m.blocks.9.norm2.bias', 'visual_encoder_m.blocks.9.mlp.fc1.weight', 'visual_encoder_m.blocks.9.mlp.fc1.bias', 'visual_encoder_m.blocks.9.mlp.fc2.weight', 'visual_encoder_m.blocks.9.mlp.fc2.bias', 'visual_encoder_m.blocks.10.norm1.weight', 'visual_encoder_m.blocks.10.norm1.bias', 'visual_encoder_m.blocks.10.attn.qkv.weight', 'visual_encoder_m.blocks.10.attn.qkv.bias', 'visual_encoder_m.blocks.10.attn.proj.weight', 'visual_encoder_m.blocks.10.attn.proj.bias', 'visual_encoder_m.blocks.10.norm2.weight', 'visual_encoder_m.blocks.10.norm2.bias', 'visual_encoder_m.blocks.10.mlp.fc1.weight', 'visual_encoder_m.blocks.10.mlp.fc1.bias', 'visual_encoder_m.blocks.10.mlp.fc2.weight', 'visual_encoder_m.blocks.10.mlp.fc2.bias', 'visual_encoder_m.blocks.11.norm1.weight', 'visual_encoder_m.blocks.11.norm1.bias', 'visual_encoder_m.blocks.11.attn.qkv.weight', 'visual_encoder_m.blocks.11.attn.qkv.bias', 'visual_encoder_m.blocks.11.attn.proj.weight', 'visual_encoder_m.blocks.11.attn.proj.bias', 'visual_encoder_m.blocks.11.norm2.weight', 'visual_encoder_m.blocks.11.norm2.bias', 'visual_encoder_m.blocks.11.mlp.fc1.weight', 'visual_encoder_m.blocks.11.mlp.fc1.bias', 'visual_encoder_m.blocks.11.mlp.fc2.weight', 'visual_encoder_m.blocks.11.mlp.fc2.bias', 'visual_encoder_m.norm.weight', 'visual_encoder_m.norm.bias', 'vision_proj_m.weight', 'vision_proj_m.bias', 'text_proj_m.weight', 'text_proj_m.bias', 'text_encoder_m.embeddings.position_ids', 'text_decoder_m.bert.embeddings.position_ids', 'text_encoder_m.embeddings.word_embeddings.weight', 'text_decoder_m.bert.embeddings.word_embeddings.weight', 'text_encoder_m.embeddings.position_embeddings.weight', 'text_decoder_m.bert.embeddings.position_embeddings.weight', 'text_encoder_m.embeddings.token_type_embeddings.weight', 'text_decoder_m.bert.embeddings.token_type_embeddings.weight', 'text_encoder_m.embeddings.LayerNorm.weight', 'text_decoder_m.bert.embeddings.LayerNorm.weight', 'text_encoder_m.embeddings.LayerNorm.bias', 'text_decoder_m.bert.embeddings.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.attention.self.query.weight', 'text_encoder_m.encoder.layer.0.attention.self.query.bias', 'text_encoder_m.encoder.layer.0.attention.self.key.weight', 'text_encoder_m.encoder.layer.0.attention.self.key.bias', 'text_encoder_m.encoder.layer.0.attention.self.value.weight', 'text_encoder_m.encoder.layer.0.attention.self.value.bias', 'text_encoder_m.encoder.layer.0.attention.output.dense.weight', 'text_encoder_m.encoder.layer.0.attention.output.dense.bias', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.intermediate.dense.weight', 'text_encoder_m.encoder.layer.0.intermediate.dense.bias', 'text_encoder_m.encoder.layer.0.output.dense.weight', 'text_encoder_m.encoder.layer.0.output.dense.bias', 'text_encoder_m.encoder.layer.0.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.attention.self.query.weight', 'text_encoder_m.encoder.layer.1.attention.self.query.bias', 'text_encoder_m.encoder.layer.1.attention.self.key.weight', 'text_encoder_m.encoder.layer.1.attention.self.key.bias', 'text_encoder_m.encoder.layer.1.attention.self.value.weight', 'text_encoder_m.encoder.layer.1.attention.self.value.bias', 'text_encoder_m.encoder.layer.1.attention.output.dense.weight', 'text_encoder_m.encoder.layer.1.attention.output.dense.bias', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.intermediate.dense.weight', 'text_encoder_m.encoder.layer.1.intermediate.dense.bias', 'text_encoder_m.encoder.layer.1.output.dense.weight', 'text_encoder_m.encoder.layer.1.output.dense.bias', 'text_encoder_m.encoder.layer.1.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.attention.self.query.weight', 'text_encoder_m.encoder.layer.2.attention.self.query.bias', 'text_encoder_m.encoder.layer.2.attention.self.key.weight', 'text_encoder_m.encoder.layer.2.attention.self.key.bias', 'text_encoder_m.encoder.layer.2.attention.self.value.weight', 'text_encoder_m.encoder.layer.2.attention.self.value.bias', 'text_encoder_m.encoder.layer.2.attention.output.dense.weight', 'text_encoder_m.encoder.layer.2.attention.output.dense.bias', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.intermediate.dense.weight', 'text_encoder_m.encoder.layer.2.intermediate.dense.bias', 'text_encoder_m.encoder.layer.2.output.dense.weight', 'text_encoder_m.encoder.layer.2.output.dense.bias', 'text_encoder_m.encoder.layer.2.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.query.weight', 'text_encoder_m.encoder.layer.6.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.query.bias', 'text_encoder_m.encoder.layer.6.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.key.weight', 'text_encoder_m.encoder.layer.6.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.key.bias', 'text_encoder_m.encoder.layer.6.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.value.weight', 'text_encoder_m.encoder.layer.6.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.value.bias', 'text_encoder_m.encoder.layer.6.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.attention.output.dense.weight', 'text_encoder_m.encoder.layer.6.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.attention.output.dense.bias', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.0.intermediate.dense.weight', 'text_encoder_m.encoder.layer.6.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.0.intermediate.dense.bias', 'text_encoder_m.encoder.layer.6.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.output.dense.weight', 'text_encoder_m.encoder.layer.6.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.output.dense.bias', 'text_encoder_m.encoder.layer.6.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.query.weight', 'text_encoder_m.encoder.layer.7.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.query.bias', 'text_encoder_m.encoder.layer.7.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.key.weight', 'text_encoder_m.encoder.layer.7.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.key.bias', 'text_encoder_m.encoder.layer.7.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.value.weight', 'text_encoder_m.encoder.layer.7.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.value.bias', 'text_encoder_m.encoder.layer.7.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.attention.output.dense.weight', 'text_encoder_m.encoder.layer.7.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.attention.output.dense.bias', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.1.intermediate.dense.weight', 'text_encoder_m.encoder.layer.7.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.1.intermediate.dense.bias', 'text_encoder_m.encoder.layer.7.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.output.dense.weight', 'text_encoder_m.encoder.layer.7.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.output.dense.bias', 'text_encoder_m.encoder.layer.7.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.query.weight', 'text_encoder_m.encoder.layer.8.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.query.bias', 'text_encoder_m.encoder.layer.8.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.key.weight', 'text_encoder_m.encoder.layer.8.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.key.bias', 'text_encoder_m.encoder.layer.8.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.value.weight', 'text_encoder_m.encoder.layer.8.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.value.bias', 'text_encoder_m.encoder.layer.8.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.attention.output.dense.weight', 'text_encoder_m.encoder.layer.8.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.attention.output.dense.bias', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.2.intermediate.dense.weight', 'text_encoder_m.encoder.layer.8.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.2.intermediate.dense.bias', 'text_encoder_m.encoder.layer.8.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.output.dense.weight', 'text_encoder_m.encoder.layer.8.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.output.dense.bias', 'text_encoder_m.encoder.layer.8.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.9.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.9.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.9.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.9.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.9.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.9.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.9.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.9.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.9.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.9.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.9.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.10.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.10.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.10.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.10.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.10.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.10.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.10.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.10.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.10.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.10.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.10.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.11.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.11.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.11.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.11.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.11.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.11.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.11.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.11.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.11.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.11.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.11.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.output.LayerNorm.bias', 'text_decoder_m.cls.predictions.bias', 'text_decoder_m.cls.predictions.transform.dense.weight', 'text_decoder_m.cls.predictions.transform.dense.bias', 'text_decoder_m.cls.predictions.transform.LayerNorm.weight', 'text_decoder_m.cls.predictions.transform.LayerNorm.bias', 'text_decoder_m.cls.predictions.decoder.weight', 'text_decoder_m.cls.predictions.decoder.bias', 'fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [    0/27734]  eta: 1 day, 1:24:42  lr: 0.000010  loss: 43.5573  time: 3.2986  data: 1.3822  max mem: 11191
Train Epoch: [0]  [   50/27734]  eta: 4:47:57  lr: 0.000010  loss: 9.7828  time: 0.5729  data: 0.0002  max mem: 15280
Train Epoch: [0]  [  100/27734]  eta: 4:35:14  lr: 0.000010  loss: 7.3025  time: 0.5698  data: 0.0002  max mem: 15289
Train Epoch: [0]  [  150/27734]  eta: 4:30:45  lr: 0.000013  loss: 9.1436  time: 0.5657  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  200/27734]  eta: 4:28:07  lr: 0.000013  loss: 7.1110  time: 0.5721  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  250/27734]  eta: 4:26:17  lr: 0.000015  loss: 4.5035  time: 0.5722  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  300/27734]  eta: 4:25:05  lr: 0.000015  loss: 3.8793  time: 0.5723  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  350/27734]  eta: 4:24:06  lr: 0.000018  loss: 6.8775  time: 0.5700  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  400/27734]  eta: 4:23:18  lr: 0.000018  loss: 8.4964  time: 0.5707  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  450/27734]  eta: 4:22:26  lr: 0.000020  loss: 8.2792  time: 0.5690  data: 0.0002  max mem: 15328
Train Epoch: [0]  [  500/27734]  eta: 4:22:17  lr: 0.000020  loss: 7.9294  time: 0.5681  data: 0.0002  max mem: 15340
Train Epoch: [0]  [  550/27734]  eta: 4:21:18  lr: 0.000020  loss: 5.5652  time: 0.5685  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  600/27734]  eta: 4:20:41  lr: 0.000020  loss: 7.7175  time: 0.5762  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  650/27734]  eta: 4:19:57  lr: 0.000020  loss: 5.3571  time: 0.5750  data: 0.0001  max mem: 15373
Train Epoch: [0]  [  700/27734]  eta: 4:19:12  lr: 0.000020  loss: 4.4179  time: 0.5723  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  750/27734]  eta: 4:18:40  lr: 0.000020  loss: 5.2067  time: 0.5730  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  800/27734]  eta: 4:18:01  lr: 0.000020  loss: 3.3182  time: 0.5748  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  850/27734]  eta: 4:17:19  lr: 0.000020  loss: 2.8159  time: 0.5751  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  900/27734]  eta: 4:16:43  lr: 0.000020  loss: 3.9149  time: 0.5673  data: 0.0002  max mem: 15373
Train Epoch: [0]  [  950/27734]  eta: 4:15:58  lr: 0.000020  loss: 6.1976  time: 0.5575  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1000/27734]  eta: 4:15:22  lr: 0.000020  loss: 2.1277  time: 0.5686  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1050/27734]  eta: 4:14:46  lr: 0.000020  loss: 4.5330  time: 0.5668  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1100/27734]  eta: 4:14:15  lr: 0.000020  loss: 6.8021  time: 0.5715  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1150/27734]  eta: 4:13:46  lr: 0.000020  loss: 3.0087  time: 0.5738  data: 0.0002  max mem: 15373
Train Epoch: [0]  [ 1200/27734]  eta: 4:13:09  lr: 0.000020  loss: 3.1331  time: 0.5638  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1250/27734]  eta: 4:12:43  lr: 0.000020  loss: 4.2669  time: 0.5755  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1300/27734]  eta: 4:12:11  lr: 0.000020  loss: 6.5814  time: 0.5751  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1350/27734]  eta: 4:11:43  lr: 0.000020  loss: 3.4978  time: 0.5716  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1400/27734]  eta: 4:11:11  lr: 0.000020  loss: 5.2864  time: 0.5676  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 1450/27734]  eta: 4:10:40  lr: 0.000020  loss: 2.6276  time: 0.5677  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1500/27734]  eta: 4:10:12  lr: 0.000020  loss: 4.0869  time: 0.5873  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 1550/27734]  eta: 4:09:48  lr: 0.000020  loss: 3.3162  time: 0.5788  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 1600/27734]  eta: 4:09:22  lr: 0.000020  loss: 4.6231  time: 0.5754  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 1650/27734]  eta: 4:08:57  lr: 0.000020  loss: 2.7762  time: 0.5804  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1700/27734]  eta: 4:08:29  lr: 0.000020  loss: 7.0196  time: 0.5712  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1750/27734]  eta: 4:08:00  lr: 0.000020  loss: 4.9254  time: 0.5735  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1800/27734]  eta: 4:07:32  lr: 0.000020  loss: 4.1256  time: 0.5734  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1850/27734]  eta: 4:07:06  lr: 0.000020  loss: 4.3065  time: 0.5780  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 1900/27734]  eta: 4:06:35  lr: 0.000020  loss: 3.7191  time: 0.5701  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 1950/27734]  eta: 4:06:08  lr: 0.000020  loss: 6.5750  time: 0.5808  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2000/27734]  eta: 4:05:41  lr: 0.000020  loss: 2.1047  time: 0.5759  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 2050/27734]  eta: 4:05:15  lr: 0.000020  loss: 4.5905  time: 0.5768  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2100/27734]  eta: 4:04:51  lr: 0.000020  loss: 3.8362  time: 0.5737  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 2150/27734]  eta: 4:04:24  lr: 0.000020  loss: 4.1142  time: 0.5797  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 2200/27734]  eta: 4:03:56  lr: 0.000020  loss: 3.4804  time: 0.5765  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2250/27734]  eta: 4:03:26  lr: 0.000020  loss: 3.5596  time: 0.5714  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2300/27734]  eta: 4:02:54  lr: 0.000020  loss: 3.0655  time: 0.5729  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2350/27734]  eta: 4:02:27  lr: 0.000020  loss: 2.9638  time: 0.5725  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2400/27734]  eta: 4:01:58  lr: 0.000020  loss: 2.5350  time: 0.5720  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2450/27734]  eta: 4:01:29  lr: 0.000020  loss: 3.2611  time: 0.5648  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2500/27734]  eta: 4:00:59  lr: 0.000020  loss: 3.7723  time: 0.5673  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2550/27734]  eta: 4:00:30  lr: 0.000020  loss: 2.5269  time: 0.5695  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2600/27734]  eta: 4:00:01  lr: 0.000020  loss: 5.6481  time: 0.5697  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2650/27734]  eta: 3:59:32  lr: 0.000020  loss: 2.2790  time: 0.5741  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2700/27734]  eta: 3:59:02  lr: 0.000020  loss: 3.1365  time: 0.5711  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2750/27734]  eta: 3:58:31  lr: 0.000020  loss: 3.7377  time: 0.5650  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2800/27734]  eta: 3:57:59  lr: 0.000020  loss: 2.7896  time: 0.5690  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2850/27734]  eta: 3:57:30  lr: 0.000020  loss: 2.4010  time: 0.5727  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2900/27734]  eta: 3:57:00  lr: 0.000020  loss: 4.5127  time: 0.5783  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 2950/27734]  eta: 3:56:31  lr: 0.000020  loss: 1.8665  time: 0.5686  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3000/27734]  eta: 3:56:02  lr: 0.000020  loss: 2.7895  time: 0.5681  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3050/27734]  eta: 3:55:32  lr: 0.000020  loss: 2.1719  time: 0.5729  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3100/27734]  eta: 3:55:03  lr: 0.000020  loss: 4.1922  time: 0.5751  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 3150/27734]  eta: 3:54:33  lr: 0.000020  loss: 3.0364  time: 0.5734  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3200/27734]  eta: 3:54:05  lr: 0.000020  loss: 2.1327  time: 0.5746  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3250/27734]  eta: 3:53:38  lr: 0.000020  loss: 3.8064  time: 0.5733  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 3300/27734]  eta: 3:53:10  lr: 0.000020  loss: 4.3779  time: 0.5762  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3350/27734]  eta: 3:52:40  lr: 0.000020  loss: 4.1487  time: 0.5757  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3400/27734]  eta: 3:52:10  lr: 0.000020  loss: 1.8541  time: 0.5696  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3450/27734]  eta: 3:51:41  lr: 0.000020  loss: 4.3151  time: 0.5701  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3500/27734]  eta: 3:51:11  lr: 0.000020  loss: 2.6725  time: 0.5663  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3550/27734]  eta: 3:50:41  lr: 0.000020  loss: 5.5167  time: 0.5679  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3600/27734]  eta: 3:50:13  lr: 0.000020  loss: 3.9290  time: 0.5686  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3650/27734]  eta: 3:49:45  lr: 0.000020  loss: 3.9154  time: 0.5808  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 3700/27734]  eta: 3:49:15  lr: 0.000020  loss: 2.7371  time: 0.5702  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3750/27734]  eta: 3:48:44  lr: 0.000020  loss: 3.2920  time: 0.5784  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3800/27734]  eta: 3:48:18  lr: 0.000020  loss: 5.8020  time: 0.5653  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3850/27734]  eta: 3:47:48  lr: 0.000020  loss: 3.6108  time: 0.5725  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3900/27734]  eta: 3:47:17  lr: 0.000020  loss: 3.3972  time: 0.5597  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 3950/27734]  eta: 3:46:48  lr: 0.000020  loss: 2.2983  time: 0.5724  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4000/27734]  eta: 3:46:19  lr: 0.000020  loss: 3.8884  time: 0.5614  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4050/27734]  eta: 3:45:48  lr: 0.000020  loss: 2.7812  time: 0.5602  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4100/27734]  eta: 3:45:19  lr: 0.000020  loss: 2.9609  time: 0.5690  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4150/27734]  eta: 3:44:49  lr: 0.000020  loss: 4.5506  time: 0.5648  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4200/27734]  eta: 3:44:21  lr: 0.000020  loss: 5.5064  time: 0.5747  data: 0.0001  max mem: 15548
Train Epoch: [0]  [ 4250/27734]  eta: 3:43:53  lr: 0.000020  loss: 3.9729  time: 0.5655  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4300/27734]  eta: 3:43:23  lr: 0.000020  loss: 2.7370  time: 0.5622  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4350/27734]  eta: 3:42:54  lr: 0.000020  loss: 2.2281  time: 0.5727  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4400/27734]  eta: 3:42:25  lr: 0.000020  loss: 3.1757  time: 0.5658  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4450/27734]  eta: 3:41:56  lr: 0.000020  loss: 5.1454  time: 0.5742  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4500/27734]  eta: 3:41:28  lr: 0.000020  loss: 2.9901  time: 0.5736  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4550/27734]  eta: 3:40:59  lr: 0.000020  loss: 4.0324  time: 0.5739  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4600/27734]  eta: 3:40:30  lr: 0.000020  loss: 3.2814  time: 0.5716  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4650/27734]  eta: 3:40:01  lr: 0.000020  loss: 3.5618  time: 0.5752  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4700/27734]  eta: 3:39:33  lr: 0.000020  loss: 2.7978  time: 0.5707  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4750/27734]  eta: 3:39:03  lr: 0.000020  loss: 4.1822  time: 0.5711  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4800/27734]  eta: 3:38:34  lr: 0.000020  loss: 3.1656  time: 0.5657  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4850/27734]  eta: 3:38:05  lr: 0.000020  loss: 2.7942  time: 0.5673  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4900/27734]  eta: 3:37:36  lr: 0.000020  loss: 2.6486  time: 0.5674  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 4950/27734]  eta: 3:37:08  lr: 0.000020  loss: 1.5633  time: 0.5789  data: 0.0002  max mem: 15548
Train Epoch: [0]  [ 5000/27734]  eta: 3:36:43  lr: 0.000020  loss: 4.0834  time: 0.5873  data: 0.0002  max mem: 15548