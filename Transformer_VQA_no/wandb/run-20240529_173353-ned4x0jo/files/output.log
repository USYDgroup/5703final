Not using distributed mode
Creating vqa datasets
Creating model
reshape position embedding from 256 to 576
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/ALBEF.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['temp', 'image_queue', 'text_queue', 'queue_ptr', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'visual_encoder_m.cls_token', 'visual_encoder_m.pos_embed', 'visual_encoder_m.patch_embed.proj.weight', 'visual_encoder_m.patch_embed.proj.bias', 'visual_encoder_m.blocks.0.norm1.weight', 'visual_encoder_m.blocks.0.norm1.bias', 'visual_encoder_m.blocks.0.attn.qkv.weight', 'visual_encoder_m.blocks.0.attn.qkv.bias', 'visual_encoder_m.blocks.0.attn.proj.weight', 'visual_encoder_m.blocks.0.attn.proj.bias', 'visual_encoder_m.blocks.0.norm2.weight', 'visual_encoder_m.blocks.0.norm2.bias', 'visual_encoder_m.blocks.0.mlp.fc1.weight', 'visual_encoder_m.blocks.0.mlp.fc1.bias', 'visual_encoder_m.blocks.0.mlp.fc2.weight', 'visual_encoder_m.blocks.0.mlp.fc2.bias', 'visual_encoder_m.blocks.1.norm1.weight', 'visual_encoder_m.blocks.1.norm1.bias', 'visual_encoder_m.blocks.1.attn.qkv.weight', 'visual_encoder_m.blocks.1.attn.qkv.bias', 'visual_encoder_m.blocks.1.attn.proj.weight', 'visual_encoder_m.blocks.1.attn.proj.bias', 'visual_encoder_m.blocks.1.norm2.weight', 'visual_encoder_m.blocks.1.norm2.bias', 'visual_encoder_m.blocks.1.mlp.fc1.weight', 'visual_encoder_m.blocks.1.mlp.fc1.bias', 'visual_encoder_m.blocks.1.mlp.fc2.weight', 'visual_encoder_m.blocks.1.mlp.fc2.bias', 'visual_encoder_m.blocks.2.norm1.weight', 'visual_encoder_m.blocks.2.norm1.bias', 'visual_encoder_m.blocks.2.attn.qkv.weight', 'visual_encoder_m.blocks.2.attn.qkv.bias', 'visual_encoder_m.blocks.2.attn.proj.weight', 'visual_encoder_m.blocks.2.attn.proj.bias', 'visual_encoder_m.blocks.2.norm2.weight', 'visual_encoder_m.blocks.2.norm2.bias', 'visual_encoder_m.blocks.2.mlp.fc1.weight', 'visual_encoder_m.blocks.2.mlp.fc1.bias', 'visual_encoder_m.blocks.2.mlp.fc2.weight', 'visual_encoder_m.blocks.2.mlp.fc2.bias', 'visual_encoder_m.blocks.3.norm1.weight', 'visual_encoder_m.blocks.3.norm1.bias', 'visual_encoder_m.blocks.3.attn.qkv.weight', 'visual_encoder_m.blocks.3.attn.qkv.bias', 'visual_encoder_m.blocks.3.attn.proj.weight', 'visual_encoder_m.blocks.3.attn.proj.bias', 'visual_encoder_m.blocks.3.norm2.weight', 'visual_encoder_m.blocks.3.norm2.bias', 'visual_encoder_m.blocks.3.mlp.fc1.weight', 'visual_encoder_m.blocks.3.mlp.fc1.bias', 'visual_encoder_m.blocks.3.mlp.fc2.weight', 'visual_encoder_m.blocks.3.mlp.fc2.bias', 'visual_encoder_m.blocks.4.norm1.weight', 'visual_encoder_m.blocks.4.norm1.bias', 'visual_encoder_m.blocks.4.attn.qkv.weight', 'visual_encoder_m.blocks.4.attn.qkv.bias', 'visual_encoder_m.blocks.4.attn.proj.weight', 'visual_encoder_m.blocks.4.attn.proj.bias', 'visual_encoder_m.blocks.4.norm2.weight', 'visual_encoder_m.blocks.4.norm2.bias', 'visual_encoder_m.blocks.4.mlp.fc1.weight', 'visual_encoder_m.blocks.4.mlp.fc1.bias', 'visual_encoder_m.blocks.4.mlp.fc2.weight', 'visual_encoder_m.blocks.4.mlp.fc2.bias', 'visual_encoder_m.blocks.5.norm1.weight', 'visual_encoder_m.blocks.5.norm1.bias', 'visual_encoder_m.blocks.5.attn.qkv.weight', 'visual_encoder_m.blocks.5.attn.qkv.bias', 'visual_encoder_m.blocks.5.attn.proj.weight', 'visual_encoder_m.blocks.5.attn.proj.bias', 'visual_encoder_m.blocks.5.norm2.weight', 'visual_encoder_m.blocks.5.norm2.bias', 'visual_encoder_m.blocks.5.mlp.fc1.weight', 'visual_encoder_m.blocks.5.mlp.fc1.bias', 'visual_encoder_m.blocks.5.mlp.fc2.weight', 'visual_encoder_m.blocks.5.mlp.fc2.bias', 'visual_encoder_m.blocks.6.norm1.weight', 'visual_encoder_m.blocks.6.norm1.bias', 'visual_encoder_m.blocks.6.attn.qkv.weight', 'visual_encoder_m.blocks.6.attn.qkv.bias', 'visual_encoder_m.blocks.6.attn.proj.weight', 'visual_encoder_m.blocks.6.attn.proj.bias', 'visual_encoder_m.blocks.6.norm2.weight', 'visual_encoder_m.blocks.6.norm2.bias', 'visual_encoder_m.blocks.6.mlp.fc1.weight', 'visual_encoder_m.blocks.6.mlp.fc1.bias', 'visual_encoder_m.blocks.6.mlp.fc2.weight', 'visual_encoder_m.blocks.6.mlp.fc2.bias', 'visual_encoder_m.blocks.7.norm1.weight', 'visual_encoder_m.blocks.7.norm1.bias', 'visual_encoder_m.blocks.7.attn.qkv.weight', 'visual_encoder_m.blocks.7.attn.qkv.bias', 'visual_encoder_m.blocks.7.attn.proj.weight', 'visual_encoder_m.blocks.7.attn.proj.bias', 'visual_encoder_m.blocks.7.norm2.weight', 'visual_encoder_m.blocks.7.norm2.bias', 'visual_encoder_m.blocks.7.mlp.fc1.weight', 'visual_encoder_m.blocks.7.mlp.fc1.bias', 'visual_encoder_m.blocks.7.mlp.fc2.weight', 'visual_encoder_m.blocks.7.mlp.fc2.bias', 'visual_encoder_m.blocks.8.norm1.weight', 'visual_encoder_m.blocks.8.norm1.bias', 'visual_encoder_m.blocks.8.attn.qkv.weight', 'visual_encoder_m.blocks.8.attn.qkv.bias', 'visual_encoder_m.blocks.8.attn.proj.weight', 'visual_encoder_m.blocks.8.attn.proj.bias', 'visual_encoder_m.blocks.8.norm2.weight', 'visual_encoder_m.blocks.8.norm2.bias', 'visual_encoder_m.blocks.8.mlp.fc1.weight', 'visual_encoder_m.blocks.8.mlp.fc1.bias', 'visual_encoder_m.blocks.8.mlp.fc2.weight', 'visual_encoder_m.blocks.8.mlp.fc2.bias', 'visual_encoder_m.blocks.9.norm1.weight', 'visual_encoder_m.blocks.9.norm1.bias', 'visual_encoder_m.blocks.9.attn.qkv.weight', 'visual_encoder_m.blocks.9.attn.qkv.bias', 'visual_encoder_m.blocks.9.attn.proj.weight', 'visual_encoder_m.blocks.9.attn.proj.bias', 'visual_encoder_m.blocks.9.norm2.weight', 'visual_encoder_m.blocks.9.norm2.bias', 'visual_encoder_m.blocks.9.mlp.fc1.weight', 'visual_encoder_m.blocks.9.mlp.fc1.bias', 'visual_encoder_m.blocks.9.mlp.fc2.weight', 'visual_encoder_m.blocks.9.mlp.fc2.bias', 'visual_encoder_m.blocks.10.norm1.weight', 'visual_encoder_m.blocks.10.norm1.bias', 'visual_encoder_m.blocks.10.attn.qkv.weight', 'visual_encoder_m.blocks.10.attn.qkv.bias', 'visual_encoder_m.blocks.10.attn.proj.weight', 'visual_encoder_m.blocks.10.attn.proj.bias', 'visual_encoder_m.blocks.10.norm2.weight', 'visual_encoder_m.blocks.10.norm2.bias', 'visual_encoder_m.blocks.10.mlp.fc1.weight', 'visual_encoder_m.blocks.10.mlp.fc1.bias', 'visual_encoder_m.blocks.10.mlp.fc2.weight', 'visual_encoder_m.blocks.10.mlp.fc2.bias', 'visual_encoder_m.blocks.11.norm1.weight', 'visual_encoder_m.blocks.11.norm1.bias', 'visual_encoder_m.blocks.11.attn.qkv.weight', 'visual_encoder_m.blocks.11.attn.qkv.bias', 'visual_encoder_m.blocks.11.attn.proj.weight', 'visual_encoder_m.blocks.11.attn.proj.bias', 'visual_encoder_m.blocks.11.norm2.weight', 'visual_encoder_m.blocks.11.norm2.bias', 'visual_encoder_m.blocks.11.mlp.fc1.weight', 'visual_encoder_m.blocks.11.mlp.fc1.bias', 'visual_encoder_m.blocks.11.mlp.fc2.weight', 'visual_encoder_m.blocks.11.mlp.fc2.bias', 'visual_encoder_m.norm.weight', 'visual_encoder_m.norm.bias', 'vision_proj_m.weight', 'vision_proj_m.bias', 'text_proj_m.weight', 'text_proj_m.bias', 'text_encoder_m.embeddings.position_ids', 'text_decoder_m.bert.embeddings.position_ids', 'text_encoder_m.embeddings.word_embeddings.weight', 'text_decoder_m.bert.embeddings.word_embeddings.weight', 'text_encoder_m.embeddings.position_embeddings.weight', 'text_decoder_m.bert.embeddings.position_embeddings.weight', 'text_encoder_m.embeddings.token_type_embeddings.weight', 'text_decoder_m.bert.embeddings.token_type_embeddings.weight', 'text_encoder_m.embeddings.LayerNorm.weight', 'text_decoder_m.bert.embeddings.LayerNorm.weight', 'text_encoder_m.embeddings.LayerNorm.bias', 'text_decoder_m.bert.embeddings.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.attention.self.query.weight', 'text_encoder_m.encoder.layer.0.attention.self.query.bias', 'text_encoder_m.encoder.layer.0.attention.self.key.weight', 'text_encoder_m.encoder.layer.0.attention.self.key.bias', 'text_encoder_m.encoder.layer.0.attention.self.value.weight', 'text_encoder_m.encoder.layer.0.attention.self.value.bias', 'text_encoder_m.encoder.layer.0.attention.output.dense.weight', 'text_encoder_m.encoder.layer.0.attention.output.dense.bias', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.0.intermediate.dense.weight', 'text_encoder_m.encoder.layer.0.intermediate.dense.bias', 'text_encoder_m.encoder.layer.0.output.dense.weight', 'text_encoder_m.encoder.layer.0.output.dense.bias', 'text_encoder_m.encoder.layer.0.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.0.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.attention.self.query.weight', 'text_encoder_m.encoder.layer.1.attention.self.query.bias', 'text_encoder_m.encoder.layer.1.attention.self.key.weight', 'text_encoder_m.encoder.layer.1.attention.self.key.bias', 'text_encoder_m.encoder.layer.1.attention.self.value.weight', 'text_encoder_m.encoder.layer.1.attention.self.value.bias', 'text_encoder_m.encoder.layer.1.attention.output.dense.weight', 'text_encoder_m.encoder.layer.1.attention.output.dense.bias', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.1.intermediate.dense.weight', 'text_encoder_m.encoder.layer.1.intermediate.dense.bias', 'text_encoder_m.encoder.layer.1.output.dense.weight', 'text_encoder_m.encoder.layer.1.output.dense.bias', 'text_encoder_m.encoder.layer.1.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.1.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.attention.self.query.weight', 'text_encoder_m.encoder.layer.2.attention.self.query.bias', 'text_encoder_m.encoder.layer.2.attention.self.key.weight', 'text_encoder_m.encoder.layer.2.attention.self.key.bias', 'text_encoder_m.encoder.layer.2.attention.self.value.weight', 'text_encoder_m.encoder.layer.2.attention.self.value.bias', 'text_encoder_m.encoder.layer.2.attention.output.dense.weight', 'text_encoder_m.encoder.layer.2.attention.output.dense.bias', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.2.intermediate.dense.weight', 'text_encoder_m.encoder.layer.2.intermediate.dense.bias', 'text_encoder_m.encoder.layer.2.output.dense.weight', 'text_encoder_m.encoder.layer.2.output.dense.bias', 'text_encoder_m.encoder.layer.2.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.2.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.query.weight', 'text_encoder_m.encoder.layer.6.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.query.bias', 'text_encoder_m.encoder.layer.6.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.key.weight', 'text_encoder_m.encoder.layer.6.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.key.bias', 'text_encoder_m.encoder.layer.6.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.0.attention.self.value.weight', 'text_encoder_m.encoder.layer.6.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.0.attention.self.value.bias', 'text_encoder_m.encoder.layer.6.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.attention.output.dense.weight', 'text_encoder_m.encoder.layer.6.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.attention.output.dense.bias', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.0.intermediate.dense.weight', 'text_encoder_m.encoder.layer.6.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.0.intermediate.dense.bias', 'text_encoder_m.encoder.layer.6.output.dense.weight', 'text_decoder_m.bert.encoder.layer.0.output.dense.weight', 'text_encoder_m.encoder.layer.6.output.dense.bias', 'text_decoder_m.bert.encoder.layer.0.output.dense.bias', 'text_encoder_m.encoder.layer.6.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.0.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.0.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.query.weight', 'text_encoder_m.encoder.layer.7.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.query.bias', 'text_encoder_m.encoder.layer.7.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.key.weight', 'text_encoder_m.encoder.layer.7.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.key.bias', 'text_encoder_m.encoder.layer.7.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.1.attention.self.value.weight', 'text_encoder_m.encoder.layer.7.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.1.attention.self.value.bias', 'text_encoder_m.encoder.layer.7.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.attention.output.dense.weight', 'text_encoder_m.encoder.layer.7.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.attention.output.dense.bias', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.1.intermediate.dense.weight', 'text_encoder_m.encoder.layer.7.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.1.intermediate.dense.bias', 'text_encoder_m.encoder.layer.7.output.dense.weight', 'text_decoder_m.bert.encoder.layer.1.output.dense.weight', 'text_encoder_m.encoder.layer.7.output.dense.bias', 'text_decoder_m.bert.encoder.layer.1.output.dense.bias', 'text_encoder_m.encoder.layer.7.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.1.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.1.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.query.weight', 'text_encoder_m.encoder.layer.8.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.query.bias', 'text_encoder_m.encoder.layer.8.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.key.weight', 'text_encoder_m.encoder.layer.8.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.key.bias', 'text_encoder_m.encoder.layer.8.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.2.attention.self.value.weight', 'text_encoder_m.encoder.layer.8.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.2.attention.self.value.bias', 'text_encoder_m.encoder.layer.8.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.attention.output.dense.weight', 'text_encoder_m.encoder.layer.8.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.attention.output.dense.bias', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.2.intermediate.dense.weight', 'text_encoder_m.encoder.layer.8.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.2.intermediate.dense.bias', 'text_encoder_m.encoder.layer.8.output.dense.weight', 'text_decoder_m.bert.encoder.layer.2.output.dense.weight', 'text_encoder_m.encoder.layer.8.output.dense.bias', 'text_decoder_m.bert.encoder.layer.2.output.dense.bias', 'text_encoder_m.encoder.layer.8.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.2.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.2.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.9.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.9.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.9.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.9.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.9.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.9.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.9.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.9.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.9.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.9.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.9.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.10.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.10.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.10.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.10.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.10.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.10.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.10.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.10.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.10.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.10.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.10.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.11.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.11.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.11.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.11.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.11.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.11.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.11.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.11.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.11.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.11.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.11.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.output.LayerNorm.bias', 'text_decoder_m.cls.predictions.bias', 'text_decoder_m.cls.predictions.transform.dense.weight', 'text_decoder_m.cls.predictions.transform.dense.bias', 'text_decoder_m.cls.predictions.transform.LayerNorm.weight', 'text_decoder_m.cls.predictions.transform.LayerNorm.bias', 'text_decoder_m.cls.predictions.decoder.weight', 'text_decoder_m.cls.predictions.decoder.bias', 'fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [    0/27734]  eta: 1 day, 4:26:41  lr: 0.000010  loss: 43.5573  time: 3.6923  data: 1.5505  max mem: 11191
Train Epoch: [0]  [   50/27734]  eta: 4:50:47  lr: 0.000010  loss: 9.7602  time: 0.5657  data: 0.0002  max mem: 15289
Train Epoch: [0]  [  100/27734]  eta: 4:36:12  lr: 0.000010  loss: 7.3972  time: 0.5678  data: 0.0001  max mem: 15289
Train Epoch: [0]  [  150/27734]  eta: 4:31:56  lr: 0.000013  loss: 9.3705  time: 0.5821  data: 0.0002  max mem: 15327
Train Epoch: [0]  [  200/27734]  eta: 4:29:14  lr: 0.000013  loss: 7.1646  time: 0.5685  data: 0.0002  max mem: 15327
Train Epoch: [0]  [  250/27734]  eta: 4:28:29  lr: 0.000015  loss: 4.5536  time: 0.6012  data: 0.0005  max mem: 15327
Train Epoch: [0]  [  300/27734]  eta: 4:27:42  lr: 0.000015  loss: 3.8927  time: 0.6022  data: 0.0002  max mem: 15327
Train Epoch: [0]  [  350/27734]  eta: 4:26:23  lr: 0.000018  loss: 7.0901  time: 0.5749  data: 0.0002  max mem: 15327
Train Epoch: [0]  [  400/27734]  eta: 4:25:44  lr: 0.000018  loss: 8.6424  time: 0.5695  data: 0.0002  max mem: 15327
Train Epoch: [0]  [  450/27734]  eta: 4:25:22  lr: 0.000020  loss: 8.2012  time: 0.6001  data: 0.0002  max mem: 15327
Train Epoch: [0]  [  500/27734]  eta: 4:24:13  lr: 0.000020  loss: 7.8225  time: 0.5660  data: 0.0002  max mem: 15337
Train Epoch: [0]  [  550/27734]  eta: 4:23:38  lr: 0.000020  loss: 5.6366  time: 0.5823  data: 0.0002  max mem: 15371
Train Epoch: [0]  [  600/27734]  eta: 4:23:26  lr: 0.000020  loss: 7.8031  time: 0.5873  data: 0.0002  max mem: 15371
Train Epoch: [0]  [  650/27734]  eta: 4:22:41  lr: 0.000020  loss: 5.4509  time: 0.5783  data: 0.0001  max mem: 15371
Train Epoch: [0]  [  700/27734]  eta: 4:21:49  lr: 0.000020  loss: 4.4168  time: 0.5693  data: 0.0002  max mem: 15371
Train Epoch: [0]  [  750/27734]  eta: 4:20:44  lr: 0.000020  loss: 5.2308  time: 0.5552  data: 0.0002  max mem: 15371
Train Epoch: [0]  [  800/27734]  eta: 4:20:18  lr: 0.000020  loss: 3.2688  time: 0.5911  data: 0.0001  max mem: 15371
Train Epoch: [0]  [  850/27734]  eta: 4:19:35  lr: 0.000020  loss: 2.7744  time: 0.5731  data: 0.0002  max mem: 15371
Train Epoch: [0]  [  900/27734]  eta: 4:18:55  lr: 0.000020  loss: 3.9193  time: 0.5699  data: 0.0002  max mem: 15371
Train Epoch: [0]  [  950/27734]  eta: 4:18:15  lr: 0.000020  loss: 5.9192  time: 0.5722  data: 0.0002  max mem: 15371
Train Epoch: [0]  [ 1000/27734]  eta: 4:17:38  lr: 0.000020  loss: 2.2421  time: 0.5659  data: 0.0002  max mem: 15371
Train Epoch: [0]  [ 1050/27734]  eta: 4:16:57  lr: 0.000020  loss: 4.4768  time: 0.5673  data: 0.0002  max mem: 15371
Train Epoch: [0]  [ 1100/27734]  eta: 4:16:26  lr: 0.000020  loss: 6.8392  time: 0.5724  data: 0.0002  max mem: 15371
Train Epoch: [0]  [ 1150/27734]  eta: 4:15:56  lr: 0.000020  loss: 3.1224  time: 0.5762  data: 0.0002  max mem: 15371
Train Epoch: [0]  [ 1200/27734]  eta: 4:15:22  lr: 0.000020  loss: 2.9973  time: 0.5653  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1250/27734]  eta: 4:14:48  lr: 0.000020  loss: 4.3316  time: 0.5728  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1300/27734]  eta: 4:14:19  lr: 0.000020  loss: 6.6928  time: 0.5678  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1350/27734]  eta: 4:13:46  lr: 0.000020  loss: 3.6331  time: 0.5697  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1400/27734]  eta: 4:13:11  lr: 0.000020  loss: 5.2176  time: 0.5734  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1450/27734]  eta: 4:12:33  lr: 0.000020  loss: 2.7633  time: 0.5637  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1500/27734]  eta: 4:12:05  lr: 0.000020  loss: 3.9342  time: 0.5832  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 1550/27734]  eta: 4:11:30  lr: 0.000020  loss: 3.3867  time: 0.5627  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1600/27734]  eta: 4:10:51  lr: 0.000020  loss: 4.6843  time: 0.5683  data: 0.0003  max mem: 15547
Train Epoch: [0]  [ 1650/27734]  eta: 4:10:15  lr: 0.000020  loss: 2.9068  time: 0.5667  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1700/27734]  eta: 4:09:46  lr: 0.000020  loss: 7.0590  time: 0.5787  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1750/27734]  eta: 4:09:20  lr: 0.000020  loss: 4.8641  time: 0.5780  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1800/27734]  eta: 4:08:50  lr: 0.000020  loss: 4.0414  time: 0.5732  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1850/27734]  eta: 4:08:17  lr: 0.000020  loss: 4.3597  time: 0.5700  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1900/27734]  eta: 4:07:47  lr: 0.000020  loss: 3.8522  time: 0.5712  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 1950/27734]  eta: 4:07:18  lr: 0.000020  loss: 6.4266  time: 0.5773  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2000/27734]  eta: 4:06:51  lr: 0.000020  loss: 2.0025  time: 0.5730  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2050/27734]  eta: 4:06:19  lr: 0.000020  loss: 4.5313  time: 0.5644  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2100/27734]  eta: 4:05:43  lr: 0.000020  loss: 3.7112  time: 0.5624  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2150/27734]  eta: 4:05:12  lr: 0.000020  loss: 3.9924  time: 0.5742  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2200/27734]  eta: 4:04:46  lr: 0.000020  loss: 3.6537  time: 0.5669  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 2250/27734]  eta: 4:04:13  lr: 0.000020  loss: 3.5010  time: 0.5687  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2300/27734]  eta: 4:03:46  lr: 0.000020  loss: 3.1522  time: 0.5824  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 2350/27734]  eta: 4:03:29  lr: 0.000020  loss: 3.0040  time: 0.5737  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2400/27734]  eta: 4:02:59  lr: 0.000020  loss: 2.5175  time: 0.5808  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2450/27734]  eta: 4:02:33  lr: 0.000020  loss: 3.2719  time: 0.5850  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2500/27734]  eta: 4:02:05  lr: 0.000020  loss: 3.7949  time: 0.5700  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2550/27734]  eta: 4:01:35  lr: 0.000020  loss: 2.5186  time: 0.5667  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2600/27734]  eta: 4:01:05  lr: 0.000020  loss: 5.6095  time: 0.5749  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2650/27734]  eta: 4:00:34  lr: 0.000020  loss: 2.4195  time: 0.5740  data: 0.0003  max mem: 15547
Train Epoch: [0]  [ 2700/27734]  eta: 4:00:05  lr: 0.000020  loss: 2.9277  time: 0.5724  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 2750/27734]  eta: 3:59:36  lr: 0.000020  loss: 3.7885  time: 0.5724  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2800/27734]  eta: 3:59:06  lr: 0.000020  loss: 2.7660  time: 0.5723  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2850/27734]  eta: 3:58:37  lr: 0.000020  loss: 2.3190  time: 0.5674  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2900/27734]  eta: 3:58:06  lr: 0.000020  loss: 4.5122  time: 0.5715  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 2950/27734]  eta: 3:57:38  lr: 0.000020  loss: 1.7937  time: 0.5778  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3000/27734]  eta: 3:57:09  lr: 0.000020  loss: 2.7299  time: 0.5761  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 3050/27734]  eta: 3:56:39  lr: 0.000020  loss: 2.2082  time: 0.5721  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3100/27734]  eta: 3:56:06  lr: 0.000020  loss: 4.1552  time: 0.5506  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3150/27734]  eta: 3:55:36  lr: 0.000020  loss: 3.0764  time: 0.5749  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3200/27734]  eta: 3:55:04  lr: 0.000020  loss: 2.1266  time: 0.5671  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3250/27734]  eta: 3:54:36  lr: 0.000020  loss: 3.8145  time: 0.5792  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3300/27734]  eta: 3:54:07  lr: 0.000020  loss: 4.4711  time: 0.5691  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3350/27734]  eta: 3:53:38  lr: 0.000020  loss: 4.1538  time: 0.5790  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 3400/27734]  eta: 3:53:09  lr: 0.000020  loss: 1.8876  time: 0.5742  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3450/27734]  eta: 3:52:41  lr: 0.000020  loss: 4.2035  time: 0.5713  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3500/27734]  eta: 3:52:11  lr: 0.000020  loss: 2.6776  time: 0.5694  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3550/27734]  eta: 3:51:43  lr: 0.000020  loss: 5.3164  time: 0.5744  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3600/27734]  eta: 3:51:13  lr: 0.000020  loss: 4.0449  time: 0.5685  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3650/27734]  eta: 3:50:43  lr: 0.000020  loss: 3.9272  time: 0.5757  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3700/27734]  eta: 3:50:12  lr: 0.000020  loss: 2.7482  time: 0.5671  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3750/27734]  eta: 3:49:41  lr: 0.000020  loss: 3.2449  time: 0.5745  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3800/27734]  eta: 3:49:11  lr: 0.000020  loss: 5.8626  time: 0.5736  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3850/27734]  eta: 3:48:45  lr: 0.000020  loss: 3.7330  time: 0.5773  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3900/27734]  eta: 3:48:17  lr: 0.000020  loss: 3.3616  time: 0.5800  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 3950/27734]  eta: 3:47:49  lr: 0.000020  loss: 2.3130  time: 0.5752  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4000/27734]  eta: 3:47:20  lr: 0.000020  loss: 3.9785  time: 0.5683  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4050/27734]  eta: 3:46:51  lr: 0.000020  loss: 2.7879  time: 0.5789  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4100/27734]  eta: 3:46:21  lr: 0.000020  loss: 3.0503  time: 0.5729  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4150/27734]  eta: 3:45:54  lr: 0.000020  loss: 4.6143  time: 0.5862  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4200/27734]  eta: 3:45:26  lr: 0.000020  loss: 5.5625  time: 0.5816  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4250/27734]  eta: 3:44:57  lr: 0.000020  loss: 3.9622  time: 0.5703  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 4300/27734]  eta: 3:44:28  lr: 0.000020  loss: 2.5774  time: 0.5738  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4350/27734]  eta: 3:44:00  lr: 0.000020  loss: 2.1901  time: 0.5783  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4400/27734]  eta: 3:43:30  lr: 0.000020  loss: 3.0417  time: 0.5681  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4450/27734]  eta: 3:43:00  lr: 0.000020  loss: 5.0739  time: 0.5745  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 4500/27734]  eta: 3:42:32  lr: 0.000020  loss: 2.9757  time: 0.5791  data: 0.0001  max mem: 15547
Train Epoch: [0]  [ 4550/27734]  eta: 3:42:02  lr: 0.000020  loss: 4.2503  time: 0.5778  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4600/27734]  eta: 3:41:34  lr: 0.000020  loss: 3.3139  time: 0.5739  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4650/27734]  eta: 3:41:05  lr: 0.000020  loss: 3.5629  time: 0.5727  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4700/27734]  eta: 3:40:36  lr: 0.000020  loss: 2.5946  time: 0.5719  data: 0.0002  max mem: 15547
Train Epoch: [0]  [ 4750/27734]  eta: 3:40:07  lr: 0.000020  loss: 4.4322  time: 0.5740  data: 0.0002  max mem: 15547
