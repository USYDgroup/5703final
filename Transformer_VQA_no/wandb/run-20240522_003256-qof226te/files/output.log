Not using distributed mode
Creating vqa datasets
Creating model
Cosine annealing scheduler will have no effect on the learning rate since t_initial = t_mul = eta_mul = 1.
load checkpoint from /home/admin1/5703-upload/5703/Transformer_VQA_no/8-epoch.pth and ALBEF.fusion ##new , fuse the img and pseduo prompt after inversion
_IncompatibleKeys(missing_keys=['inversion.0.weight', 'inversion.0.bias', 'inversion.2.weight', 'inversion.2.bias', 'inversion.4.weight', 'inversion.4.bias'], unexpected_keys=['fusion_encoder.cls.predictions.bias', 'fusion_encoder.cls.predictions.transform.dense.weight', 'fusion_encoder.cls.predictions.transform.dense.bias', 'fusion_encoder.cls.predictions.transform.LayerNorm.weight', 'fusion_encoder.cls.predictions.transform.LayerNorm.bias', 'fusion_encoder.cls.predictions.decoder.weight', 'fusion_encoder.cls.predictions.decoder.bias'])
Start training
Train Epoch: [0]  [  0/563]  eta: 0:31:39  lr: 0.000010  loss: 0.6989  time: 3.3747  data: 1.4739  max mem: 11149
Train Epoch: [0]  [ 50/563]  eta: 0:05:17  lr: 0.000010  loss: 0.4797  time: 0.5653  data: 0.0001  max mem: 14771
Train Epoch: [0]  [100/563]  eta: 0:04:34  lr: 0.000010  loss: 0.3068  time: 0.5664  data: 0.0001  max mem: 14771
Train Epoch: [0]  [150/563]  eta: 0:04:00  lr: 0.000013  loss: 0.2086  time: 0.5595  data: 0.0001  max mem: 14771
Train Epoch: [0]  [200/563]  eta: 0:03:29  lr: 0.000013  loss: 0.1689  time: 0.5671  data: 0.0001  max mem: 14771
Train Epoch: [0]  [250/563]  eta: 0:03:00  lr: 0.000015  loss: 0.3079  time: 0.5730  data: 0.0001  max mem: 14771
Train Epoch: [0]  [300/563]  eta: 0:02:30  lr: 0.000015  loss: 0.2298  time: 0.5562  data: 0.0001  max mem: 14771
Train Epoch: [0]  [350/563]  eta: 0:02:01  lr: 0.000018  loss: 0.2724  time: 0.5689  data: 0.0001  max mem: 14771
Train Epoch: [0]  [400/563]  eta: 0:01:33  lr: 0.000018  loss: 0.2049  time: 0.5704  data: 0.0001  max mem: 14771
Train Epoch: [0]  [450/563]  eta: 0:01:04  lr: 0.000020  loss: 0.1343  time: 0.5665  data: 0.0001  max mem: 14771
Train Epoch: [0]  [500/563]  eta: 0:00:35  lr: 0.000020  loss: 0.0705  time: 0.5728  data: 0.0001  max mem: 14771
Train Epoch: [0]  [550/563]  eta: 0:00:07  lr: 0.000020  loss: 0.2024  time: 0.5672  data: 0.0001  max mem: 14771
Train Epoch: [0]  [562/563]  eta: 0:00:00  lr: 0.000020  loss: 0.0995  time: 0.5526  data: 0.0001  max mem: 14771
Train Epoch: [0] Total time: 0:05:21 (0.5704 s / it)
Averaged stats: lr: 0.0000  loss: 0.2845
Generate VQA test result:  [  0/282]  eta: 0:04:16    time: 0.9081  data: 0.4012  max mem: 14771
Generate VQA test result:  [ 50/282]  eta: 0:00:50    time: 0.2034  data: 0.0001  max mem: 14771
Generate VQA test result:  [100/282]  eta: 0:00:38    time: 0.2035  data: 0.0001  max mem: 14771
Generate VQA test result:  [150/282]  eta: 0:00:27    time: 0.2036  data: 0.0001  max mem: 14771
Generate VQA test result:  [200/282]  eta: 0:00:16    time: 0.2037  data: 0.0001  max mem: 14771
Generate VQA test result:  [250/282]  eta: 0:00:06    time: 0.2030  data: 0.0001  max mem: 14771
Traceback (most recent call last):
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run.py", line 406, in <module>
    main(args, config)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run.py", line 349, in main
    vqa_result,metric = evaluation(model, test_loader, tokenizer, device, config)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/admin1/5703-upload/5703/Transformer_VQA_no/run.py", line 184, in evaluation
    wandb.log(
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 420, in wrapper
    return func(self, *args, **kwargs)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 371, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 361, in wrapper
    return func(self, *args, **kwargs)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1838, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/admin1/anconda3/envs/pytorch2.0/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1597, in _log
    raise ValueError("wandb.log must be passed a dictionary")
ValueError: wandb.log must be passed a dictionary
Generate VQA test result:  [281/282]  eta: 0:00:00    time: 0.2031  data: 0.0001  max mem: 14771
Generate VQA test result: Total time: 0:00:58 (0.2062 s / it)