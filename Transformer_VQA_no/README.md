File is very large, can be download at the link:
https://drive.google.com/drive/folders/1MXZfTKqnHwK3Sgl67fXS41wAHGdfb5mw?usp=drive_link
Subdirectories and Files:
1.	pycache: Contains cached bytecode files created by Python.
2.	.conda: Likely contains Conda environment configurations.
3.	.idea: Configuration files for an IDE (Integrated Development Environment), probably IntelliJ IDEA or PyCharm.
4.	.vscode: Configuration files for Visual Studio Code.
5.	configs: Contains configuration files for the models and experiments.
1.	bert_config.json: Configuration file for a BERT model.
2.	vqa.yaml: Configuration file specific to VQA.
3.	wandb_config.txt: Configuration file for Weights & Biases, a tool for experiment tracking.
6.	dataset: Contains datasets and data processing scripts.
1.	pycache: Contains cached Python bytecode files.
2.	pre: Pre-processed data.
1.	combined_images: Directory for combined images.
2.	object: Directory possibly for object images or data.
3.	object1: Another directory possibly for object images or data.
4.	shape: Directory for shape-related image data.
5.	Files in pre:
1.	all_train.csv: CSV file containing all training data.
2.	cate_distribution.ipynb: Jupyter notebook for analyzing category distribution.
3.	Concat_png.ipynb: Jupyter notebook for concatenating PNG images.
4.	data_preprocess.ipynb: Jupyter notebook for data preprocessing.
5.	enhance_preprocess.ipynb: Jupyter notebook for enhanced preprocessing.
6.	enhanced_pre_train.json: JSON file for enhanced pre-training data.
7.	json_train.json: JSON file containing training data in JSON format.
8.	pre_test.json: JSON file containing pre-processed test data.
9.	pre_train.json: JSON file containing pre-processed training data.
10.	questions.csv: CSV file containing questions for the VQA dataset.
11.	questions.txt: Text file containing questions for the VQA dataset.
3.	vqa2: Directory likely for VQA version 2.
1.	answer_list.json: JSON file listing possible answers.
2.	init.py: Initialization file for the vqa2 package.
3.	randaugment.py: Python script for data augmentation.
4.	utils.py: Utility functions for VQA.
5.	vqa_dataset.py: Python script for handling the VQA dataset.
7.	hf_model_infer: Contains scripts and files related to model inference using Hugging Face.
1.	imgs: Directory for images.
2.	optim: Directory for optimization-related files.
3.	output: Directory for model output.
4.	output_optimal: Directory for optimal output results.
5.	output_vqa2: Directory for VQA version 2 output.
6.	output1: Another output directory.
7.	scheduler: Directory for scheduling scripts or configurations.
8.	src: Source code directory.
1.	pycache: Contains cached Python bytecode files.
2.	blip2_qformer.py: Python script related to the BLIP2 model and query formulation.
3.	blip2.py: Python script related to the BLIP2 model.
4.	pre_vqa.py: Python script for preprocessing VQA data.
5.	tokenization_bert.py: Python script for BERT tokenization.
6.	vision_transformer.py: Python script for vision transformer model.
7.	xbert.py: Python script possibly related to an extended version of BERT.
8.	wandb: Directory for Weights & Biases experiment tracking.
1.	.gitignore: File specifying which files and directories to ignore in Git version control.
2.	GPUtest.py: Python script for testing GPU functionality.
3.	infer.ipynb: Jupyter notebook for inference.
4.	run_vqa2.py: Python script to run VQA version 2 experiments.
5.	run.py: Main script to run the project.
6.	run.sh: Shell script to execute the project.
7.	test.ipynb: Jupyter notebook for testing.
8.	utils.py: Utility functions for the project.
9.	vqaEval.py: Python script for evaluating VQA models.
10.	wandb_export_2024-05-18T07_44_28.101+08_00.csv: CSV file exported from Weights & Biases.
11.	8-epoch.pth: Model checkpoint file after 8 epochs of training.
12.	ALBEF.pth: Model checkpoint for ALBEF (a VQA model).
13.	pre_finetuned.pth: Pre-finetuned model checkpoint.


